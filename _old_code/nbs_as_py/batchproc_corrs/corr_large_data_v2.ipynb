{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","toc_visible":true,"collapsed_sections":["nhY7aerK7vM5","L1bLtNfcMUWF","p5ellF9eWuO7","BDOowypRDotz","QKmd10a6t0xz","Nq_4RmJbv7OU"],"authorship_tag":"ABX9TyOOnR/wgTGizxE5J5lJNUld"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"29837198eaba48c885f0d0e17c98d594":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6292b0e54ef54ff4b15bcc57bdb0fc80","IPY_MODEL_aed706b7581141398beed076ecda775c","IPY_MODEL_4c6fbff637a9432aabd4d15f0a97f920"],"layout":"IPY_MODEL_f940162a1e874dfaa0e69b105644085c"}},"6292b0e54ef54ff4b15bcc57bdb0fc80":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_755c71f9dc34444eaaa23ac4d0893298","placeholder":"​","style":"IPY_MODEL_23eaa7d287db4a0b82601c61590f65bc","value":"tokenizer_config.json: 100%"}},"aed706b7581141398beed076ecda775c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_79311847c11b4f808899921c94c56b57","max":396,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cc6c6680d6c342f3a58605f3b8b33ffb","value":396}},"4c6fbff637a9432aabd4d15f0a97f920":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c482f7ef5964a07828f3c7b5550c9e4","placeholder":"​","style":"IPY_MODEL_c38adc5316d64c53853363c673415c04","value":" 396/396 [00:00&lt;00:00, 30.0kB/s]"}},"f940162a1e874dfaa0e69b105644085c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"755c71f9dc34444eaaa23ac4d0893298":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23eaa7d287db4a0b82601c61590f65bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"79311847c11b4f808899921c94c56b57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc6c6680d6c342f3a58605f3b8b33ffb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9c482f7ef5964a07828f3c7b5550c9e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c38adc5316d64c53853363c673415c04":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c7e7d7d09c584adcabfc269eb0530def":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0ce08e7c84ab4572a09a6ea4ff785872","IPY_MODEL_d61792614f6e47bdb491d2d4c4a61571","IPY_MODEL_df4a73a4c99b419f81ec986dc3eb08ae"],"layout":"IPY_MODEL_65fe13ad82b24993a06ea6e7317f5363"}},"0ce08e7c84ab4572a09a6ea4ff785872":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d38619f7fd7a4d9c9bc400ff7ecbada5","placeholder":"​","style":"IPY_MODEL_8d1f022f7f014355adc29da45abda279","value":"tokenizer.json: 100%"}},"d61792614f6e47bdb491d2d4c4a61571":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_562f13f4ba6542ab80fc723431200ea0","max":2113710,"min":0,"orientation":"horizontal","style":"IPY_MODEL_16fdb2a8dcf24fde962e3194b36c77c4","value":2113710}},"df4a73a4c99b419f81ec986dc3eb08ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f7f41172fd844098e540713d53a026b","placeholder":"​","style":"IPY_MODEL_346de61707e046d3b836e4becce49d60","value":" 2.11M/2.11M [00:00&lt;00:00, 2.45MB/s]"}},"65fe13ad82b24993a06ea6e7317f5363":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d38619f7fd7a4d9c9bc400ff7ecbada5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d1f022f7f014355adc29da45abda279":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"562f13f4ba6542ab80fc723431200ea0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16fdb2a8dcf24fde962e3194b36c77c4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7f7f41172fd844098e540713d53a026b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"346de61707e046d3b836e4becce49d60":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97324a712cb44e8ca33e4099d61ac8c2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cfb1412fd7df4e8abb99f253415f0ff2","IPY_MODEL_5930649579374ea09fb50d781a42c32d","IPY_MODEL_ef1a88eef29e46da96130f5a0406f8ce"],"layout":"IPY_MODEL_3405e5eb643c4fb4bba354f05c1840c5"}},"cfb1412fd7df4e8abb99f253415f0ff2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45c946164a824c1c8c6c04b70317aef9","placeholder":"​","style":"IPY_MODEL_53596883eb3f4250975e07e0caa78629","value":"special_tokens_map.json: 100%"}},"5930649579374ea09fb50d781a42c32d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_001f25d61d9c491dba91ec8ea1f1d5a2","max":99,"min":0,"orientation":"horizontal","style":"IPY_MODEL_75b84111b39a42319a671207947e5d28","value":99}},"ef1a88eef29e46da96130f5a0406f8ce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5bd7042f6924a9bae52f4578f2d0102","placeholder":"​","style":"IPY_MODEL_f81204c39b3944159b71525e2992d4eb","value":" 99.0/99.0 [00:00&lt;00:00, 8.21kB/s]"}},"3405e5eb643c4fb4bba354f05c1840c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45c946164a824c1c8c6c04b70317aef9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53596883eb3f4250975e07e0caa78629":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"001f25d61d9c491dba91ec8ea1f1d5a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75b84111b39a42319a671207947e5d28":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a5bd7042f6924a9bae52f4578f2d0102":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f81204c39b3944159b71525e2992d4eb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a1fadd5f5d8d486496739e2ac9c3aa50":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_05f9811ac3eb4497917137918b5c732d","IPY_MODEL_6ea4c7cc7cc6436c9946fb51e8dd1cb8","IPY_MODEL_8d6a76a7784e41e08fd5bc3b7f49fda9"],"layout":"IPY_MODEL_5cb0bf022a7b42a5aa7383938b0da83b"}},"05f9811ac3eb4497917137918b5c732d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6eec701494fb4e5e9d2ac8084cf3ba86","placeholder":"​","style":"IPY_MODEL_8430810db84145e68025eeefb0c8e997","value":"config.json: 100%"}},"6ea4c7cc7cc6436c9946fb51e8dd1cb8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c849d832667e4fc78bbf1447bdbde3c4","max":567,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f6f031d050ec414a9b007374d492c7b9","value":567}},"8d6a76a7784e41e08fd5bc3b7f49fda9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bd5126a726a4ef9ac28df3f8b2a8285","placeholder":"​","style":"IPY_MODEL_174ccc788d7842088ca2ce92acbd4533","value":" 567/567 [00:00&lt;00:00, 46.0kB/s]"}},"5cb0bf022a7b42a5aa7383938b0da83b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6eec701494fb4e5e9d2ac8084cf3ba86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8430810db84145e68025eeefb0c8e997":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c849d832667e4fc78bbf1447bdbde3c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6f031d050ec414a9b007374d492c7b9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2bd5126a726a4ef9ac28df3f8b2a8285":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"174ccc788d7842088ca2ce92acbd4533":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a62ea4c1aad64c9693607e2fb1a421ed":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7142a398671d47a7b2591ed5070a0d32","IPY_MODEL_d5828c2d741444eeb5e409e6b03269eb","IPY_MODEL_974623d3d0154493903a903540e2f1ec"],"layout":"IPY_MODEL_259375d9e9ed4f6c98632c9b8dfe0261"}},"7142a398671d47a7b2591ed5070a0d32":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4f8f2e18053467db7a5103711d0cd4a","placeholder":"​","style":"IPY_MODEL_960a163352fc47cd99ac786c8eb222c5","value":"model.safetensors: 100%"}},"d5828c2d741444eeb5e409e6b03269eb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5a16480fada474591558964fb3b350e","max":166029852,"min":0,"orientation":"horizontal","style":"IPY_MODEL_52ba9ef59947437cb1cd013dbb2a684d","value":166029852}},"974623d3d0154493903a903540e2f1ec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e2b088b947249b59d7ef8431089cdd5","placeholder":"​","style":"IPY_MODEL_507e60f22aa74ebf96e0368021b76794","value":" 166M/166M [00:00&lt;00:00, 286MB/s]"}},"259375d9e9ed4f6c98632c9b8dfe0261":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4f8f2e18053467db7a5103711d0cd4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"960a163352fc47cd99ac786c8eb222c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f5a16480fada474591558964fb3b350e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52ba9ef59947437cb1cd013dbb2a684d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3e2b088b947249b59d7ef8431089cdd5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"507e60f22aa74ebf96e0368021b76794":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"03091eae7ba743ac8d77bcd80dba7bb5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bb03fe5d200c4295863bbef6ed666c23","IPY_MODEL_b851f3320146489ba38497a62e5328b9","IPY_MODEL_78fa68f7e59c43b9883251d74b6a5d62"],"layout":"IPY_MODEL_bb064152e6834627ac50f148a728fa25"}},"bb03fe5d200c4295863bbef6ed666c23":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5efa58a8bdaf4a67b7f529dfadd0b533","placeholder":"​","style":"IPY_MODEL_b72f45234fc44ecb8a99523f1725a0b0","value":"config.json: 100%"}},"b851f3320146489ba38497a62e5328b9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_30f8087e6747403a9d966daadee3f3f2","max":569,"min":0,"orientation":"horizontal","style":"IPY_MODEL_546d741c440b4d8c8b828850ce4d7f11","value":569}},"78fa68f7e59c43b9883251d74b6a5d62":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2d9d6c053b64c0b9ad88bf8f2f05217","placeholder":"​","style":"IPY_MODEL_c3b82d333615425f95826a7d508b2363","value":" 569/569 [00:00&lt;00:00, 47.2kB/s]"}},"bb064152e6834627ac50f148a728fa25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5efa58a8bdaf4a67b7f529dfadd0b533":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b72f45234fc44ecb8a99523f1725a0b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"30f8087e6747403a9d966daadee3f3f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"546d741c440b4d8c8b828850ce4d7f11":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d2d9d6c053b64c0b9ad88bf8f2f05217":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3b82d333615425f95826a7d508b2363":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e400851f2c54757b440d5713513a259":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d3d4f5ba55da406f879500c407a9e6af","IPY_MODEL_f35dae51f5694659a8a87d32fba45c0c","IPY_MODEL_4651a695dd7c47a1ac0972cd8f56fd1a"],"layout":"IPY_MODEL_358891ea0cb44e9184cf2f06356f7b96"}},"d3d4f5ba55da406f879500c407a9e6af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64cfbcdd8fa4495e92a7bf58b1dd233b","placeholder":"​","style":"IPY_MODEL_ec1e9eafd4774df9b66da947738f825d","value":"model.safetensors: 100%"}},"f35dae51f5694659a8a87d32fba45c0c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_131cd9677280496aa281d74baeb94107","max":374998696,"min":0,"orientation":"horizontal","style":"IPY_MODEL_97cce94b8c684b198be7c4c50d939fa3","value":374998696}},"4651a695dd7c47a1ac0972cd8f56fd1a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d08bffd0d3f421bad116624e327040c","placeholder":"​","style":"IPY_MODEL_80d637b1258b4911a5b20df5dfce3748","value":" 375M/375M [00:01&lt;00:00, 344MB/s]"}},"358891ea0cb44e9184cf2f06356f7b96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64cfbcdd8fa4495e92a7bf58b1dd233b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec1e9eafd4774df9b66da947738f825d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"131cd9677280496aa281d74baeb94107":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97cce94b8c684b198be7c4c50d939fa3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1d08bffd0d3f421bad116624e327040c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80d637b1258b4911a5b20df5dfce3748":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"35805c1abe3845a79b7f748ad3d490b1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4adbd227eef94162b8f007f930ba031b","IPY_MODEL_6940c91600554a0daa2c4fdfda41dd6a","IPY_MODEL_f802364c6f44430392ebeab19b0cc6aa"],"layout":"IPY_MODEL_66059e869bcd47e1a63df626e22aa143"}},"4adbd227eef94162b8f007f930ba031b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04fed2c304b24a31abf261bd41e4af5b","placeholder":"​","style":"IPY_MODEL_b749fa026b9c485d93146ea28253bda3","value":"Downloading builder script: 100%"}},"6940c91600554a0daa2c4fdfda41dd6a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_daed1cb8e35b458c8cd70d70e5a729fd","max":2726,"min":0,"orientation":"horizontal","style":"IPY_MODEL_34f97b3510f74864885fa2d0b8be1c53","value":2726}},"f802364c6f44430392ebeab19b0cc6aa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53bef488334e44c4b478c0f9e5c6123c","placeholder":"​","style":"IPY_MODEL_0b90b6f00d4b4aff90c762a6ba03089a","value":" 2.73k/2.73k [00:00&lt;00:00, 11.2kB/s]"}},"66059e869bcd47e1a63df626e22aa143":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04fed2c304b24a31abf261bd41e4af5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b749fa026b9c485d93146ea28253bda3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"daed1cb8e35b458c8cd70d70e5a729fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34f97b3510f74864885fa2d0b8be1c53":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"53bef488334e44c4b478c0f9e5c6123c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b90b6f00d4b4aff90c762a6ba03089a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"688e3387137c4823ab5c13a2a94e1fb0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5e0d08be3a3845649d964aba110a7dc1","IPY_MODEL_da3463dd631f446c80db31e00fd3ec52","IPY_MODEL_825c40805c7b41b5a3c327bb891b8a3c"],"layout":"IPY_MODEL_d80ff5fa09724b87b16b78c748dc4fd8"}},"5e0d08be3a3845649d964aba110a7dc1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eabcf425456e4cfeafb1554faa927f6f","placeholder":"​","style":"IPY_MODEL_3d157560a491463d9bb691b661f8fa9b","value":"Downloading readme: 100%"}},"da3463dd631f446c80db31e00fd3ec52":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0cb3c9b7a85143428df2874bed536639","max":7351,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f7c2b3c42e2940308deb0d6f205598fb","value":7351}},"825c40805c7b41b5a3c327bb891b8a3c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d42e7ba9db9c420e977636065fde5951","placeholder":"​","style":"IPY_MODEL_057892a6e4d947639a26f08990f0cb79","value":" 7.35k/7.35k [00:00&lt;00:00, 29.4kB/s]"}},"d80ff5fa09724b87b16b78c748dc4fd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eabcf425456e4cfeafb1554faa927f6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d157560a491463d9bb691b661f8fa9b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0cb3c9b7a85143428df2874bed536639":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7c2b3c42e2940308deb0d6f205598fb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d42e7ba9db9c420e977636065fde5951":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"057892a6e4d947639a26f08990f0cb79":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fbe1a7caccf74609a9b0c56a90fe81bc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bfdf0fa98ea345b6b11372c39ba1d09d","IPY_MODEL_8e8c9f4eae0948728ada05d1961bf3e3","IPY_MODEL_07b543665170418d9d47bc496f2b30cc"],"layout":"IPY_MODEL_22224628a66d4ef7af5a1ced1428623d"}},"bfdf0fa98ea345b6b11372c39ba1d09d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c1efac036314e4cabaa8a82c2760c66","placeholder":"​","style":"IPY_MODEL_72e5697cb62b413db3a27cbf22d77dcc","value":"Fetching 2 files: 100%"}},"8e8c9f4eae0948728ada05d1961bf3e3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_36be0ef6250f42bc9226675b655b7da8","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9119bc86b4f848e3932b709bde5c530d","value":2}},"07b543665170418d9d47bc496f2b30cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_968e404326464f708a40c58543dfc284","placeholder":"​","style":"IPY_MODEL_a33556e0a11f4600b1785773a652cb27","value":" 2/2 [00:00&lt;00:00,  2.09it/s]"}},"22224628a66d4ef7af5a1ced1428623d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c1efac036314e4cabaa8a82c2760c66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72e5697cb62b413db3a27cbf22d77dcc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"36be0ef6250f42bc9226675b655b7da8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9119bc86b4f848e3932b709bde5c530d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"968e404326464f708a40c58543dfc284":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a33556e0a11f4600b1785773a652cb27":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e7c4453beff64fa8971a58d459867440":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_359a2e9e420e450bb80b5cea533505fa","IPY_MODEL_3bce6d9a310b495ca805dc1e39e58bbc","IPY_MODEL_180aea270f5543e7b1e69c4f9e89f9de"],"layout":"IPY_MODEL_430276854f0b4f95bafa6342d2d8546a"}},"359a2e9e420e450bb80b5cea533505fa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a28b4cd7354a4cd1860d064bd0d76282","placeholder":"​","style":"IPY_MODEL_050ecee2d8b94eb7a4f5c0763bc22ca7","value":"layers.2/cfg.json: 100%"}},"3bce6d9a310b495ca805dc1e39e58bbc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3dc2f2a4f077486b9d7f6dd3596a5b64","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e0e15ae5796d4a5f8b6970be81c1018f","value":112}},"180aea270f5543e7b1e69c4f9e89f9de":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a221b9127184046bab7126334209093","placeholder":"​","style":"IPY_MODEL_30ed304d5dc84ffa93bfb8c802b626a2","value":" 112/112 [00:00&lt;00:00, 8.22kB/s]"}},"430276854f0b4f95bafa6342d2d8546a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a28b4cd7354a4cd1860d064bd0d76282":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"050ecee2d8b94eb7a4f5c0763bc22ca7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3dc2f2a4f077486b9d7f6dd3596a5b64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0e15ae5796d4a5f8b6970be81c1018f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3a221b9127184046bab7126334209093":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30ed304d5dc84ffa93bfb8c802b626a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"53329d6965cd4dcc83214af5237671b8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1a98913f6c604f1192667399f088dec9","IPY_MODEL_802e3576b5d34ea1b3fe1b76ab8afed2","IPY_MODEL_5fe1ae2c14594f27a96b2309096b95cf"],"layout":"IPY_MODEL_f7273d801fd34e56b26f3a138f00a42e"}},"1a98913f6c604f1192667399f088dec9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1543b0c7df9f4aad8b2a1f9871202d9d","placeholder":"​","style":"IPY_MODEL_1e9a35e342a6408fb8275c592d28965c","value":"sae.safetensors: 100%"}},"802e3576b5d34ea1b3fe1b76ab8afed2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a723945c5c7c411381e9797a536801a0","max":134351176,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9c3cb670fed346d6b863709fc3566835","value":134351176}},"5fe1ae2c14594f27a96b2309096b95cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f9f03e0561b4883a0f6e7c15266a45c","placeholder":"​","style":"IPY_MODEL_1fedcfc7bd8648ff85314efda2ac74ba","value":" 134M/134M [00:00&lt;00:00, 411MB/s]"}},"f7273d801fd34e56b26f3a138f00a42e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1543b0c7df9f4aad8b2a1f9871202d9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e9a35e342a6408fb8275c592d28965c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a723945c5c7c411381e9797a536801a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c3cb670fed346d6b863709fc3566835":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3f9f03e0561b4883a0f6e7c15266a45c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fedcfc7bd8648ff85314efda2ac74ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"17d0bc149e91433eacf646707914699b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_544cd2a387084c1baa2afc81965f6cb3","IPY_MODEL_1486cc52529347e688213c1c9b1750d5","IPY_MODEL_07aba03b859d40d4886d22b3f8e9c36c"],"layout":"IPY_MODEL_6d1051dd43fa4275871a4a7edee02205"}},"544cd2a387084c1baa2afc81965f6cb3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8aebca09bff4f67b5fd28fc9d412842","placeholder":"​","style":"IPY_MODEL_576bfddfe40c463cb3df34b9089f8a89","value":"Fetching 2 files: 100%"}},"1486cc52529347e688213c1c9b1750d5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_18d3e639ef5949c18648cd106d6de257","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6f177e92585b47f4ad8345027afb288c","value":2}},"07aba03b859d40d4886d22b3f8e9c36c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_575af99d732d4cf78ec7aa9ae5843d8f","placeholder":"​","style":"IPY_MODEL_34b6791108f14787a4db8d75182b762b","value":" 2/2 [00:01&lt;00:00,  1.84it/s]"}},"6d1051dd43fa4275871a4a7edee02205":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8aebca09bff4f67b5fd28fc9d412842":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"576bfddfe40c463cb3df34b9089f8a89":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18d3e639ef5949c18648cd106d6de257":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f177e92585b47f4ad8345027afb288c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"575af99d732d4cf78ec7aa9ae5843d8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34b6791108f14787a4db8d75182b762b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3471262d2a9041718a2896630c3f58d1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f67df43ab9474fdba784518da326ecfa","IPY_MODEL_a4be450ae0ac408c8d9e79dfe9344ec5","IPY_MODEL_5d4104a4dfa14f4698c74171bac66ded"],"layout":"IPY_MODEL_25f3f75b0b9545efa56d00a5a7ea956c"}},"f67df43ab9474fdba784518da326ecfa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_abee9d3c2bf34eef886a080e529423f1","placeholder":"​","style":"IPY_MODEL_b14fcdf9ed07461f8ea4c90bb87f8bea","value":"layers.2/cfg.json: 100%"}},"a4be450ae0ac408c8d9e79dfe9344ec5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce41a2cd9c3e4ffb9287c4291cf4cafd","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a1256913dd6f4eb1b07a1631dd9789d7","value":112}},"5d4104a4dfa14f4698c74171bac66ded":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f176e4aef4c49edbcf91310bfd6e80d","placeholder":"​","style":"IPY_MODEL_d708cd332a214e68baa0018171c58062","value":" 112/112 [00:00&lt;00:00, 9.11kB/s]"}},"25f3f75b0b9545efa56d00a5a7ea956c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abee9d3c2bf34eef886a080e529423f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b14fcdf9ed07461f8ea4c90bb87f8bea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce41a2cd9c3e4ffb9287c4291cf4cafd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1256913dd6f4eb1b07a1631dd9789d7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0f176e4aef4c49edbcf91310bfd6e80d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d708cd332a214e68baa0018171c58062":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98c58de8b2524d88a91d39d6b1b2127d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_654ec12d4193462eb830cab79cfe3245","IPY_MODEL_ba38df95643a4141a1f0ce33f325eb26","IPY_MODEL_c0e64c9881544ef18c263c04dde0a0af"],"layout":"IPY_MODEL_a960e494e7224771a304a220875804bd"}},"654ec12d4193462eb830cab79cfe3245":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_927db426b36f4d33a4dbc8370711860b","placeholder":"​","style":"IPY_MODEL_fc6e444ee0cc4a3a827d4f79a36e94e2","value":"sae.safetensors: 100%"}},"ba38df95643a4141a1f0ce33f325eb26":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_891ff3c845194a61b363b38a323838dc","max":201461072,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c23e07c3b27b408da0514ff94cf760cf","value":201461072}},"c0e64c9881544ef18c263c04dde0a0af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_92760a3b51f84566845295f388a06dde","placeholder":"​","style":"IPY_MODEL_4482272dd6804d6cb0159deec575d371","value":" 201M/201M [00:00&lt;00:00, 396MB/s]"}},"a960e494e7224771a304a220875804bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"927db426b36f4d33a4dbc8370711860b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc6e444ee0cc4a3a827d4f79a36e94e2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"891ff3c845194a61b363b38a323838dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c23e07c3b27b408da0514ff94cf760cf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"92760a3b51f84566845295f388a06dde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4482272dd6804d6cb0159deec575d371":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# setup"],"metadata":{"id":"nhY7aerK7vM5"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"og3NgzELGzKN","executionInfo":{"status":"ok","timestamp":1725402745949,"user_tz":240,"elapsed":14688,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["%%capture\n","!pip install git+https://github.com/EleutherAI/sae.git"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"KFTmWGkcp6u6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725402754430,"user_tz":240,"elapsed":8538,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"592a738c-b6ae-4779-a58f-078823f3c5d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Triton not installed, using eager implementation of SAE decoder.\n"]}],"source":["from sae.config import SaeConfig\n","from sae.utils import decoder_impl\n","from sae import Sae\n","\n","import gc\n","import pickle\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import json\n","from fnmatch import fnmatch\n","from pathlib import Path\n","from typing import NamedTuple, Optional, Callable, Union, List, Tuple\n","# from jaxtyping import Float, Int\n","\n","import einops\n","import torch\n","from torch import Tensor, nn\n","from huggingface_hub import snapshot_download\n","from natsort import natsorted\n","from safetensors.torch import load_model, save_model\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\""]},{"cell_type":"markdown","metadata":{"id":"aQ_3rxDtd3Mc"},"source":["## get rand"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"BqIiTtkid4qA","executionInfo":{"status":"ok","timestamp":1725402754431,"user_tz":240,"elapsed":192,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["def score_rand(num_feats, sim_fn, shapereq_bool=False):\n","    all_rand_scores = []\n","    # num_feats = len(uniq_corr_indices_AB_forA)\n","    for i in range(5):\n","        rand_modA_feats = np.random.randint(low=0, high=weight_matrix.shape[0], size=num_feats).tolist()\n","        rand_modB_feats = np.random.randint(low=0, high=weight_matrix_2.shape[0], size=num_feats).tolist()\n","\n","        if shapereq_bool:\n","            score = sim_fn(weight_matrix[rand_modA_feats], weight_matrix_2[rand_modB_feats], \"nd\")\n","        else:\n","            score = sim_fn(weight_matrix[rand_modA_feats], weight_matrix_2[rand_modB_feats])\n","        all_rand_scores.append(score)\n","    print(sum(all_rand_scores) / len(all_rand_scores))\n","    # plt.hist(all_rand_scores)\n","    # plt.show()\n","    return sum(all_rand_scores) / len(all_rand_scores)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"4MuzPsULu30o","executionInfo":{"status":"ok","timestamp":1725402754431,"user_tz":240,"elapsed":189,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["# import random\n","# row_idxs = list(range(weight_matrix_2.shape[0]))\n","# random.shuffle(row_idxs)\n","# jaccard_similarity(weight_matrix_np, weight_matrix_2[row_idxs])"]},{"cell_type":"markdown","metadata":{"id":"vlKdEehFvC86"},"source":["## sim fns"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Rl7IYESN1irP","executionInfo":{"status":"ok","timestamp":1725402754432,"user_tz":240,"elapsed":186,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["import functools\n","from typing import Any, Callable, Dict, List, Tuple, Union\n","\n","import numpy as np\n","import numpy.typing as npt\n","import torch\n","\n","\n","def to_numpy_if_needed(*args: Union[torch.Tensor, npt.NDArray]) -> List[npt.NDArray]:\n","    def convert(x: Union[torch.Tensor, npt.NDArray]) -> npt.NDArray:\n","        return x if isinstance(x, np.ndarray) else x.numpy()\n","\n","    return list(map(convert, args))\n","\n","\n","def to_torch_if_needed(*args: Union[torch.Tensor, npt.NDArray]) -> List[torch.Tensor]:\n","    def convert(x: Union[torch.Tensor, npt.NDArray]) -> torch.Tensor:\n","        return x if isinstance(x, torch.Tensor) else torch.from_numpy(x)\n","\n","    return list(map(convert, args))\n","\n","\n","def adjust_dimensionality(\n","    R: npt.NDArray, Rp: npt.NDArray, strategy=\"zero_pad\"\n",") -> Tuple[npt.NDArray, npt.NDArray]:\n","    D = R.shape[1]\n","    Dp = Rp.shape[1]\n","    if strategy == \"zero_pad\":\n","        if D - Dp == 0:\n","            return R, Rp\n","        elif D - Dp > 0:\n","            return R, np.concatenate((Rp, np.zeros((Rp.shape[0], D - Dp))), axis=1)\n","        else:\n","            return np.concatenate((R, np.zeros((R.shape[0], Dp - D))), axis=1), Rp\n","    else:\n","        raise NotImplementedError()\n","\n","\n","def center_columns(R: npt.NDArray) -> npt.NDArray:\n","    return R - R.mean(axis=0)[None, :]\n","\n","\n","def normalize_matrix_norm(R: npt.NDArray) -> npt.NDArray:\n","    return R / np.linalg.norm(R, ord=\"fro\")\n","\n","\n","def sim_random_baseline(\n","    rep1: torch.Tensor, rep2: torch.Tensor, sim_func: Callable, n_permutations: int = 10\n",") -> Dict[str, Any]:\n","    torch.manual_seed(1234)\n","    scores = []\n","    for _ in range(n_permutations):\n","        perm = torch.randperm(rep1.size(0))\n","\n","        score = sim_func(rep1[perm, :], rep2)\n","        score = score if isinstance(score, float) else score[\"score\"]\n","\n","        scores.append(score)\n","\n","    return {\"baseline_scores\": np.array(scores)}\n","\n","\n","class Pipeline:\n","    def __init__(\n","        self,\n","        preprocess_funcs: List[Callable[[npt.NDArray], npt.NDArray]],\n","        similarity_func: Callable[[npt.NDArray, npt.NDArray], Dict[str, Any]],\n","    ) -> None:\n","        self.preprocess_funcs = preprocess_funcs\n","        self.similarity_func = similarity_func\n","\n","    def __call__(self, R: npt.NDArray, Rp: npt.NDArray) -> Dict[str, Any]:\n","        for preprocess_func in self.preprocess_funcs:\n","            R = preprocess_func(R)\n","            Rp = preprocess_func(Rp)\n","        return self.similarity_func(R, Rp)\n","\n","    def __str__(self) -> str:\n","        def func_name(func: Callable) -> str:\n","            return (\n","                func.__name__\n","                if not isinstance(func, functools.partial)\n","                else func.func.__name__\n","            )\n","\n","        def partial_keywords(func: Callable) -> str:\n","            if not isinstance(func, functools.partial):\n","                return \"\"\n","            else:\n","                return str(func.keywords)\n","\n","        return (\n","            \"Pipeline(\"\n","            + (\n","                \"+\".join(map(func_name, self.preprocess_funcs))\n","                + \"+\"\n","                + func_name(self.similarity_func)\n","                + partial_keywords(self.similarity_func)\n","            )\n","            + \")\"\n","        )"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"RgcXEjdcXAOj","executionInfo":{"status":"ok","timestamp":1725402755232,"user_tz":240,"elapsed":984,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["from typing import List, Set, Union\n","\n","import numpy as np\n","import numpy.typing as npt\n","import sklearn.neighbors\n","import torch\n","\n","# from llmcomp.measures.utils import to_numpy_if_needed\n","\n","\n","def _jac_sim_i(idx_R: Set[int], idx_Rp: Set[int]) -> float:\n","    return len(idx_R.intersection(idx_Rp)) / len(idx_R.union(idx_Rp))\n","\n","\n","def jaccard_similarity(\n","    R: Union[torch.Tensor, npt.NDArray],\n","    Rp: Union[torch.Tensor, npt.NDArray],\n","    k: int = 10,\n","    inner: str = \"cosine\",\n","    n_jobs: int = 8,\n",") -> float:\n","    R, Rp = to_numpy_if_needed(R, Rp)\n","\n","    indices_R = nn_array_to_setlist(top_k_neighbors(R, k, inner, n_jobs))\n","    indices_Rp = nn_array_to_setlist(top_k_neighbors(Rp, k, inner, n_jobs))\n","\n","    return float(\n","        np.mean(\n","            [_jac_sim_i(idx_R, idx_Rp) for idx_R, idx_Rp in zip(indices_R, indices_Rp)]\n","        )\n","    )\n","\n","\n","def top_k_neighbors(\n","    R: npt.NDArray,\n","    k: int,\n","    inner: str,\n","    n_jobs: int,\n",") -> npt.NDArray:\n","    # k+1 nearest neighbors, because we pass in all the data, which means that a point\n","    # will be the nearest neighbor to itself. We remove this point from the results and\n","    # report only the k nearest neighbors distinct from the point itself.\n","    nns = sklearn.neighbors.NearestNeighbors(\n","        n_neighbors=k + 1, metric=inner, n_jobs=n_jobs\n","    )\n","    nns.fit(R)\n","    _, nns = nns.kneighbors(R)\n","    return nns[:, 1:]\n","\n","\n","def nn_array_to_setlist(nn: npt.NDArray) -> List[Set[int]]:\n","    return [set(idx) for idx in nn]"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"K8QY53-0umRk","executionInfo":{"status":"ok","timestamp":1725402755232,"user_tz":240,"elapsed":484,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["import functools\n","import logging\n","from abc import ABC\n","from abc import abstractmethod\n","from dataclasses import dataclass\n","from dataclasses import field\n","from typing import Any\n","from typing import Callable\n","from typing import get_args\n","from typing import List\n","from typing import Literal\n","from typing import Optional\n","from typing import Protocol\n","from typing import Tuple\n","from typing import Union\n","\n","import numpy as np\n","import numpy.typing as npt\n","import torch\n","from einops import rearrange\n","# from loguru import logger\n","\n","log = logging.getLogger(__name__)\n","\n","\n","SHAPE_TYPE = Literal[\"nd\", \"ntd\", \"nchw\"]\n","\n","ND_SHAPE, NTD_SHAPE, NCHW_SHAPE = get_args(SHAPE_TYPE)[0], get_args(SHAPE_TYPE)[1], get_args(SHAPE_TYPE)[2]\n","\n","\n","class SimilarityFunction(Protocol):\n","    def __call__(  # noqa: E704\n","        self,\n","        R: torch.Tensor | npt.NDArray,\n","        Rp: torch.Tensor | npt.NDArray,\n","        shape: SHAPE_TYPE,\n","    ) -> float: ...\n","\n","\n","class RSMSimilarityFunction(Protocol):\n","    def __call__(  # noqa: E704\n","        self, R: torch.Tensor | npt.NDArray, Rp: torch.Tensor | npt.NDArray, shape: SHAPE_TYPE, n_jobs: int\n","    ) -> float: ...\n","\n","\n","@dataclass\n","class BaseSimilarityMeasure(ABC):\n","    larger_is_more_similar: bool\n","    is_symmetric: bool\n","\n","    is_metric: bool | None = None\n","    invariant_to_affine: bool | None = None\n","    invariant_to_invertible_linear: bool | None = None\n","    invariant_to_ortho: bool | None = None\n","    invariant_to_permutation: bool | None = None\n","    invariant_to_isotropic_scaling: bool | None = None\n","    invariant_to_translation: bool | None = None\n","    name: str = field(init=False)\n","\n","    def __post_init__(self):\n","        self.name = self.__class__.__name__\n","\n","    @abstractmethod\n","    def __call__(self, *args: Any, **kwds: Any) -> Any:\n","        raise NotImplementedError\n","\n","\n","class FunctionalSimilarityMeasure(BaseSimilarityMeasure):\n","    @abstractmethod\n","    def __call__(self, output_a: torch.Tensor | npt.NDArray, output_b: torch.Tensor | npt.NDArray) -> float:\n","        raise NotImplementedError\n","\n","\n","@dataclass(kw_only=True)\n","class RepresentationalSimilarityMeasure(BaseSimilarityMeasure):\n","    sim_func: SimilarityFunction\n","\n","    def __call__(\n","        self,\n","        R: torch.Tensor | npt.NDArray,\n","        Rp: torch.Tensor | npt.NDArray,\n","        shape: SHAPE_TYPE,\n","    ) -> float:\n","        return self.sim_func(R, Rp, shape)\n","\n","\n","class RSMSimilarityMeasure(RepresentationalSimilarityMeasure):\n","    sim_func: RSMSimilarityFunction\n","\n","    @staticmethod\n","    def estimate_good_number_of_jobs(R: torch.Tensor | npt.NDArray, Rp: torch.Tensor | npt.NDArray) -> int:\n","        # RSMs in are NxN (or DxD) so the number of jobs should roughly scale quadratically with increase in N (or D).\n","        # False! As long as sklearn-native metrics are used, they will use parallel implementations regardless of job\n","        # count. Each job would spawn their own threads, which leads to oversubscription of cores and thus slowdown.\n","        # This seems to be not fully correct (n_jobs=2 seems to actually use two cores), but using n_jobs=1 seems the\n","        # fastest.\n","        return 1\n","\n","    def __call__(\n","        self,\n","        R: torch.Tensor | npt.NDArray,\n","        Rp: torch.Tensor | npt.NDArray,\n","        shape: SHAPE_TYPE,\n","        n_jobs: Optional[int] = None,\n","    ) -> float:\n","        if n_jobs is None:\n","            n_jobs = self.estimate_good_number_of_jobs(R, Rp)\n","        return self.sim_func(R, Rp, shape, n_jobs=n_jobs)\n","\n","\n","def to_numpy_if_needed(*args: Union[torch.Tensor, npt.NDArray]) -> List[npt.NDArray]:\n","    def convert(x: Union[torch.Tensor, npt.NDArray]) -> npt.NDArray:\n","        return x if isinstance(x, np.ndarray) else x.numpy()\n","\n","    return list(map(convert, args))\n","\n","\n","def to_torch_if_needed(*args: Union[torch.Tensor, npt.NDArray]) -> List[torch.Tensor]:\n","    def convert(x: Union[torch.Tensor, npt.NDArray]) -> torch.Tensor:\n","        return x if isinstance(x, torch.Tensor) else torch.from_numpy(x)\n","\n","    return list(map(convert, args))\n","\n","\n","def adjust_dimensionality(R: npt.NDArray, Rp: npt.NDArray, strategy=\"zero_pad\") -> Tuple[npt.NDArray, npt.NDArray]:\n","    D = R.shape[1]\n","    Dp = Rp.shape[1]\n","    if strategy == \"zero_pad\":\n","        if D - Dp == 0:\n","            return R, Rp\n","        elif D - Dp > 0:\n","            return R, np.concatenate((Rp, np.zeros((Rp.shape[0], D - Dp))), axis=1)\n","        else:\n","            return np.concatenate((R, np.zeros((R.shape[0], Dp - D))), axis=1), Rp\n","    else:\n","        raise NotImplementedError()\n","\n","\n","def center_columns(R: npt.NDArray) -> npt.NDArray:\n","    return R - R.mean(axis=0)[None, :]\n","\n","\n","def normalize_matrix_norm(R: npt.NDArray) -> npt.NDArray:\n","    return R / np.linalg.norm(R, ord=\"fro\")\n","\n","\n","def normalize_row_norm(R: npt.NDArray) -> npt.NDArray:\n","    return R / np.linalg.norm(R, ord=2, axis=1, keepdims=True)\n","\n","\n","def standardize(R: npt.NDArray) -> npt.NDArray:\n","    return (R - R.mean(axis=0, keepdims=True)) / R.std(axis=0)\n","\n","\n","def double_center(x: npt.NDArray) -> npt.NDArray:\n","    return x - x.mean(axis=0, keepdims=True) - x.mean(axis=1, keepdims=True) + x.mean()\n","\n","\n","def align_spatial_dimensions(R: npt.NDArray, Rp: npt.NDArray) -> Tuple[npt.NDArray, npt.NDArray]:\n","    \"\"\"\n","    Aligns spatial representations by resizing them to the smallest spatial dimension.\n","    Subsequent aligned spatial representations are flattened, with the spatial aligned representations\n","    moving into the *sample* dimension.\n","    \"\"\"\n","    R_re, Rp_re = resize_wh_reps(R, Rp)\n","    R_re = rearrange(R_re, \"n c h w -> (n h w) c\")\n","    Rp_re = rearrange(Rp_re, \"n c h w -> (n h w) c\")\n","    if R_re.shape[0] > 5000:\n","        logger.info(f\"Got {R_re.shape[0]} samples in N after flattening. Subsampling to reduce compute.\")\n","        subsample = R_re.shape[0] // 5000\n","        R_re = R_re[::subsample]\n","        Rp_re = Rp_re[::subsample]\n","\n","    return R_re, Rp_re\n","\n","\n","def average_pool_downsample(R, resize: bool, new_size: tuple[int, int]):\n","    if not resize:\n","        return R  # do nothing\n","    else:\n","        is_numpy = isinstance(R, np.ndarray)\n","        R_torch = torch.from_numpy(R) if is_numpy else R\n","        R_torch = torch.nn.functional.adaptive_avg_pool2d(R_torch, new_size)\n","        return R_torch.numpy() if is_numpy else R_torch\n","\n","\n","def resize_wh_reps(R: npt.NDArray, Rp: npt.NDArray) -> Tuple[npt.NDArray, npt.NDArray]:\n","    \"\"\"\n","    Function for resizing spatial representations that are not the same size.\n","    Does through fourier transform and resizing.\n","\n","    Args:\n","        R: numpy array of shape  [batch_size, height, width, num_channels]\n","        RP: numpy array of shape [batch_size, height, width, num_channels]\n","\n","    Returns:\n","        fft_acts1: numpy array of shape [batch_size, (new) height, (new) width, num_channels]\n","        fft_acts2: numpy array of shape [batch_size, (new) height, (new) width, num_channels]\n","\n","    \"\"\"\n","    height1, width1 = R.shape[2], R.shape[3]\n","    height2, width2 = Rp.shape[2], Rp.shape[3]\n","    if height1 != height2 or width1 != width2:\n","        height = min(height1, height2)\n","        width = min(width1, width2)\n","        new_size = [height, width]\n","        resize = True\n","    else:\n","        height = height1\n","        width = width1\n","        new_size = None\n","        resize = False\n","\n","    # resize and preprocess with fft\n","    avg_ds1 = average_pool_downsample(R, resize=resize, new_size=new_size)\n","    avg_ds2 = average_pool_downsample(Rp, resize=resize, new_size=new_size)\n","    return avg_ds1, avg_ds2\n","\n","\n","def fft_resize(images, resize=False, new_size=None):\n","    \"\"\"Function for applying DFT and resizing.\n","\n","    This function takes in an array of images, applies the 2-d fourier transform\n","    and resizes them according to new_size, keeping the frequencies that overlap\n","    between the two sizes.\n","\n","    Args:\n","              images: a numpy array with shape\n","                      [batch_size, height, width, num_channels]\n","              resize: boolean, whether or not to resize\n","              new_size: a tuple (size, size), with height and width the same\n","\n","    Returns:\n","              im_fft_downsampled: a numpy array with shape\n","                           [batch_size, (new) height, (new) width, num_channels]\n","    \"\"\"\n","    assert len(images.shape) == 4, \"expecting images to be\" \"[batch_size, height, width, num_channels]\"\n","    if resize:\n","        # FFT --> remove high frequencies --> inverse FFT\n","        im_complex = images.astype(\"complex64\")\n","        im_fft = np.fft.fft2(im_complex, axes=(1, 2))\n","        im_shifted = np.fft.fftshift(im_fft, axes=(1, 2))\n","\n","        center_width = im_shifted.shape[2] // 2\n","        center_height = im_shifted.shape[1] // 2\n","        half_w = new_size[0] // 2\n","        half_h = new_size[1] // 2\n","        cropped_fft = im_shifted[\n","            :, center_height - half_h : center_height + half_h, center_width - half_w : center_width + half_w, :\n","        ]\n","        cropped_fft_shifted_back = np.fft.ifft2(cropped_fft, axes=(1, 2))\n","        return cropped_fft_shifted_back.real\n","    else:\n","        return images\n","\n","\n","class Pipeline:\n","    def __init__(\n","        self,\n","        preprocess_funcs: List[Callable[[npt.NDArray], npt.NDArray]],\n","        similarity_func: Callable[[npt.NDArray, npt.NDArray, SHAPE_TYPE], float],\n","    ) -> None:\n","        self.preprocess_funcs = preprocess_funcs\n","        self.similarity_func = similarity_func\n","\n","    def __call__(self, R: npt.NDArray, Rp: npt.NDArray, shape: SHAPE_TYPE) -> float:\n","        try:\n","            for preprocess_func in self.preprocess_funcs:\n","                R = preprocess_func(R)\n","                Rp = preprocess_func(Rp)\n","            return self.similarity_func(R, Rp, shape)\n","        except ValueError as e:\n","            log.info(f\"Pipeline failed: {e}\")\n","            return np.nan\n","\n","    def __str__(self) -> str:\n","        def func_name(func: Callable) -> str:\n","            return func.__name__ if not isinstance(func, functools.partial) else func.func.__name__\n","\n","        def partial_keywords(func: Callable) -> str:\n","            if not isinstance(func, functools.partial):\n","                return \"\"\n","            else:\n","                return str(func.keywords)\n","\n","        return (\n","            \"Pipeline(\"\n","            + (\n","                \"+\".join(map(func_name, self.preprocess_funcs))\n","                + \"+\"\n","                + func_name(self.similarity_func)\n","                + partial_keywords(self.similarity_func)\n","            )\n","            + \")\"\n","        )\n","\n","\n","def flatten(*args: Union[torch.Tensor, npt.NDArray], shape: SHAPE_TYPE) -> List[Union[torch.Tensor, npt.NDArray]]:\n","    if shape == \"ntd\":\n","        return list(map(flatten_nxtxd_to_ntxd, args))\n","    elif shape == \"nd\":\n","        return list(args)\n","    elif shape == \"nchw\":\n","        return list(map(flatten_nxcxhxw_to_nxchw, args))  # Flattening non-trivial for nchw\n","    else:\n","        raise ValueError(\"Unknown shape of representations. Must be one of 'ntd', 'nchw', 'nd'.\")\n","\n","\n","def flatten_nxtxd_to_ntxd(R: Union[torch.Tensor, npt.NDArray]) -> torch.Tensor:\n","    R = to_torch_if_needed(R)[0]\n","    log.debug(\"Shape before flattening: %s\", str(R.shape))\n","    R = torch.flatten(R, start_dim=0, end_dim=1)\n","    log.debug(\"Shape after flattening: %s\", str(R.shape))\n","    return R\n","\n","\n","def flatten_nxcxhxw_to_nxchw(R: Union[torch.Tensor, npt.NDArray]) -> torch.Tensor:\n","    R = to_torch_if_needed(R)[0]\n","    log.debug(\"Shape before flattening: %s\", str(R.shape))\n","    R = torch.reshape(R, (R.shape[0], -1))\n","    log.debug(\"Shape after flattening: %s\", str(R.shape))\n","    return R"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"MU_QCO_UvFKl","executionInfo":{"status":"ok","timestamp":1725402755232,"user_tz":240,"elapsed":482,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["from typing import Optional\n","from typing import Union\n","\n","import numpy as np\n","import numpy.typing as npt\n","import scipy.spatial.distance\n","import scipy.stats\n","import sklearn.metrics\n","import torch\n","# from repsim.measures.utils import flatten\n","# from repsim.measures.utils import RSMSimilarityMeasure\n","# from repsim.measures.utils import SHAPE_TYPE\n","# from repsim.measures.utils import to_numpy_if_needed\n","\n","\n","def representational_similarity_analysis(\n","    R: Union[torch.Tensor, npt.NDArray],\n","    Rp: Union[torch.Tensor, npt.NDArray],\n","    shape: SHAPE_TYPE,\n","    inner=\"correlation\",\n","    outer=\"spearman\",\n","    n_jobs: Optional[int] = None,\n",") -> float:\n","    \"\"\"Representational similarity analysis\n","\n","    Args:\n","        R (Union[torch.Tensor, npt.NDArray]): N x D representation\n","        Rp (Union[torch.Tensor, npt.NDArray]): N x D' representation\n","        inner (str, optional): inner similarity function for RSM. Must be one of\n","            scipy.spatial.distance.pdist identifiers . Defaults to \"correlation\".\n","        outer (str, optional): outer similarity function that compares RSMs. Defaults to\n","             \"spearman\". Must be one of \"spearman\", \"euclidean\"\n","\n","    Returns:\n","        float: _description_\n","    \"\"\"\n","    R, Rp = flatten(R, Rp, shape=shape)\n","    R, Rp = to_numpy_if_needed(R, Rp)\n","\n","    if inner == \"correlation\":\n","        # n_jobs only works if metric is in PAIRWISE_DISTANCES as defined in sklearn, i.e., not for correlation.\n","        # But correlation = 1 - cosine dist of row-centered data, so we use the faster cosine metric and center the data.\n","        R = R - R.mean(axis=1, keepdims=True)\n","        S = scipy.spatial.distance.squareform(  # take the lower triangle of RSM\n","            1 - sklearn.metrics.pairwise_distances(R, metric=\"cosine\", n_jobs=n_jobs),  # type:ignore\n","            checks=False,\n","        )\n","        Rp = Rp - Rp.mean(axis=1, keepdims=True)\n","        Sp = scipy.spatial.distance.squareform(\n","            1 - sklearn.metrics.pairwise_distances(Rp, metric=\"cosine\", n_jobs=n_jobs),  # type:ignore\n","            checks=False,\n","        )\n","    elif inner == \"euclidean\":\n","        # take the lower triangle of RSM\n","        S = scipy.spatial.distance.squareform(\n","            sklearn.metrics.pairwise_distances(R, metric=inner, n_jobs=n_jobs), checks=False\n","        )\n","        Sp = scipy.spatial.distance.squareform(\n","            sklearn.metrics.pairwise_distances(Rp, metric=inner, n_jobs=n_jobs), checks=False\n","        )\n","    else:\n","        raise NotImplementedError(f\"{inner=}\")\n","\n","    if outer == \"spearman\":\n","        return scipy.stats.spearmanr(S, Sp).statistic  # type:ignore\n","    elif outer == \"euclidean\":\n","        return float(np.linalg.norm(S - Sp, ord=2))\n","    else:\n","        raise ValueError(f\"Unknown outer similarity function: {outer}\")\n","\n","\n","class RSA(RSMSimilarityMeasure):\n","    def __init__(self):\n","        # choice of inner/outer in __call__ if fixed to default values, so these values are always the same\n","        super().__init__(\n","            sim_func=representational_similarity_analysis,\n","            larger_is_more_similar=True,\n","            is_metric=False,\n","            is_symmetric=True,\n","            invariant_to_affine=False,\n","            invariant_to_invertible_linear=False,\n","            invariant_to_ortho=False,\n","            invariant_to_permutation=True,\n","            invariant_to_isotropic_scaling=True,\n","            invariant_to_translation=True,\n","        )"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"LO8o8I5owA7p","executionInfo":{"status":"ok","timestamp":1725402755232,"user_tz":240,"elapsed":481,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["##################################################################################\n","# Copied from https://github.com/google/svcca/blob/1f3fbf19bd31bd9b76e728ef75842aa1d9a4cd2b/cca_core.py\n","# Copyright 2018 Google Inc.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","\"\"\"\n","The core code for applying Canonical Correlation Analysis to deep networks.\n","\n","This module contains the core functions to apply canonical correlation analysis\n","to deep neural networks. The main function is get_cca_similarity, which takes in\n","two sets of activations, typically the neurons in two layers and their outputs\n","on all of the datapoints D = [d_1,...,d_m] that have been passed through.\n","\n","Inputs have shape (num_neurons1, m), (num_neurons2, m). This can be directly\n","applied used on fully connected networks. For convolutional layers, the 3d block\n","of neurons can either be flattened entirely, along channels, or alternatively,\n","the dft_ccas (Discrete Fourier Transform) module can be used.\n","\n","See:\n","https://arxiv.org/abs/1706.05806\n","https://arxiv.org/abs/1806.05759\n","for full details.\n","\n","\"\"\"\n","import numpy as np\n","# from repsim.measures.utils import align_spatial_dimensions\n","\n","num_cca_trials = 5\n","\n","\n","def positivedef_matrix_sqrt(array):\n","    \"\"\"Stable method for computing matrix square roots, supports complex matrices.\n","\n","    Args:\n","              array: A numpy 2d array, can be complex valued that is a positive\n","                     definite symmetric (or hermitian) matrix\n","\n","    Returns:\n","              sqrtarray: The matrix square root of array\n","    \"\"\"\n","    w, v = np.linalg.eigh(array)\n","    #  A - np.dot(v, np.dot(np.diag(w), v.T))\n","    wsqrt = np.sqrt(w)\n","    sqrtarray = np.dot(v, np.dot(np.diag(wsqrt), np.conj(v).T))\n","    return sqrtarray\n","\n","\n","def remove_small(sigma_xx, sigma_xy, sigma_yx, sigma_yy, epsilon):\n","    \"\"\"Takes covariance between X, Y, and removes values of small magnitude.\n","\n","    Args:\n","              sigma_xx: 2d numpy array, variance matrix for x\n","              sigma_xy: 2d numpy array, crossvariance matrix for x,y\n","              sigma_yx: 2d numpy array, crossvariance matrixy for x,y,\n","                        (conjugate) transpose of sigma_xy\n","              sigma_yy: 2d numpy array, variance matrix for y\n","              epsilon : cutoff value for norm below which directions are thrown\n","                         away\n","\n","    Returns:\n","              sigma_xx_crop: 2d array with low x norm directions removed\n","              sigma_xy_crop: 2d array with low x and y norm directions removed\n","              sigma_yx_crop: 2d array with low x and y norm directiosn removed\n","              sigma_yy_crop: 2d array with low y norm directions removed\n","              x_idxs: indexes of sigma_xx that were removed\n","              y_idxs: indexes of sigma_yy that were removed\n","    \"\"\"\n","\n","    x_diag = np.abs(np.diagonal(sigma_xx))\n","    y_diag = np.abs(np.diagonal(sigma_yy))\n","    x_idxs = x_diag >= epsilon\n","    y_idxs = y_diag >= epsilon\n","\n","    sigma_xx_crop = sigma_xx[x_idxs][:, x_idxs]\n","    sigma_xy_crop = sigma_xy[x_idxs][:, y_idxs]\n","    sigma_yx_crop = sigma_yx[y_idxs][:, x_idxs]\n","    sigma_yy_crop = sigma_yy[y_idxs][:, y_idxs]\n","\n","    return (sigma_xx_crop, sigma_xy_crop, sigma_yx_crop, sigma_yy_crop, x_idxs, y_idxs)\n","\n","\n","def compute_ccas(sigma_xx, sigma_xy, sigma_yx, sigma_yy, epsilon, verbose=True):\n","    \"\"\"Main cca computation function, takes in variances and crossvariances.\n","\n","    This function takes in the covariances and cross covariances of X, Y,\n","    preprocesses them (removing small magnitudes) and outputs the raw results of\n","    the cca computation, including cca directions in a rotated space, and the\n","    cca correlation coefficient values.\n","\n","    Args:\n","              sigma_xx: 2d numpy array, (num_neurons_x, num_neurons_x)\n","                        variance matrix for x\n","              sigma_xy: 2d numpy array, (num_neurons_x, num_neurons_y)\n","                        crossvariance matrix for x,y\n","              sigma_yx: 2d numpy array, (num_neurons_y, num_neurons_x)\n","                        crossvariance matrix for x,y (conj) transpose of sigma_xy\n","              sigma_yy: 2d numpy array, (num_neurons_y, num_neurons_y)\n","                        variance matrix for y\n","              epsilon:  small float to help with stabilizing computations\n","              verbose:  boolean on whether to print intermediate outputs\n","\n","    Returns:\n","              [ux, sx, vx]: [numpy 2d array, numpy 1d array, numpy 2d array]\n","                            ux and vx are (conj) transposes of each other, being\n","                            the canonical directions in the X subspace.\n","                            sx is the set of canonical correlation coefficients-\n","                            how well corresponding directions in vx, Vy correlate\n","                            with each other.\n","              [uy, sy, vy]: Same as above, but for Y space\n","              invsqrt_xx:   Inverse square root of sigma_xx to transform canonical\n","                            directions back to original space\n","              invsqrt_yy:   Same as above but for sigma_yy\n","              x_idxs:       The indexes of the input sigma_xx that were pruned\n","                            by remove_small\n","              y_idxs:       Same as above but for sigma_yy\n","    \"\"\"\n","\n","    (sigma_xx, sigma_xy, sigma_yx, sigma_yy, x_idxs, y_idxs) = remove_small(\n","        sigma_xx, sigma_xy, sigma_yx, sigma_yy, epsilon\n","    )\n","\n","    numx = sigma_xx.shape[0]\n","    numy = sigma_yy.shape[0]\n","\n","    if numx == 0 or numy == 0:\n","        return (\n","            [0, 0, 0],\n","            [0, 0, 0],\n","            np.zeros_like(sigma_xx),\n","            np.zeros_like(sigma_yy),\n","            x_idxs,\n","            y_idxs,\n","        )\n","\n","    if verbose:\n","        print(\"adding eps to diagonal and taking inverse\")\n","    sigma_xx += epsilon * np.eye(numx)\n","    sigma_yy += epsilon * np.eye(numy)\n","    inv_xx = np.linalg.pinv(sigma_xx)\n","    inv_yy = np.linalg.pinv(sigma_yy)\n","\n","    if verbose:\n","        print(\"taking square root\")\n","    invsqrt_xx = positivedef_matrix_sqrt(inv_xx)\n","    invsqrt_yy = positivedef_matrix_sqrt(inv_yy)\n","\n","    if verbose:\n","        print(\"dot products...\")\n","    arr = np.dot(invsqrt_xx, np.dot(sigma_xy, invsqrt_yy))\n","\n","    if verbose:\n","        print(\"trying to take final svd\")\n","    u, s, v = np.linalg.svd(arr)\n","\n","    if verbose:\n","        print(\"computed everything!\")\n","\n","    return [u, np.abs(s), v], invsqrt_xx, invsqrt_yy, x_idxs, y_idxs\n","\n","\n","def sum_threshold(array, threshold):\n","    \"\"\"Computes threshold index of decreasing nonnegative array by summing.\n","\n","    This function takes in a decreasing array nonnegative floats, and a\n","    threshold between 0 and 1. It returns the index i at which the sum of the\n","    array up to i is threshold*total mass of the array.\n","\n","    Args:\n","              array: a 1d numpy array of decreasing, nonnegative floats\n","              threshold: a number between 0 and 1\n","\n","    Returns:\n","              i: index at which np.sum(array[:i]) >= threshold\n","    \"\"\"\n","    assert (threshold >= 0) and (threshold <= 1), \"print incorrect threshold\"\n","\n","    for i in range(len(array)):\n","        if np.sum(array[:i]) / np.sum(array) >= threshold:\n","            return i\n","\n","\n","def create_zero_dict(compute_dirns, dimension):\n","    \"\"\"Outputs a zero dict when neuron activation norms too small.\n","\n","    This function creates a return_dict with appropriately shaped zero entries\n","    when all neuron activations are very small.\n","\n","    Args:\n","              compute_dirns: boolean, whether to have zero vectors for directions\n","              dimension: int, defines shape of directions\n","\n","    Returns:\n","              return_dict: a dict of appropriately shaped zero entries\n","    \"\"\"\n","    return_dict = {}\n","    return_dict[\"mean\"] = (np.asarray(0), np.asarray(0))\n","    return_dict[\"sum\"] = (np.asarray(0), np.asarray(0))\n","    return_dict[\"cca_coef1\"] = np.asarray(0)\n","    return_dict[\"cca_coef2\"] = np.asarray(0)\n","    return_dict[\"idx1\"] = 0\n","    return_dict[\"idx2\"] = 0\n","\n","    if compute_dirns:\n","        return_dict[\"cca_dirns1\"] = np.zeros((1, dimension))\n","        return_dict[\"cca_dirns2\"] = np.zeros((1, dimension))\n","\n","    return return_dict\n","\n","\n","def get_cca_similarity(\n","    acts1,\n","    acts2,\n","    epsilon=0.0,\n","    threshold=0.98,\n","    compute_coefs=True,\n","    compute_dirns=False,\n","    verbose=True,\n","):\n","    \"\"\"The main function for computing cca similarities.\n","\n","    This function computes the cca similarity between two sets of activations,\n","    returning a dict with the cca coefficients, a few statistics of the cca\n","    coefficients, and (optionally) the actual directions.\n","\n","    Args:\n","              acts1: (num_neurons1, data_points) a 2d numpy array of neurons by\n","                     datapoints where entry (i,j) is the output of neuron i on\n","                     datapoint j.\n","              acts2: (num_neurons2, data_points) same as above, but (potentially)\n","                     for a different set of neurons. Note that acts1 and acts2\n","                     can have different numbers of neurons, but must agree on the\n","                     number of datapoints\n","\n","              epsilon: small float to help stabilize computations\n","\n","              threshold: float between 0, 1 used to get rid of trailing zeros in\n","                         the cca correlation coefficients to output more accurate\n","                         summary statistics of correlations.\n","\n","\n","              compute_coefs: boolean value determining whether coefficients\n","                             over neurons are computed. Needed for computing\n","                             directions\n","\n","              compute_dirns: boolean value determining whether actual cca\n","                             directions are computed. (For very large neurons and\n","                             datasets, may be better to compute these on the fly\n","                             instead of store in memory.)\n","\n","              verbose: Boolean, whether intermediate outputs are printed\n","\n","    Returns:\n","              return_dict: A dictionary with outputs from the cca computations.\n","                           Contains neuron coefficients (combinations of neurons\n","                           that correspond to cca directions), the cca correlation\n","                           coefficients (how well aligned directions correlate),\n","                           x and y idxs (for computing cca directions on the fly\n","                           if compute_dirns=False), and summary statistics. If\n","                           compute_dirns=True, the cca directions are also\n","                           computed.\n","    \"\"\"\n","\n","    # assert dimensionality equal\n","    assert acts1.shape[1] == acts2.shape[1], \"dimensions don't match\"\n","    # check that acts1, acts2 are transposition\n","    assert acts1.shape[0] < acts1.shape[1], \"input must be number of neurons\" \"by datapoints\"\n","    return_dict = {}\n","\n","    # compute covariance with numpy function for extra stability\n","    numx = acts1.shape[0]\n","    numy = acts2.shape[0]\n","\n","    covariance = np.cov(acts1, acts2)\n","    sigmaxx = covariance[:numx, :numx]\n","    sigmaxy = covariance[:numx, numx:]\n","    sigmayx = covariance[numx:, :numx]\n","    sigmayy = covariance[numx:, numx:]\n","\n","    # rescale covariance to make cca computation more stable\n","    xmax = np.max(np.abs(sigmaxx))\n","    ymax = np.max(np.abs(sigmayy))\n","    sigmaxx /= xmax\n","    sigmayy /= ymax\n","    sigmaxy /= np.sqrt(xmax * ymax)\n","    sigmayx /= np.sqrt(xmax * ymax)\n","\n","    ([u, s, v], invsqrt_xx, invsqrt_yy, x_idxs, y_idxs) = compute_ccas(\n","        sigmaxx, sigmaxy, sigmayx, sigmayy, epsilon=epsilon, verbose=verbose\n","    )\n","\n","    # if x_idxs or y_idxs is all false, return_dict has zero entries\n","    if (not np.any(x_idxs)) or (not np.any(y_idxs)):\n","        return create_zero_dict(compute_dirns, acts1.shape[1])\n","\n","    if compute_coefs:\n","        # also compute full coefficients over all neurons\n","        x_mask = np.dot(x_idxs.reshape((-1, 1)), x_idxs.reshape((1, -1)))\n","        y_mask = np.dot(y_idxs.reshape((-1, 1)), y_idxs.reshape((1, -1)))\n","\n","        return_dict[\"coef_x\"] = u.T\n","        return_dict[\"invsqrt_xx\"] = invsqrt_xx\n","        return_dict[\"full_coef_x\"] = np.zeros((numx, numx))\n","        np.place(return_dict[\"full_coef_x\"], x_mask, return_dict[\"coef_x\"])\n","        return_dict[\"full_invsqrt_xx\"] = np.zeros((numx, numx))\n","        np.place(return_dict[\"full_invsqrt_xx\"], x_mask, return_dict[\"invsqrt_xx\"])\n","\n","        return_dict[\"coef_y\"] = v\n","        return_dict[\"invsqrt_yy\"] = invsqrt_yy\n","        return_dict[\"full_coef_y\"] = np.zeros((numy, numy))\n","        np.place(return_dict[\"full_coef_y\"], y_mask, return_dict[\"coef_y\"])\n","        return_dict[\"full_invsqrt_yy\"] = np.zeros((numy, numy))\n","        np.place(return_dict[\"full_invsqrt_yy\"], y_mask, return_dict[\"invsqrt_yy\"])\n","\n","        # compute means\n","        neuron_means1 = np.mean(acts1, axis=1, keepdims=True)\n","        neuron_means2 = np.mean(acts2, axis=1, keepdims=True)\n","        return_dict[\"neuron_means1\"] = neuron_means1\n","        return_dict[\"neuron_means2\"] = neuron_means2\n","\n","    if compute_dirns:\n","        # orthonormal directions that are CCA directions\n","        cca_dirns1 = (\n","            np.dot(\n","                np.dot(return_dict[\"full_coef_x\"], return_dict[\"full_invsqrt_xx\"]),\n","                (acts1 - neuron_means1),\n","            )\n","            + neuron_means1\n","        )\n","        cca_dirns2 = (\n","            np.dot(\n","                np.dot(return_dict[\"full_coef_y\"], return_dict[\"full_invsqrt_yy\"]),\n","                (acts2 - neuron_means2),\n","            )\n","            + neuron_means2\n","        )\n","\n","    # get rid of trailing zeros in the cca coefficients\n","    idx1 = sum_threshold(s, threshold)\n","    idx2 = sum_threshold(s, threshold)\n","\n","    return_dict[\"cca_coef1\"] = s\n","    return_dict[\"cca_coef2\"] = s\n","    return_dict[\"x_idxs\"] = x_idxs\n","    return_dict[\"y_idxs\"] = y_idxs\n","    # summary statistics\n","    return_dict[\"mean\"] = (np.mean(s[:idx1]), np.mean(s[:idx2]))\n","    return_dict[\"sum\"] = (np.sum(s), np.sum(s))\n","\n","    if compute_dirns:\n","        return_dict[\"cca_dirns1\"] = cca_dirns1\n","        return_dict[\"cca_dirns2\"] = cca_dirns2\n","\n","    return return_dict\n","\n","\n","def robust_cca_similarity(acts1, acts2, threshold=0.98, epsilon=1e-6, compute_dirns=True):\n","    \"\"\"Calls get_cca_similarity multiple times while adding noise.\n","\n","    This function is very similar to get_cca_similarity, and can be used if\n","    get_cca_similarity doesn't converge for some pair of inputs. This function\n","    adds some noise to the activations to help convergence.\n","\n","    Args:\n","              acts1: (num_neurons1, data_points) a 2d numpy array of neurons by\n","                     datapoints where entry (i,j) is the output of neuron i on\n","                     datapoint j.\n","              acts2: (num_neurons2, data_points) same as above, but (potentially)\n","                     for a different set of neurons. Note that acts1 and acts2\n","                     can have different numbers of neurons, but must agree on the\n","                     number of datapoints\n","\n","              threshold: float between 0, 1 used to get rid of trailing zeros in\n","                         the cca correlation coefficients to output more accurate\n","                         summary statistics of correlations.\n","\n","              epsilon: small float to help stabilize computations\n","\n","              compute_dirns: boolean value determining whether actual cca\n","                             directions are computed. (For very large neurons and\n","                             datasets, may be better to compute these on the fly\n","                             instead of store in memory.)\n","\n","    Returns:\n","              return_dict: A dictionary with outputs from the cca computations.\n","                           Contains neuron coefficients (combinations of neurons\n","                           that correspond to cca directions), the cca correlation\n","                           coefficients (how well aligned directions correlate),\n","                           x and y idxs (for computing cca directions on the fly\n","                           if compute_dirns=False), and summary statistics. If\n","                           compute_dirns=True, the cca directions are also\n","                           computed.\n","    \"\"\"\n","\n","    for trial in range(num_cca_trials):\n","        try:\n","            return_dict = get_cca_similarity(acts1, acts2, threshold, compute_dirns)\n","        except np.linalg.LinAlgError:\n","            acts1 = acts1 * 1e-1 + np.random.normal(size=acts1.shape) * epsilon\n","            acts2 = acts2 * 1e-1 + np.random.normal(size=acts1.shape) * epsilon\n","            if trial + 1 == num_cca_trials:\n","                raise\n","\n","    return return_dict\n","    # End of copy from https://github.com/google/svcca/blob/1f3fbf19bd31bd9b76e728ef75842aa1d9a4cd2b/cca_core.py\n","\n","\n","def top_k_pca_comps(singular_values, threshold=0.99):\n","    total_variance = np.sum(singular_values**2)\n","    explained_variance = (singular_values**2) / total_variance\n","    cumulative_variance = np.cumsum(explained_variance)\n","    return np.argmax(cumulative_variance >= threshold * total_variance) + 1\n","\n","\n","def _svcca_original(acts1, acts2):\n","    # Copy from https://github.com/google/svcca/blob/1f3fbf19bd31bd9b76e728ef75842aa1d9a4cd2b/tutorials/001_Introduction.ipynb\n","    # Modification: get_cca_similarity is in the same file.\n","    # Modification: top-k PCA component selection s.t. explained variance > 0.99 total variance\n","    # Mean subtract activations\n","    cacts1 = acts1 - np.mean(acts1, axis=1, keepdims=True)\n","    cacts2 = acts2 - np.mean(acts2, axis=1, keepdims=True)\n","\n","    # Perform SVD\n","    U1, s1, V1 = np.linalg.svd(cacts1, full_matrices=False)\n","    U2, s2, V2 = np.linalg.svd(cacts2, full_matrices=False)\n","\n","    # top-k PCA components only\n","    k1 = top_k_pca_comps(s1)\n","    k2 = top_k_pca_comps(s2)\n","\n","    svacts1 = np.dot(s1[:k1] * np.eye(k1), V1[:k1])\n","    # can also compute as svacts1 = np.dot(U1.T[:20], cacts1)\n","    svacts2 = np.dot(s2[:k2] * np.eye(k2), V2[:k2])\n","    # can also compute as svacts1 = np.dot(U2.T[:20], cacts2)\n","\n","    svcca_results = get_cca_similarity(svacts1, svacts2, epsilon=1e-10, verbose=False)\n","    # End of copy from https://github.com/google/svcca/blob/1f3fbf19bd31bd9b76e728ef75842aa1d9a4cd2b/tutorials/001_Introduction.ipynb\n","    return np.mean(svcca_results[\"cca_coef1\"])\n","\n","\n","# Copied from https://github.com/google/svcca/blob/1f3fbf19bd31bd9b76e728ef75842aa1d9a4cd2b/pwcca.py\n","# Modification: get_cca_similarity is in the same file.\n","def compute_pwcca(acts1, acts2, epsilon=0.0):\n","    \"\"\"Computes projection weighting for weighting CCA coefficients\n","\n","    Args:\n","         acts1: 2d numpy array, shaped (neurons, num_datapoints)\n","         acts2: 2d numpy array, shaped (neurons, num_datapoints)\n","\n","    Returns:\n","         Original cca coefficient mean and weighted mean\n","\n","    \"\"\"\n","    sresults = get_cca_similarity(\n","        acts1,\n","        acts2,\n","        epsilon=epsilon,\n","        compute_dirns=False,\n","        compute_coefs=True,\n","        verbose=False,\n","    )\n","    if np.sum(sresults[\"x_idxs\"]) <= np.sum(sresults[\"y_idxs\"]):\n","        dirns = (\n","            np.dot(\n","                sresults[\"coef_x\"],\n","                (acts1[sresults[\"x_idxs\"]] - sresults[\"neuron_means1\"][sresults[\"x_idxs\"]]),\n","            )\n","            + sresults[\"neuron_means1\"][sresults[\"x_idxs\"]]\n","        )\n","        coefs = sresults[\"cca_coef1\"]\n","        acts = acts1\n","        idxs = sresults[\"x_idxs\"]\n","    else:\n","        dirns = (\n","            np.dot(\n","                sresults[\"coef_y\"],\n","                (acts1[sresults[\"y_idxs\"]] - sresults[\"neuron_means2\"][sresults[\"y_idxs\"]]),\n","            )\n","            + sresults[\"neuron_means2\"][sresults[\"y_idxs\"]]\n","        )\n","        coefs = sresults[\"cca_coef2\"]\n","        acts = acts2\n","        idxs = sresults[\"y_idxs\"]\n","    P, _ = np.linalg.qr(dirns.T)\n","    weights = np.sum(np.abs(np.dot(P.T, acts[idxs].T)), axis=1)\n","    weights = weights / np.sum(weights)\n","\n","    return np.sum(weights * coefs), weights, coefs\n","    # End of copy from https://github.com/google/svcca/blob/1f3fbf19bd31bd9b76e728ef75842aa1d9a4cd2b/pwcca.py\n","\n","\n","##################################################################################\n","\n","from typing import Union  # noqa:e402\n","\n","import numpy.typing as npt  # noqa:e402\n","import torch  # noqa:e402\n","\n","# from repsim.measures.utils import (\n","#     SHAPE_TYPE,\n","#     flatten,\n","#     resize_wh_reps,\n","#     to_numpy_if_needed,\n","#     RepresentationalSimilarityMeasure,\n","# )  # noqa:e402\n","\n","\n","def svcca(\n","    R: Union[torch.Tensor, npt.NDArray],\n","    Rp: Union[torch.Tensor, npt.NDArray],\n","    shape: SHAPE_TYPE,\n",") -> float:\n","    R, Rp = flatten(R, Rp, shape=shape)\n","    R, Rp = to_numpy_if_needed(R, Rp)\n","    return _svcca_original(R.T, Rp.T)\n","\n","\n","def pwcca(\n","    R: Union[torch.Tensor, npt.NDArray],\n","    Rp: Union[torch.Tensor, npt.NDArray],\n","    shape: SHAPE_TYPE,\n",") -> float:\n","    R, Rp = flatten(R, Rp, shape=shape)\n","    R, Rp = to_numpy_if_needed(R, Rp)\n","    return compute_pwcca(R.T, Rp.T)[0]\n","\n","\n","class SVCCA(RepresentationalSimilarityMeasure):\n","    def __init__(self):\n","        super().__init__(\n","            sim_func=svcca,\n","            larger_is_more_similar=True,\n","            is_metric=False,\n","            is_symmetric=True,\n","            invariant_to_affine=False,\n","            invariant_to_invertible_linear=False,\n","            invariant_to_ortho=True,\n","            invariant_to_permutation=True,\n","            invariant_to_isotropic_scaling=True,\n","            invariant_to_translation=True,\n","        )\n","\n","    def __call__(self, R: torch.Tensor | npt.NDArray, Rp: torch.Tensor | npt.NDArray, shape: SHAPE_TYPE) -> float:\n","        if shape == \"nchw\":\n","            # Move spatial dimensions into the sample dimension\n","            # If not the same spatial dimension, resample via FFT.\n","            R, Rp = align_spatial_dimensions(R, Rp)\n","            shape = \"nd\"\n","\n","        return self.sim_func(R, Rp, shape)\n","\n","\n","class PWCCA(RepresentationalSimilarityMeasure):\n","    def __init__(self):\n","        super().__init__(\n","            sim_func=pwcca,\n","            larger_is_more_similar=True,\n","            is_metric=False,\n","            is_symmetric=False,\n","            invariant_to_affine=False,\n","            invariant_to_invertible_linear=False,\n","            invariant_to_ortho=False,\n","            invariant_to_permutation=False,\n","            invariant_to_isotropic_scaling=True,\n","            invariant_to_translation=True,\n","        )\n","\n","    def __call__(self, R: torch.Tensor | npt.NDArray, Rp: torch.Tensor | npt.NDArray, shape: SHAPE_TYPE) -> float:\n","        if shape == \"nchw\":\n","            # Move spatial dimensions into the sample dimension\n","            # If not the same spatial dimension, resample via FFT.\n","            R, Rp = align_spatial_dimensions(R, Rp)\n","            shape = \"nd\"\n","\n","        return self.sim_func(R, Rp, shape)"]},{"cell_type":"markdown","source":["# load model"],"metadata":{"id":"L1bLtNfcMUWF"}},{"cell_type":"code","source":["import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-70m\")\n","tokenizer.pad_token = tokenizer.eos_token\n","# model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/pythia-70m\")\n","model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/pythia-70m\").to('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0,"referenced_widgets":["29837198eaba48c885f0d0e17c98d594","6292b0e54ef54ff4b15bcc57bdb0fc80","aed706b7581141398beed076ecda775c","4c6fbff637a9432aabd4d15f0a97f920","f940162a1e874dfaa0e69b105644085c","755c71f9dc34444eaaa23ac4d0893298","23eaa7d287db4a0b82601c61590f65bc","79311847c11b4f808899921c94c56b57","cc6c6680d6c342f3a58605f3b8b33ffb","9c482f7ef5964a07828f3c7b5550c9e4","c38adc5316d64c53853363c673415c04","c7e7d7d09c584adcabfc269eb0530def","0ce08e7c84ab4572a09a6ea4ff785872","d61792614f6e47bdb491d2d4c4a61571","df4a73a4c99b419f81ec986dc3eb08ae","65fe13ad82b24993a06ea6e7317f5363","d38619f7fd7a4d9c9bc400ff7ecbada5","8d1f022f7f014355adc29da45abda279","562f13f4ba6542ab80fc723431200ea0","16fdb2a8dcf24fde962e3194b36c77c4","7f7f41172fd844098e540713d53a026b","346de61707e046d3b836e4becce49d60","97324a712cb44e8ca33e4099d61ac8c2","cfb1412fd7df4e8abb99f253415f0ff2","5930649579374ea09fb50d781a42c32d","ef1a88eef29e46da96130f5a0406f8ce","3405e5eb643c4fb4bba354f05c1840c5","45c946164a824c1c8c6c04b70317aef9","53596883eb3f4250975e07e0caa78629","001f25d61d9c491dba91ec8ea1f1d5a2","75b84111b39a42319a671207947e5d28","a5bd7042f6924a9bae52f4578f2d0102","f81204c39b3944159b71525e2992d4eb","a1fadd5f5d8d486496739e2ac9c3aa50","05f9811ac3eb4497917137918b5c732d","6ea4c7cc7cc6436c9946fb51e8dd1cb8","8d6a76a7784e41e08fd5bc3b7f49fda9","5cb0bf022a7b42a5aa7383938b0da83b","6eec701494fb4e5e9d2ac8084cf3ba86","8430810db84145e68025eeefb0c8e997","c849d832667e4fc78bbf1447bdbde3c4","f6f031d050ec414a9b007374d492c7b9","2bd5126a726a4ef9ac28df3f8b2a8285","174ccc788d7842088ca2ce92acbd4533","a62ea4c1aad64c9693607e2fb1a421ed","7142a398671d47a7b2591ed5070a0d32","d5828c2d741444eeb5e409e6b03269eb","974623d3d0154493903a903540e2f1ec","259375d9e9ed4f6c98632c9b8dfe0261","d4f8f2e18053467db7a5103711d0cd4a","960a163352fc47cd99ac786c8eb222c5","f5a16480fada474591558964fb3b350e","52ba9ef59947437cb1cd013dbb2a684d","3e2b088b947249b59d7ef8431089cdd5","507e60f22aa74ebf96e0368021b76794"]},"id":"_HIrKMhshMnd","executionInfo":{"status":"ok","timestamp":1725402763085,"user_tz":240,"elapsed":8332,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"deb38819-0162-4ff8-bc53-36493c7ce6b3"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/396 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29837198eaba48c885f0d0e17c98d594"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7e7d7d09c584adcabfc269eb0530def"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97324a712cb44e8ca33e4099d61ac8c2"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/567 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1fadd5f5d8d486496739e2ac9c3aa50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/166M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a62ea4c1aad64c9693607e2fb1a421ed"}},"metadata":{}}]},{"cell_type":"code","source":["# model_2 = AutoModelForCausalLM.from_pretrained(\"EleutherAI/pythia-160m\")\n","model_2 = AutoModelForCausalLM.from_pretrained(\"EleutherAI/pythia-160m\").to('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0,"referenced_widgets":["03091eae7ba743ac8d77bcd80dba7bb5","bb03fe5d200c4295863bbef6ed666c23","b851f3320146489ba38497a62e5328b9","78fa68f7e59c43b9883251d74b6a5d62","bb064152e6834627ac50f148a728fa25","5efa58a8bdaf4a67b7f529dfadd0b533","b72f45234fc44ecb8a99523f1725a0b0","30f8087e6747403a9d966daadee3f3f2","546d741c440b4d8c8b828850ce4d7f11","d2d9d6c053b64c0b9ad88bf8f2f05217","c3b82d333615425f95826a7d508b2363","1e400851f2c54757b440d5713513a259","d3d4f5ba55da406f879500c407a9e6af","f35dae51f5694659a8a87d32fba45c0c","4651a695dd7c47a1ac0972cd8f56fd1a","358891ea0cb44e9184cf2f06356f7b96","64cfbcdd8fa4495e92a7bf58b1dd233b","ec1e9eafd4774df9b66da947738f825d","131cd9677280496aa281d74baeb94107","97cce94b8c684b198be7c4c50d939fa3","1d08bffd0d3f421bad116624e327040c","80d637b1258b4911a5b20df5dfce3748"]},"id":"ekf0nxvD413W","executionInfo":{"status":"ok","timestamp":1725402766508,"user_tz":240,"elapsed":3639,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"422b4de2-db33-4577-f8db-99bbb0f4da98"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/569 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03091eae7ba743ac8d77bcd80dba7bb5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/375M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e400851f2c54757b440d5713513a259"}},"metadata":{}}]},{"cell_type":"code","source":["layer_id = 2"],"metadata":{"id":"p7xURcuSWMWI","executionInfo":{"status":"ok","timestamp":1725402766509,"user_tz":240,"elapsed":41,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["# get data"],"metadata":{"id":"p5ellF9eWuO7"}},{"cell_type":"code","source":["%%capture\n","!pip install datasets"],"metadata":{"id":"X8JUvtRDVGtG","executionInfo":{"status":"ok","timestamp":1725402768146,"user_tz":240,"elapsed":1677,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","execution_count":14,"metadata":{"id":"evaS0FH3N7O4","colab":{"base_uri":"https://localhost:8080/","height":170,"referenced_widgets":["35805c1abe3845a79b7f748ad3d490b1","4adbd227eef94162b8f007f930ba031b","6940c91600554a0daa2c4fdfda41dd6a","f802364c6f44430392ebeab19b0cc6aa","66059e869bcd47e1a63df626e22aa143","04fed2c304b24a31abf261bd41e4af5b","b749fa026b9c485d93146ea28253bda3","daed1cb8e35b458c8cd70d70e5a729fd","34f97b3510f74864885fa2d0b8be1c53","53bef488334e44c4b478c0f9e5c6123c","0b90b6f00d4b4aff90c762a6ba03089a","688e3387137c4823ab5c13a2a94e1fb0","5e0d08be3a3845649d964aba110a7dc1","da3463dd631f446c80db31e00fd3ec52","825c40805c7b41b5a3c327bb891b8a3c","d80ff5fa09724b87b16b78c748dc4fd8","eabcf425456e4cfeafb1554faa927f6f","3d157560a491463d9bb691b661f8fa9b","0cb3c9b7a85143428df2874bed536639","f7c2b3c42e2940308deb0d6f205598fb","d42e7ba9db9c420e977636065fde5951","057892a6e4d947639a26f08990f0cb79"]},"executionInfo":{"status":"ok","timestamp":1725402775810,"user_tz":240,"elapsed":7676,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"88992258-f8f8-4de3-c0d1-e14e950cd1bb"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/2.73k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35805c1abe3845a79b7f748ad3d490b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading readme:   0%|          | 0.00/7.35k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"688e3387137c4823ab5c13a2a94e1fb0"}},"metadata":{}},{"name":"stdout","output_type":"stream","text":["The repository for Skylion007/openwebtext contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/Skylion007/openwebtext.\n","You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n","\n","Do you wish to run the custom code? [y/N] y\n"]}],"source":["from datasets import load_dataset\n","dataset = load_dataset(\"Skylion007/openwebtext\", split=\"train\", streaming=True)\n","dataset_iter = iter(dataset)"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"dJEy0N4yTtI6","executionInfo":{"status":"ok","timestamp":1725402775810,"user_tz":240,"elapsed":342,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["def get_next_batch(dataset_iter, batch_size=100):\n","    batch = []\n","    for _ in range(batch_size):\n","        try:\n","            sample = next(dataset_iter)\n","            batch.append(sample['text'])\n","        except StopIteration:\n","            break\n","    return batch"]},{"cell_type":"markdown","metadata":{"id":"BDOowypRDotz"},"source":["# load sae weights"]},{"cell_type":"code","source":["name = \"EleutherAI/sae-pythia-70m-32k\"\n","i = 2\n","hookpoint = \"layers.\" + str(i)\n","decoder=True\n","\n","repo_path = Path(\n","            snapshot_download(\n","                name,\n","                allow_patterns=f\"{hookpoint}/*\" if hookpoint is not None else None,\n","                # allow_patterns = None\n","            )\n","        )\n","if hookpoint is not None:\n","    repo_path = repo_path / hookpoint\n","path = Path(repo_path)\n","cfg_dict = {\"expansion_factor\": 32, \"normalize_decoder\": True, \"num_latents\": 32768, \"k\": 16, \"d_in\": 512}\n","d_in = cfg_dict.pop(\"d_in\")\n","cfg = SaeConfig(**cfg_dict)\n","\n","sae = Sae(d_in, cfg, device=device, decoder=decoder)\n","\n","load_model(\n","    model=sae,\n","    filename=str(path / \"sae.safetensors\"),\n","    device=str(device),\n","    strict=decoder,\n",")\n","\n","# weight_matrix_np = sae.W_dec.cpu().detach().numpy()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0,"referenced_widgets":["fbe1a7caccf74609a9b0c56a90fe81bc","bfdf0fa98ea345b6b11372c39ba1d09d","8e8c9f4eae0948728ada05d1961bf3e3","07b543665170418d9d47bc496f2b30cc","22224628a66d4ef7af5a1ced1428623d","2c1efac036314e4cabaa8a82c2760c66","72e5697cb62b413db3a27cbf22d77dcc","36be0ef6250f42bc9226675b655b7da8","9119bc86b4f848e3932b709bde5c530d","968e404326464f708a40c58543dfc284","a33556e0a11f4600b1785773a652cb27","e7c4453beff64fa8971a58d459867440","359a2e9e420e450bb80b5cea533505fa","3bce6d9a310b495ca805dc1e39e58bbc","180aea270f5543e7b1e69c4f9e89f9de","430276854f0b4f95bafa6342d2d8546a","a28b4cd7354a4cd1860d064bd0d76282","050ecee2d8b94eb7a4f5c0763bc22ca7","3dc2f2a4f077486b9d7f6dd3596a5b64","e0e15ae5796d4a5f8b6970be81c1018f","3a221b9127184046bab7126334209093","30ed304d5dc84ffa93bfb8c802b626a2","53329d6965cd4dcc83214af5237671b8","1a98913f6c604f1192667399f088dec9","802e3576b5d34ea1b3fe1b76ab8afed2","5fe1ae2c14594f27a96b2309096b95cf","f7273d801fd34e56b26f3a138f00a42e","1543b0c7df9f4aad8b2a1f9871202d9d","1e9a35e342a6408fb8275c592d28965c","a723945c5c7c411381e9797a536801a0","9c3cb670fed346d6b863709fc3566835","3f9f03e0561b4883a0f6e7c15266a45c","1fedcfc7bd8648ff85314efda2ac74ba"]},"id":"uKhIIoiOMuw1","executionInfo":{"status":"ok","timestamp":1725402777298,"user_tz":240,"elapsed":1830,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3d79b0f8-c9df-4e53-ca97-d271596a7f02"},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":["Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbe1a7caccf74609a9b0c56a90fe81bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["layers.2/cfg.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7c4453beff64fa8971a58d459867440"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["sae.safetensors:   0%|          | 0.00/134M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53329d6965cd4dcc83214af5237671b8"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["(set(), [])"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["name = \"EleutherAI/sae-pythia-160m-32k\"\n","decoder=True\n","hookpoint = \"layers.\" + str(i)\n","\n","repo_path = Path(\n","            snapshot_download(\n","                name,\n","                allow_patterns=f\"{hookpoint}/*\" if hookpoint is not None else None,\n","                # allow_patterns = None\n","            )\n","        )\n","if hookpoint is not None:\n","    repo_path = repo_path / hookpoint\n","path = Path(repo_path)\n","cfg_dict = {\"expansion_factor\": 32, \"normalize_decoder\": True, \"num_latents\": 32768, \"k\": 16, \"d_in\": 768}\n","d_in = cfg_dict.pop(\"d_in\")\n","cfg = SaeConfig(**cfg_dict)\n","\n","sae_2 = Sae(d_in, cfg, device=device, decoder=decoder)\n","\n","load_model(\n","    model=sae_2,\n","    filename=str(path / \"sae.safetensors\"),\n","    device=str(device),\n","    strict=decoder,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0,"referenced_widgets":["17d0bc149e91433eacf646707914699b","544cd2a387084c1baa2afc81965f6cb3","1486cc52529347e688213c1c9b1750d5","07aba03b859d40d4886d22b3f8e9c36c","6d1051dd43fa4275871a4a7edee02205","b8aebca09bff4f67b5fd28fc9d412842","576bfddfe40c463cb3df34b9089f8a89","18d3e639ef5949c18648cd106d6de257","6f177e92585b47f4ad8345027afb288c","575af99d732d4cf78ec7aa9ae5843d8f","34b6791108f14787a4db8d75182b762b","3471262d2a9041718a2896630c3f58d1","f67df43ab9474fdba784518da326ecfa","a4be450ae0ac408c8d9e79dfe9344ec5","5d4104a4dfa14f4698c74171bac66ded","25f3f75b0b9545efa56d00a5a7ea956c","abee9d3c2bf34eef886a080e529423f1","b14fcdf9ed07461f8ea4c90bb87f8bea","ce41a2cd9c3e4ffb9287c4291cf4cafd","a1256913dd6f4eb1b07a1631dd9789d7","0f176e4aef4c49edbcf91310bfd6e80d","d708cd332a214e68baa0018171c58062","98c58de8b2524d88a91d39d6b1b2127d","654ec12d4193462eb830cab79cfe3245","ba38df95643a4141a1f0ce33f325eb26","c0e64c9881544ef18c263c04dde0a0af","a960e494e7224771a304a220875804bd","927db426b36f4d33a4dbc8370711860b","fc6e444ee0cc4a3a827d4f79a36e94e2","891ff3c845194a61b363b38a323838dc","c23e07c3b27b408da0514ff94cf760cf","92760a3b51f84566845295f388a06dde","4482272dd6804d6cb0159deec575d371"]},"id":"EsRFCzhQ6SVC","executionInfo":{"status":"ok","timestamp":1725402779939,"user_tz":240,"elapsed":2668,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"326e45ea-826f-49bf-87cf-cef320ceaee8"},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":["Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17d0bc149e91433eacf646707914699b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["layers.2/cfg.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3471262d2a9041718a2896630c3f58d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["sae.safetensors:   0%|          | 0.00/201M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98c58de8b2524d88a91d39d6b1b2127d"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["(set(), [])"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["# get sae actvs"],"metadata":{"id":"I39lHkhTNZeJ"}},{"cell_type":"code","source":["accumulated_outputs = None\n","batch_size = 100\n","maxseqlen = 300\n","\n","# Loop through the entire dataset in batches\n","# while True:\n","for i in range(1):\n","    batch = get_next_batch(dataset_iter, batch_size)\n","    if not batch:\n","        break  # Stop if there are no more batches\n","\n","    # Tokenize the batch and move to the device\n","    inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=maxseqlen)\n","    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n","\n","    with torch.inference_mode():\n","        outputs = model(**inputs, output_hidden_states=True)\n","        if accumulated_outputs is None:\n","            accumulated_outputs = outputs.hidden_states[layer_id]\n","        else:\n","            accumulated_outputs = torch.cat((accumulated_outputs, outputs.hidden_states[layer_id]), dim= 0)\n","\n","    # Clear memory to prevent OOM\n","    del inputs, outputs\n","    torch.cuda.empty_cache()  # Only if you're using CUDA\n","    gc.collect()"],"metadata":{"id":"8FbduLi5SLjE","executionInfo":{"status":"ok","timestamp":1725399086190,"user_tz":240,"elapsed":1087,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["accumulated_outputs.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5VQyVT8OzMuy","executionInfo":{"status":"ok","timestamp":1725399096916,"user_tz":240,"elapsed":12,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"6e7adc45-d816-4ebf-ad76-18d615e27332"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([100, 300, 512])"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["with torch.inference_mode():\n","    feature_acts_model_A = sae.pre_acts(accumulated_outputs)"],"metadata":{"id":"xuykfSH8NWAI","executionInfo":{"status":"ok","timestamp":1725399124921,"user_tz":240,"elapsed":401,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["first_dim_reshaped = feature_acts_model_A.shape[0] * feature_acts_model_A.shape[1]\n","reshaped_activations_A = feature_acts_model_A.reshape(first_dim_reshaped, feature_acts_model_A.shape[-1]).cpu()\n","del feature_acts_model_A\n","del accumulated_outputs\n","torch.cuda.empty_cache()"],"metadata":{"id":"nd4_A466NrlD","executionInfo":{"status":"ok","timestamp":1725399129365,"user_tz":240,"elapsed":2892,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":["# get sae 2 actvs"],"metadata":{"id":"gDVXVUn05iSU"}},{"cell_type":"code","source":["from datasets import load_dataset\n","dataset = load_dataset(\"Skylion007/openwebtext\", split=\"train\", streaming=True)\n","dataset_iter = iter(dataset)"],"metadata":{"id":"SE0tLrwZ7Cgs","executionInfo":{"status":"ok","timestamp":1725399135059,"user_tz":240,"elapsed":4949,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["layer_id"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H-V7QirTvnKO","executionInfo":{"status":"ok","timestamp":1725399135063,"user_tz":240,"elapsed":44,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ee7f61cd-ced8-40be-8543-aa5423a7713c"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["accumulated_outputs = None\n","batch_size = 100\n","maxseqlen = 300\n","\n","# Loop through the entire dataset in batches\n","# while True:\n","for i in range(1):\n","    batch = get_next_batch(dataset_iter, batch_size)\n","    if not batch:\n","        break  # Stop if there are no more batches\n","\n","    # Tokenize the batch and move to the device\n","    inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=maxseqlen)\n","    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n","\n","    with torch.inference_mode():\n","        outputs = model_2(**inputs, output_hidden_states=True)\n","        if accumulated_outputs is None:\n","            accumulated_outputs = outputs.hidden_states[layer_id]\n","        else:\n","            accumulated_outputs = torch.cat((accumulated_outputs, outputs.hidden_states[layer_id]), dim= 0)\n","\n","    # Clear memory to prevent OOM\n","    del inputs, outputs\n","    torch.cuda.empty_cache()  # Only if you're using CUDA\n","    gc.collect()"],"metadata":{"id":"5SRLGONB5iSe","executionInfo":{"status":"ok","timestamp":1725399136684,"user_tz":240,"elapsed":1662,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["with torch.inference_mode():\n","    reshaped_activations_B = sae_2.pre_acts(accumulated_outputs)"],"metadata":{"id":"0UHM3Rk45iSf","executionInfo":{"status":"ok","timestamp":1725399136692,"user_tz":240,"elapsed":17,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["first_dim_reshaped = reshaped_activations_B.shape[0] * reshaped_activations_B.shape[1]\n","reshaped_activations_B = reshaped_activations_B.reshape(first_dim_reshaped, reshaped_activations_B.shape[-1]).cpu()\n","# del feature_acts_model_A\n","del accumulated_outputs\n","torch.cuda.empty_cache()"],"metadata":{"id":"vSIBCyzM5iSf","executionInfo":{"status":"ok","timestamp":1725399139020,"user_tz":240,"elapsed":2344,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":["# find how many cols of tensor are all 0"],"metadata":{"id":"wlPc0hFnse7X"}},{"cell_type":"code","source":["import numpy as np\n","\n","def count_zero_columns(tensor):\n","    # Check if all elements in each column are zero\n","    zero_columns = np.all(tensor == 0, axis=0)\n","    # Count True values in the zero_columns array\n","    zero_cols_indices = np.where(zero_columns)[0]\n","    return np.sum(zero_columns), zero_cols_indices\n","\n","# Count zero columns\n","zero_cols_count, zero_cols_indices = count_zero_columns(reshaped_activations_A.cpu().numpy())\n","print(\"Number of zero columns:\", zero_cols_count), zero_cols_indices"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PBKmyBdJsfsd","executionInfo":{"status":"ok","timestamp":1725396718457,"user_tz":240,"elapsed":897,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"02ddb879-e97c-475f-a5e0-fee0a5a76410"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of zero columns: 5647\n"]},{"output_type":"execute_result","data":{"text/plain":["(None, array([    0,     1,     6, ..., 32747, 32754, 32761]))"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["len(reshaped_activations_A[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0FdgZsMasnuu","executionInfo":{"status":"ok","timestamp":1725384803085,"user_tz":240,"elapsed":9,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a7585c3f-d615-4a96-af0b-99309c515756"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["32768"]},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","source":["# CORR fn- normalize in batches"],"metadata":{"id":"QL5KfPhOOfNW"}},{"cell_type":"code","source":["def normalize_byChunks(actv_tensor, chunk_size=10000): # chunk_size: Number of rows per chunk\n","    mean_A = actv_tensor.mean(dim=0, keepdim=True)\n","    std_A = actv_tensor.std(dim=0, keepdim=True)\n","\n","    num_chunks = actv_tensor.shape[0] // chunk_size\n","\n","    normalized_A = np.zeros_like(actv_tensor.cpu())  # Preallocate the normalized matrix\n","    # normalized_A = actv_tensor.new_zeros(actv_tensor.size())\n","\n","    for i in range(num_chunks):\n","        # print (i, num_chunks)\n","        start_index = i * chunk_size\n","        end_index = start_index + chunk_size\n","        chunk = actv_tensor[start_index:end_index]\n","        normalized_A[start_index:end_index] = (chunk - mean_A) / (std_A + 1e-8)\n","\n","    # Handle any remaining rows if the data size is not perfectly divisible by chunk_size\n","    if actv_tensor.shape[0] % chunk_size != 0:\n","        start_index = num_chunks * chunk_size\n","        chunk = actv_tensor[start_index:]\n","        normalized_A[start_index:] = (chunk - mean_A) / (std_A + 1e-8)\n","\n","    return torch.tensor(normalized_A)"],"metadata":{"id":"N6J62SaiQ0vQ","executionInfo":{"status":"ok","timestamp":1725399144051,"user_tz":240,"elapsed":522,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["def batched_correlation(reshaped_activations_A, reshaped_activations_B, batch_size=100):\n","    # Ensure tensors are on GPU\n","    # if torch.cuda.is_available():\n","    #     reshaped_activations_A = reshaped_activations_A.to('cuda')\n","    #     reshaped_activations_B = reshaped_activations_B.to('cuda')\n","\n","    normalized_A = normalize_byChunks(reshaped_activations_A, chunk_size=10000)\n","    normalized_B = normalize_byChunks(reshaped_activations_B, chunk_size=10000)\n","\n","    if torch.cuda.is_available():\n","        normalized_A = normalized_A.to('cuda')\n","        normalized_B = normalized_B.to('cuda')\n","\n","    num_batches = (normalized_B.shape[1] + batch_size - 1) // batch_size\n","    max_values = []\n","    max_indices = []\n","\n","    for batch in range(num_batches):\n","        start = batch * batch_size\n","        if start % 5000 == 0:\n","            print(start)\n","        end = min(start + batch_size, normalized_B.shape[1])\n","\n","        batch_corr_matrix = torch.matmul(normalized_A.t(), normalized_B[:, start:end]) / normalized_A.shape[0]\n","        max_val, max_idx = batch_corr_matrix.max(dim=0)\n","        max_values.append(max_val)\n","        max_indices.append(max_idx)  # Adjust indices for the batch offset\n","\n","        del batch_corr_matrix\n","        torch.cuda.empty_cache()\n","\n","    # return torch.cat(max_indices), torch.cat(max_values)\n","    return torch.cat(max_indices).cpu().numpy(), torch.cat(max_values).cpu().numpy()"],"metadata":{"id":"-S-sMkjTPK_J","executionInfo":{"status":"ok","timestamp":1725399146635,"user_tz":240,"elapsed":446,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["inds, vals = batched_correlation(reshaped_activations_A, reshaped_activations_B)"],"metadata":{"id":"u0vgcG6xjfXS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725399171661,"user_tz":240,"elapsed":21951,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d580e88f-c783-4377-aabb-f74dca53c354"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","5000\n","10000\n","15000\n","20000\n","25000\n","30000\n"]}]},{"cell_type":"code","source":["num_unq_pairs = len(list(set(inds.tolist())))\n","print(\"% unique: \", num_unq_pairs / len(inds))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725399171662,"user_tz":240,"elapsed":30,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f5211d51-2b41-4270-9f61-f30b0800b5b4","id":"-XrrrS9mmUl-"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["% unique:  0.20245361328125\n"]}]},{"cell_type":"code","source":["inds"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SmTLTHB079aF","executionInfo":{"status":"ok","timestamp":1725399171662,"user_tz":240,"elapsed":29,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3f1ac618-259b-490c-c26e-e4e7bc7f3b4d"},"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([16024,  9848, 15044, ..., 13767,  2049, 20511])"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["sum(vals) / len(vals)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725399171662,"user_tz":240,"elapsed":27,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"949481b2-851a-4fc1-f337-e2391b3c2c3d","id":"oSPt2gMXmUl_"},"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.26922327984738104"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["vals"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CMyeAOQs81Zd","executionInfo":{"status":"ok","timestamp":1725396710360,"user_tz":240,"elapsed":558,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e4d586d4-078d-407d-c9ff-0893ab73988b"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.09855709, 0.2184115 , 0.37436447, ..., 0.3204564 , 0.46035522,\n","       0.45258734], dtype=float32)"]},"metadata":{},"execution_count":38}]},{"cell_type":"markdown","source":["# save corrs"],"metadata":{"id":"noIC7fkP7oqF"}},{"cell_type":"code","source":[],"metadata":{"id":"XsoORgNo7qbV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# old corr fn"],"metadata":{"id":"2jY7w9Hnq9z7"}},{"cell_type":"code","source":["def batched_correlation(reshaped_activations_A, reshaped_activations_B, batch_size=100):\n","    # Ensure tensors are on GPU\n","    if torch.cuda.is_available():\n","        reshaped_activations_A = reshaped_activations_A.to('cuda')\n","        reshaped_activations_B = reshaped_activations_B.to('cuda')\n","\n","    # Normalize columns of A\n","    mean_A = reshaped_activations_A.mean(dim=0, keepdim=True)\n","    std_A = reshaped_activations_A.std(dim=0, keepdim=True)\n","    normalized_A = (reshaped_activations_A - mean_A) / (std_A + 1e-8)  # Avoid division by zero\n","\n","    # Normalize columns of B\n","    mean_B = reshaped_activations_B.mean(dim=0, keepdim=True)\n","    std_B = reshaped_activations_B.std(dim=0, keepdim=True)\n","    normalized_B = (reshaped_activations_B - mean_B) / (std_B + 1e-8)  # Avoid division by zero\n","\n","    num_batches = (normalized_B.shape[1] + batch_size - 1) // batch_size\n","    max_values = []\n","    max_indices = []\n","\n","    for batch in range(num_batches):\n","        start = batch * batch_size\n","        end = min(start + batch_size, normalized_B.shape[1])\n","        batch_corr_matrix = torch.matmul(normalized_A.t(), normalized_B[:, start:end]) / normalized_A.shape[0]\n","        max_val, max_idx = batch_corr_matrix.max(dim=0)\n","        max_values.append(max_val)\n","        # max_indices.append(max_idx + start)  # Adjust indices for the batch offset\n","        max_indices.append(max_idx)  # Adjust indices for the batch offset\n","\n","        del batch_corr_matrix\n","        torch.cuda.empty_cache()\n","\n","    return torch.cat(max_indices), torch.cat(max_values)"],"metadata":{"id":"-gNiXZwvq-ws","executionInfo":{"status":"ok","timestamp":1725397978235,"user_tz":240,"elapsed":422,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":75,"outputs":[]},{"cell_type":"code","execution_count":44,"metadata":{"id":"ATEVgois5XHb","executionInfo":{"status":"ok","timestamp":1725397012998,"user_tz":240,"elapsed":6725,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["highest_correlations_indices_AB, highest_correlations_values_AB = batched_correlation(reshaped_activations_A, reshaped_activations_B)\n","highest_correlations_indices_AB = highest_correlations_indices_AB.detach().cpu().numpy()\n","highest_correlations_values_AB = highest_correlations_values_AB.detach().cpu().numpy()"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1725397012998,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":240},"id":"1rRyG85M59j2","outputId":"8572e556-d382-450b-9f08-03bf866b50af"},"outputs":[{"output_type":"stream","name":"stdout","text":["6635\n"]},{"output_type":"execute_result","data":{"text/plain":["0.202484130859375"]},"metadata":{},"execution_count":45}],"source":["num_unq_pairs = len(list(set(highest_correlations_indices_AB)))\n","print(num_unq_pairs)\n","num_unq_pairs / len(highest_correlations_indices_AB)"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1725397012998,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":240},"id":"wF1AQkJi50GX","outputId":"fb98c4f5-f636-45aa-d02e-cd9c7b695f9b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.26922327968713944"]},"metadata":{},"execution_count":46}],"source":["sum(highest_correlations_values_AB) / len(highest_correlations_values_AB)"]},{"cell_type":"markdown","source":["# old data construction code"],"metadata":{"id":"u7a36gaJr5_e"}},{"cell_type":"markdown","source":["## make data"],"metadata":{"id":"6-B-I9EHsAhn"}},{"cell_type":"code","execution_count":65,"metadata":{"id":"fOkujtWFPXIj","executionInfo":{"status":"ok","timestamp":1725397912877,"user_tz":240,"elapsed":2984,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["from datasets import load_dataset\n","dataset = load_dataset(\"Skylion007/openwebtext\", split=\"train\", streaming=True)"]},{"cell_type":"code","execution_count":66,"metadata":{"id":"30z1aF3MPfBz","executionInfo":{"status":"ok","timestamp":1725397912877,"user_tz":240,"elapsed":21,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["# Function to get next batch\n","def get_next_batch(dataset_iter, batch_size=100):\n","    batch = []\n","    for _ in range(batch_size):\n","        try:\n","            sample = next(dataset_iter)\n","            batch.append(sample['text'])\n","        except StopIteration:\n","            break\n","    return batch\n","\n","# Get a batch of 100 samples\n","dataset_iter = iter(dataset)\n","batch = get_next_batch(dataset_iter)\n","\n","# Tokenize the batch\n","inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=300)"]},{"cell_type":"code","execution_count":67,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1725397912877,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":240},"id":"ZkoaYrAFK3Ts","outputId":"d529ba11-de8d-4894-caf9-0e2bb6110369"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([100, 300])"]},"metadata":{},"execution_count":67}],"source":["inputs['input_ids'].shape  # (batchnum, maxseqlen)"]},{"cell_type":"markdown","source":["## get sae actvs"],"metadata":{"id":"cv7I8bdJss8K"}},{"cell_type":"code","source":["i=2"],"metadata":{"id":"ktfkrd_ivNsa","executionInfo":{"status":"ok","timestamp":1725398055412,"user_tz":240,"elapsed":404,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":80,"outputs":[]},{"cell_type":"code","source":["with torch.inference_mode():\n","    # inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}  # Move inputs to GPU\n","    outputs = model(**inputs, output_hidden_states=True)\n","    hidden_state_2 = outputs.hidden_states[i].to(\"cuda\")\n","    feature_acts_model_A = sae.pre_acts(hidden_state_2)"],"metadata":{"id":"8e9IbZMAtpnd","executionInfo":{"status":"ok","timestamp":1725398065512,"user_tz":240,"elapsed":7560,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":81,"outputs":[]},{"cell_type":"code","source":["first_dim_reshaped = feature_acts_model_A.shape[0] * feature_acts_model_A.shape[1]\n","reshaped_activations_A = feature_acts_model_A.reshape(first_dim_reshaped, feature_acts_model_A.shape[-1]).cpu()\n","del feature_acts_model_A\n","del outputs\n","torch.cuda.empty_cache()"],"metadata":{"id":"0FNMoDaOti66","executionInfo":{"status":"ok","timestamp":1725398068216,"user_tz":240,"elapsed":2713,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":82,"outputs":[]},{"cell_type":"code","source":["with torch.inference_mode():\n","    # inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}  # Move inputs to GPU\n","    outputs = model_2(**inputs, output_hidden_states=True)\n","    hidden_state_2 = outputs.hidden_states[i].to(\"cuda\")\n","    feature_acts_model_B = sae_2.pre_acts(hidden_state_2)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1725398085227,"user_tz":240,"elapsed":17030,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"UImU1uSmst-x"},"execution_count":83,"outputs":[]},{"cell_type":"code","source":["first_dim_reshaped = feature_acts_model_B.shape[0] * feature_acts_model_B.shape[1]\n","reshaped_activations_B = feature_acts_model_B.reshape(first_dim_reshaped, feature_acts_model_B.shape[-1]).cpu()\n","del feature_acts_model_B\n","del outputs\n","torch.cuda.empty_cache()"],"metadata":{"executionInfo":{"status":"ok","timestamp":1725398088282,"user_tz":240,"elapsed":3065,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"ct3hL-zOst-_"},"execution_count":84,"outputs":[]},{"cell_type":"markdown","source":["## get corrs"],"metadata":{"id":"QKmd10a6t0xz"}},{"cell_type":"code","execution_count":85,"metadata":{"executionInfo":{"status":"ok","timestamp":1725398094965,"user_tz":240,"elapsed":6711,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"ZDapEeamt1-Z"},"outputs":[],"source":["highest_correlations_indices_AB, highest_correlations_values_AB = batched_correlation(reshaped_activations_A, reshaped_activations_B)\n","highest_correlations_indices_AB = highest_correlations_indices_AB.detach().cpu().numpy()\n","highest_correlations_values_AB = highest_correlations_values_AB.detach().cpu().numpy()"]},{"cell_type":"code","execution_count":86,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46,"status":"ok","timestamp":1725398094966,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":240},"outputId":"25d3ef8a-c957-4bfd-9ed4-5b9b33ddaba8","id":"cThoOA7Lt1-a"},"outputs":[{"output_type":"stream","name":"stdout","text":["7646\n"]},{"output_type":"execute_result","data":{"text/plain":["0.23333740234375"]},"metadata":{},"execution_count":86}],"source":["num_unq_pairs = len(list(set(highest_correlations_indices_AB)))\n","print(num_unq_pairs)\n","num_unq_pairs / len(highest_correlations_indices_AB)"]},{"cell_type":"code","execution_count":87,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44,"status":"ok","timestamp":1725398094966,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":240},"outputId":"899d5d6f-d1fa-4231-d16e-85e41caac3d2","id":"g_mTshYLt1-a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.695116701542247"]},"metadata":{},"execution_count":87}],"source":["sum(highest_correlations_values_AB) / len(highest_correlations_values_AB)"]},{"cell_type":"markdown","source":["## use new corr fn on old data constr"],"metadata":{"id":"Nq_4RmJbv7OU"}},{"cell_type":"code","source":["def normalize_byChunks(actv_tensor, chunk_size=10000): # chunk_size: Number of rows per chunk\n","    mean_A = actv_tensor.mean(dim=0, keepdim=True)\n","    std_A = actv_tensor.std(dim=0, keepdim=True)\n","\n","    num_chunks = actv_tensor.shape[0] // chunk_size\n","\n","    normalized_A = np.zeros_like(actv_tensor.cpu())  # Preallocate the normalized matrix\n","    # normalized_A = actv_tensor.new_zeros(actv_tensor.size())\n","\n","    for i in range(num_chunks):\n","        # print (i, num_chunks)\n","        start_index = i * chunk_size\n","        end_index = start_index + chunk_size\n","        chunk = actv_tensor[start_index:end_index]\n","        normalized_A[start_index:end_index] = (chunk - mean_A) / (std_A + 1e-8)\n","\n","    # Handle any remaining rows if the data size is not perfectly divisible by chunk_size\n","    if actv_tensor.shape[0] % chunk_size != 0:\n","        start_index = num_chunks * chunk_size\n","        chunk = actv_tensor[start_index:]\n","        normalized_A[start_index:] = (chunk - mean_A) / (std_A + 1e-8)\n","\n","    return torch.tensor(normalized_A)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1725398249910,"user_tz":240,"elapsed":2043,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"FhJfJu3dv9qR"},"execution_count":89,"outputs":[]},{"cell_type":"code","source":["def batched_correlation(reshaped_activations_A, reshaped_activations_B, batch_size=100):\n","    # Ensure tensors are on GPU\n","    # if torch.cuda.is_available():\n","    #     reshaped_activations_A = reshaped_activations_A.to('cuda')\n","    #     reshaped_activations_B = reshaped_activations_B.to('cuda')\n","\n","    normalized_A = normalize_byChunks(reshaped_activations_A, chunk_size=10000)\n","    normalized_B = normalize_byChunks(reshaped_activations_B, chunk_size=10000)\n","\n","    if torch.cuda.is_available():\n","        normalized_A = normalized_A.to('cuda')\n","        normalized_B = normalized_B.to('cuda')\n","\n","    num_batches = (normalized_B.shape[1] + batch_size - 1) // batch_size\n","    max_values = []\n","    max_indices = []\n","\n","    for batch in range(num_batches):\n","        start = batch * batch_size\n","        if start % 5000 == 0:\n","            print(start)\n","        end = min(start + batch_size, normalized_B.shape[1])\n","\n","        batch_corr_matrix = torch.matmul(normalized_A.t(), normalized_B[:, start:end]) / normalized_A.shape[0]\n","        max_val, max_idx = batch_corr_matrix.max(dim=0)\n","        max_values.append(max_val)\n","        max_indices.append(max_idx)  # Adjust indices for the batch offset\n","\n","        del batch_corr_matrix\n","        torch.cuda.empty_cache()\n","\n","    # return torch.cat(max_indices), torch.cat(max_values)\n","    return torch.cat(max_indices).cpu().numpy(), torch.cat(max_values).cpu().numpy()"],"metadata":{"executionInfo":{"status":"ok","timestamp":1725398250891,"user_tz":240,"elapsed":16,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"RQD9phw_v9qb"},"execution_count":90,"outputs":[]},{"cell_type":"code","source":["inds, vals = batched_correlation(reshaped_activations_A, reshaped_activations_B)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725398275574,"user_tz":240,"elapsed":21889,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"99307478-5701-4364-be78-9e6fa2f25271","id":"obR2GOKOv9qb"},"execution_count":91,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","5000\n","10000\n","15000\n","20000\n","25000\n","30000\n"]}]},{"cell_type":"code","source":["num_unq_pairs = len(list(set(inds.tolist())))\n","print(\"% unique: \", num_unq_pairs / len(inds))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725398279218,"user_tz":240,"elapsed":619,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"93d9a6a4-3d98-4e20-e13a-09c65f0429ed","id":"qcDjbth_v9qb"},"execution_count":92,"outputs":[{"output_type":"stream","name":"stdout","text":["% unique:  0.23333740234375\n"]}]},{"cell_type":"code","source":["inds"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725398280852,"user_tz":240,"elapsed":13,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c056d3bc-f05d-4f9e-9581-5b61c167181d","id":"9kTCHUl0v9qc"},"execution_count":93,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 3391,  2604, 29157, ..., 17032, 16703,  7760])"]},"metadata":{},"execution_count":93}]},{"cell_type":"code","source":["sum(vals) / len(vals)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725398282584,"user_tz":240,"elapsed":14,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"1a9c0388-285e-43a1-f0b9-ae4b715596a5","id":"Mo2qDgNQv9qc"},"execution_count":94,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6951167039323991"]},"metadata":{},"execution_count":94}]},{"cell_type":"markdown","source":["# new run model actvs in batches- 300"],"metadata":{"id":"Nz6-IO9WwO8l"}},{"cell_type":"markdown","source":["## make data"],"metadata":{"id":"1bzdKyTrwWoO"}},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"status":"ok","timestamp":1725402781175,"user_tz":240,"elapsed":1252,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"dYayzWaFwWoZ"},"outputs":[],"source":["from datasets import load_dataset\n","dataset = load_dataset(\"Skylion007/openwebtext\", split=\"train\", streaming=True)"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"status":"ok","timestamp":1725402782345,"user_tz":240,"elapsed":1185,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"Me9LYWVgwWoa"},"outputs":[],"source":["batch_size = 300\n","\n","def get_next_batch(dataset_iter, batch_size=100):\n","    batch = []\n","    for _ in range(batch_size):\n","        try:\n","            sample = next(dataset_iter)\n","            batch.append(sample['text'])\n","        except StopIteration:\n","            break\n","    return batch\n","\n","# Get a batch of 100 samples\n","dataset_iter = iter(dataset)\n","batch = get_next_batch(dataset_iter, batch_size)\n","\n","# Tokenize the batch\n","inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=300)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1725402782345,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":240},"outputId":"dc924186-7c1a-4f63-c9ce-da80985dce8b","id":"SM8gzmupwWoa"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([300, 300])"]},"metadata":{},"execution_count":20}],"source":["inputs['input_ids'].shape  # (batchnum, maxseqlen)"]},{"cell_type":"code","source":["inputs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0FLBV_o91P8v","executionInfo":{"status":"ok","timestamp":1725402782345,"user_tz":240,"elapsed":25,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d72baa69-0dd1-4d06-f28f-dae269a157c7"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([[11688,    14,  1952,  ...,   253,   760,  7345],\n","        [28292, 14385,   273,  ...,    84,   417,  2590],\n","        [  510, 11626,  4469,  ...,   253,  3127,   296],\n","        ...,\n","        [   49, 33236,    27,  ...,  8452,   588,  3513],\n","        [  510,  2926,   273,  ...,     0,     0,     0],\n","        [ 1276,   310,   253,  ...,   275,   436, 12082]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        ...,\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 1, 1, 1]])}"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["## get sae actvs"],"metadata":{"id":"QjtpPY-nwWoa"}},{"cell_type":"code","source":["i=2"],"metadata":{"executionInfo":{"status":"ok","timestamp":1725402782345,"user_tz":240,"elapsed":24,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"2oJurcC2wWob"},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# accumulated_outputs = None\n","# batch_size = 100\n","# maxseqlen = 300\n","\n","# # Loop through the entire dataset in batches\n","# # while True:\n","# for batch_id in range(1):\n","#     # batch = get_next_batch(dataset_iter, batch_size)\n","#     # if not batch:\n","#     #     break  # Stop if there are no more batches\n","\n","#     start = batch_id * batch_size\n","#     end = min(start + batch_size, inputs['input_ids'].shape[0])\n","#     # curr_inputs = inputs['input_ids'][start:end].to(model.device)\n","#     # inputs = {k: v.to(model.device) for k, v in inputs.items()}\n","\n","#     with torch.inference_mode():\n","#         # outputs = model(**inputs, output_hidden_states=True)\n","#         outputs = model(**curr_inputs, output_hidden_states=True)\n","#         if accumulated_outputs is None:\n","#             accumulated_outputs = outputs.hidden_states[layer_id]\n","#         else:\n","#             accumulated_outputs = torch.cat((accumulated_outputs, outputs.hidden_states[layer_id]), dim= 0)\n","\n","#     # Clear memory to prevent OOM\n","#     del inputs, outputs\n","#     torch.cuda.empty_cache()  # Only if you're using CUDA\n","#     gc.collect()"],"metadata":{"id":"M5tOBTdQ0atX","executionInfo":{"status":"ok","timestamp":1725402782981,"user_tz":240,"elapsed":659,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader, TensorDataset\n","\n","accumulated_outputs = None\n","batch_size = 100\n","maxseqlen = 300\n","\n","# Assuming 'inputs' is your input dictionary with 'input_ids' and 'attention_mask'\n","dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'])\n","loader = DataLoader(dataset, batch_size=16, shuffle=False)  # Adjust batch_size based on your memory constraints\n","\n","all_hidden_states = []\n","for batch in loader:\n","    input_ids, attention_mask = batch\n","\n","    # Prepare inputs for the model\n","    batch_inputs = {'input_ids': input_ids.to(model.device), 'attention_mask': attention_mask.to(model.device)}\n","    # Forward pass, set output_hidden_states to True to get hidden states\n","    with torch.no_grad():  # Disable gradient calculation for memory efficiency\n","        outputs = model(**batch_inputs, output_hidden_states=True)\n","        if accumulated_outputs is None:\n","            accumulated_outputs = outputs.hidden_states[layer_id]\n","        else:\n","            accumulated_outputs = torch.cat((accumulated_outputs, outputs.hidden_states[layer_id]), dim= 0)\n","\n","    # Clear memory to prevent OOM\n","    del batch_inputs, outputs\n","    torch.cuda.empty_cache()  # Only if you're using CUDA\n","    gc.collect()\n"],"metadata":{"id":"7Blh7UxQ0dXI","executionInfo":{"status":"ok","timestamp":1725402786983,"user_tz":240,"elapsed":4019,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["with torch.inference_mode():\n","    feature_acts_model_A = sae.pre_acts(accumulated_outputs)"],"metadata":{"id":"9pSGnHwG2OVj","executionInfo":{"status":"ok","timestamp":1725402786983,"user_tz":240,"elapsed":28,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# with torch.inference_mode():\n","#     inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}  # Move inputs to GPU\n","#     outputs = model(**inputs, output_hidden_states=True)\n","#     hidden_state_2 = outputs.hidden_states[i].to(\"cuda\")\n","#     feature_acts_model_A = sae.pre_acts(hidden_state_2)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1725402786984,"user_tz":240,"elapsed":28,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"gdEq0udXwWob"},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["first_dim_reshaped = feature_acts_model_A.shape[0] * feature_acts_model_A.shape[1]\n","reshaped_activations_A = feature_acts_model_A.reshape(first_dim_reshaped, feature_acts_model_A.shape[-1]).cpu()\n","del feature_acts_model_A\n","del accumulated_outputs\n","torch.cuda.empty_cache()"],"metadata":{"executionInfo":{"status":"ok","timestamp":1725402796128,"user_tz":240,"elapsed":9171,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"psDEeb25wWob"},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader, TensorDataset\n","\n","accumulated_outputs = None\n","batch_size = 100\n","maxseqlen = 300\n","\n","# Assuming 'inputs' is your input dictionary with 'input_ids' and 'attention_mask'\n","dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'])\n","loader = DataLoader(dataset, batch_size=16, shuffle=False)  # Adjust batch_size based on your memory constraints\n","\n","all_hidden_states = []\n","for batch in loader:\n","    input_ids, attention_mask = batch\n","\n","    # Prepare inputs for the model\n","    batch_inputs = {'input_ids': input_ids.to(model.device), 'attention_mask': attention_mask.to(model.device)}\n","    # Forward pass, set output_hidden_states to True to get hidden states\n","    with torch.no_grad():  # Disable gradient calculation for memory efficiency\n","        outputs = model_2(**batch_inputs, output_hidden_states=True)\n","        if accumulated_outputs is None:\n","            accumulated_outputs = outputs.hidden_states[layer_id]\n","        else:\n","            accumulated_outputs = torch.cat((accumulated_outputs, outputs.hidden_states[layer_id]), dim= 0)\n","\n","    # Clear memory to prevent OOM\n","    del batch_inputs, outputs\n","    torch.cuda.empty_cache()  # Only if you're using CUDA\n","    gc.collect()\n"],"metadata":{"id":"S2vXhVex2WiH","executionInfo":{"status":"ok","timestamp":1725402799512,"user_tz":240,"elapsed":3406,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["with torch.inference_mode():\n","    feature_acts_model_B = sae_2.pre_acts(accumulated_outputs)"],"metadata":{"id":"96XEH7rn2i6F","executionInfo":{"status":"ok","timestamp":1725402799512,"user_tz":240,"elapsed":21,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["# with torch.inference_mode():\n","#     inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}  # Move inputs to GPU\n","#     outputs = model_2(**inputs, output_hidden_states=True)\n","#     hidden_state_2 = outputs.hidden_states[i].to(\"cuda\")\n","#     feature_acts_model_B = sae_2.pre_acts(hidden_state_2)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1725402799512,"user_tz":240,"elapsed":20,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"ODBzSjc-wWob"},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["first_dim_reshaped = feature_acts_model_B.shape[0] * feature_acts_model_B.shape[1]\n","reshaped_activations_B = feature_acts_model_B.reshape(first_dim_reshaped, feature_acts_model_B.shape[-1]).cpu()\n","del feature_acts_model_B\n","del accumulated_outputs\n","torch.cuda.empty_cache()"],"metadata":{"executionInfo":{"status":"ok","timestamp":1725402808177,"user_tz":240,"elapsed":8685,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"M2UcbrTQwWob"},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["## use new corr fn on old data constr"],"metadata":{"id":"kHh2nLvywWoc"}},{"cell_type":"code","source":["def normalize_byChunks(actv_tensor, chunk_size=10000): # chunk_size: Number of rows per chunk\n","    mean_A = actv_tensor.mean(dim=0, keepdim=True)\n","    std_A = actv_tensor.std(dim=0, keepdim=True)\n","\n","    num_chunks = actv_tensor.shape[0] // chunk_size\n","\n","    normalized_A = np.zeros_like(actv_tensor.cpu())  # Preallocate the normalized matrix\n","    # normalized_A = actv_tensor.new_zeros(actv_tensor.size())\n","\n","    for i in range(num_chunks):\n","        # print (i, num_chunks)\n","        start_index = i * chunk_size\n","        end_index = start_index + chunk_size\n","        chunk = actv_tensor[start_index:end_index]\n","        normalized_A[start_index:end_index] = (chunk - mean_A) / (std_A + 1e-8)\n","\n","    # Handle any remaining rows if the data size is not perfectly divisible by chunk_size\n","    if actv_tensor.shape[0] % chunk_size != 0:\n","        start_index = num_chunks * chunk_size\n","        chunk = actv_tensor[start_index:]\n","        normalized_A[start_index:] = (chunk - mean_A) / (std_A + 1e-8)\n","\n","    return torch.tensor(normalized_A)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1725402808177,"user_tz":240,"elapsed":29,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"q4qYql6xwWoc"},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["def batched_correlation(reshaped_activations_A, reshaped_activations_B, batch_size=100):\n","    # Ensure tensors are on GPU\n","    # if torch.cuda.is_available():\n","    #     reshaped_activations_A = reshaped_activations_A.to('cuda')\n","    #     reshaped_activations_B = reshaped_activations_B.to('cuda')\n","\n","    normalized_A = normalize_byChunks(reshaped_activations_A, chunk_size=10000)\n","    normalized_B = normalize_byChunks(reshaped_activations_B, chunk_size=10000)\n","\n","    if torch.cuda.is_available():\n","        normalized_A = normalized_A.to('cuda')\n","        normalized_B = normalized_B.to('cuda')\n","\n","    num_batches = (normalized_B.shape[1] + batch_size - 1) // batch_size\n","    max_values = []\n","    max_indices = []\n","\n","    for batch in range(num_batches):\n","        start = batch * batch_size\n","        if start % 5000 == 0:\n","            print(start)\n","        end = min(start + batch_size, normalized_B.shape[1])\n","\n","        batch_corr_matrix = torch.matmul(normalized_A.t(), normalized_B[:, start:end]) / normalized_A.shape[0]\n","        max_val, max_idx = batch_corr_matrix.max(dim=0)\n","        max_values.append(max_val)\n","        max_indices.append(max_idx)  # Adjust indices for the batch offset\n","\n","        del batch_corr_matrix\n","        torch.cuda.empty_cache()\n","\n","    # return torch.cat(max_indices), torch.cat(max_values)\n","    return torch.cat(max_indices).cpu().numpy(), torch.cat(max_values).cpu().numpy()"],"metadata":{"executionInfo":{"status":"ok","timestamp":1725402808177,"user_tz":240,"elapsed":28,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"NQ9VzLLUwWoc"},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["inds, vals = batched_correlation(reshaped_activations_A, reshaped_activations_B)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725402871573,"user_tz":240,"elapsed":63425,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"4379a72b-42af-4515-daea-3255a8f976e2","id":"prsnMg7xwWoc"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","5000\n","10000\n","15000\n","20000\n","25000\n","30000\n"]}]},{"cell_type":"code","source":["num_unq_pairs = len(list(set(inds.tolist())))\n","print(\"% unique: \", num_unq_pairs / len(inds))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725402871574,"user_tz":240,"elapsed":328,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ed5d5cf4-2a5e-4f07-ba6f-5b697a7d79ed","id":"kMOqUsbOwWoc"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["% unique:  0.288116455078125\n"]}]},{"cell_type":"code","source":["sum(vals) / len(vals)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725402871574,"user_tz":240,"elapsed":326,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"1c9be76b-25e1-42b5-c0c8-43e51c94cf30","id":"_4BZZh5bwWod"},"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6520237068427832"]},"metadata":{},"execution_count":36}]},{"cell_type":"markdown","source":["## sim metrics"],"metadata":{"id":"8-3a7uPL9BFp"}},{"cell_type":"code","source":["weight_matrix = sae.W_dec.cpu().detach().numpy()\n","weight_matrix_2 = sae_2.W_dec.cpu().detach().numpy()"],"metadata":{"id":"Aay4Svqq9CJN","executionInfo":{"status":"ok","timestamp":1725402871574,"user_tz":240,"elapsed":324,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["svcca(weight_matrix[inds], weight_matrix_2, \"nd\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xSyyf5bd9kfa","executionInfo":{"status":"ok","timestamp":1725402880612,"user_tz":240,"elapsed":9361,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"8e5cd593-4ecb-49ef-8b3e-6451f3b54b97"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.01169722531881733"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["svcca(weight_matrix, weight_matrix_2, \"nd\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G2VW0mgR9bbj","executionInfo":{"status":"ok","timestamp":1725402890133,"user_tz":240,"elapsed":9536,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9d7c34e3-1c32-459a-d374-534042764265"},"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.004165474019166399"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["score_rand(len(weight_matrix), svcca, shapereq_bool=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gabRslsl_jF_","executionInfo":{"status":"ok","timestamp":1725402942680,"user_tz":240,"elapsed":52564,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b6061b3a-9637-4bcc-945e-506fde2e2f83"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["0.006178370737369772\n"]},{"output_type":"execute_result","data":{"text/plain":["0.006178370737369772"]},"metadata":{},"execution_count":40}]},{"cell_type":"markdown","source":["## 1-1 only"],"metadata":{"id":"tkYxsIN49vot"}},{"cell_type":"code","source":["uniq_corr_indices_AB_forB = []\n","uniq_corr_indices_AB_forA = []\n","unq_vals = []\n","seen = set()\n","\n","# Iterate through each index, checking membership in the set\n","for ind_B, ind_A in enumerate(inds.tolist()):\n","    if ind_A not in seen:\n","        seen.add(ind_A)\n","        uniq_corr_indices_AB_forA.append(ind_A)\n","        uniq_corr_indices_AB_forB.append(ind_B)\n","        unq_vals.append(vals[ind_B])"],"metadata":{"id":"W20mKPrX-U-b","executionInfo":{"status":"ok","timestamp":1725404776225,"user_tz":240,"elapsed":410,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":95,"outputs":[]},{"cell_type":"code","source":["len(list(set(uniq_corr_indices_AB_forA)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725404080994,"user_tz":240,"elapsed":1087,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b2201a15-d9c5-4ba4-b722-7b59e3285c68","id":"WslG6GLXGLgy"},"execution_count":76,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9441"]},"metadata":{},"execution_count":76}]},{"cell_type":"code","source":["len(list(set(uniq_corr_indices_AB_forB)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725404080994,"user_tz":240,"elapsed":18,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b730e700-f5d9-49ad-cdff-e5dcd8c21872","id":"HdazdlfMGLgz"},"execution_count":77,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9441"]},"metadata":{},"execution_count":77}]},{"cell_type":"code","source":["unq_vals = [val for val in vals[uniq_corr_indices_AB_forB]]"],"metadata":{"executionInfo":{"status":"ok","timestamp":1725404782382,"user_tz":240,"elapsed":598,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"tcGQXR7zI4-f"},"execution_count":96,"outputs":[]},{"cell_type":"code","source":["len(vals[uniq_corr_indices_AB_forB])"],"metadata":{"executionInfo":{"status":"ok","timestamp":1725404785759,"user_tz":240,"elapsed":11,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e0f02224-9bdc-410e-d946-4fc52c8ecc2e","colab":{"base_uri":"https://localhost:8080/"},"id":"3Op11OWvI4-r"},"execution_count":97,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9441"]},"metadata":{},"execution_count":97}]},{"cell_type":"code","source":["sum(unq_vals) / len(unq_vals)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-zTGacrFI7fZ","executionInfo":{"status":"ok","timestamp":1725404794713,"user_tz":240,"elapsed":562,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3e4f35db-0094-4d64-a94c-150bfe80d074"},"execution_count":98,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6145634546231988"]},"metadata":{},"execution_count":98}]},{"cell_type":"code","source":["svcca(weight_matrix[uniq_corr_indices_AB_forA], weight_matrix_2[uniq_corr_indices_AB_forB], \"nd\")"],"metadata":{"id":"1SSbiUsH90SL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725402944708,"user_tz":240,"elapsed":2043,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"81ecc90d-c4af-4911-8195-4ae450d66cb7"},"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4634880654009297"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["score_rand(len(uniq_corr_indices_AB_forA), svcca, shapereq_bool=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uAlDZThr4UP6","executionInfo":{"status":"ok","timestamp":1725402956179,"user_tz":240,"elapsed":11700,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"88daeee4-94d4-42c5-fda7-fd1cae48148c"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["0.009152381922018334\n"]},{"output_type":"execute_result","data":{"text/plain":["0.009152381922018334"]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","source":["### rmv all corr < 0.9"],"metadata":{"id":"dUNX46zAGTbC"}},{"cell_type":"code","source":["new_highest_correlations_indices_A = []\n","new_highest_correlations_indices_B = []\n","new_highest_correlations_values = []\n","\n","ind_B = 0\n","for ind_A, val in zip(uniq_corr_indices_AB_forA, unq_vals):\n","    if val > 0.9:\n","        new_highest_correlations_indices_A.append(ind_A)\n","        new_highest_correlations_indices_B.append(ind_B)\n","        new_highest_correlations_values.append(val)\n","    ind_B += 1"],"metadata":{"executionInfo":{"status":"ok","timestamp":1725404195718,"user_tz":240,"elapsed":398,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"VC29SBdGGZ4v"},"execution_count":79,"outputs":[]},{"cell_type":"code","source":["len(list(set(new_highest_correlations_indices_A)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725404219638,"user_tz":240,"elapsed":840,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"29861c73-7329-43a9-e6a0-5da70e6831c6","id":"H5va9wwnGt9l"},"execution_count":80,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1518"]},"metadata":{},"execution_count":80}]},{"cell_type":"code","source":["len(list(set(new_highest_correlations_indices_B)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725404220556,"user_tz":240,"elapsed":13,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e1a3ada8-b2c6-4911-d2e3-b25aad307e86","id":"HgJlRPf1Gt9m"},"execution_count":81,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1518"]},"metadata":{},"execution_count":81}]},{"cell_type":"code","source":["svcca_paired_above0_9 = svcca(weight_matrix[(new_highest_correlations_indices_A)], weight_matrix_2[new_highest_correlations_indices_B, :], \"nd\")\n","svcca_paired_above0_9"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725404227245,"user_tz":240,"elapsed":1853,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b76ae4de-b0ee-415a-d294-b738034939f3","id":"5QZf94cFGZ45"},"execution_count":82,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.06163555361747941"]},"metadata":{},"execution_count":82}]},{"cell_type":"code","source":["score_rand(len(new_highest_correlations_indices_A), svcca, shapereq_bool=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9cvJSMDyHF6W","executionInfo":{"status":"ok","timestamp":1725404341569,"user_tz":240,"elapsed":5239,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"dfd70708-7854-446d-dc8e-756d035649d2"},"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["0.019683541964734957\n"]},{"output_type":"execute_result","data":{"text/plain":["0.019683541964734957"]},"metadata":{},"execution_count":83}]},{"cell_type":"markdown","source":["## remove all corr feats less than 0.9"],"metadata":{"id":"zQ7a7IQJIz0m"}},{"cell_type":"code","source":["new_highest_correlations_indices_A = []\n","new_highest_correlations_indices_B = []\n","new_highest_correlations_values = []\n","\n","ind_B = 0\n","for ind_A, val in zip(inds, vals):\n","    if val > 0.9:\n","        new_highest_correlations_indices_A.append(ind_A)\n","        new_highest_correlations_indices_B.append(ind_B)\n","        new_highest_correlations_values.append(val)\n","    ind_B += 1"],"metadata":{"id":"BWkGo4TqIz0m","executionInfo":{"status":"ok","timestamp":1725403837178,"user_tz":240,"elapsed":457,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":67,"outputs":[]},{"cell_type":"code","source":["len(new_highest_correlations_indices_A)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725403320169,"user_tz":240,"elapsed":595,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"98c3ad1e-4363-48d3-bc35-65541a088058","id":"1pdYPESTIz0m"},"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6209"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["len(list(set(new_highest_correlations_indices_A)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725403331483,"user_tz":240,"elapsed":14,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"6a3ba239-8a27-476f-fd48-258e3e2efb55","id":"7-uk1jhQIz0n"},"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2859"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["len(list(set(new_highest_correlations_indices_B)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725403338799,"user_tz":240,"elapsed":880,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"7e36a705-ea2d-4238-f91b-3e3a42fb5245","id":"pIhpk6VIIz0n"},"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6209"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["svcca_paired_above0_9 = svcca(weight_matrix[(new_highest_correlations_indices_A)], weight_matrix_2[new_highest_correlations_indices_B, :], \"nd\")\n","svcca_paired_above0_9"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vo3A-2sVmGPK","executionInfo":{"status":"ok","timestamp":1725403370988,"user_tz":240,"elapsed":3107,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"aef1dc4e-15ed-41f1-f913-d4f97fb31189"},"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.15484215962563724"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["# unpaired\n","svcca_unpaired_above0_9 = svcca(weight_matrix[:len(new_highest_correlations_indices_A)], weight_matrix_2[:len(new_highest_correlations_indices_B)], \"nd\")\n","svcca_unpaired_above0_9"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725403400791,"user_tz":240,"elapsed":4324,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f2349640-a5a8-4a40-fe59-d0aa3f589207","id":"hZZss4CiIz0n"},"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.006822617983190428"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["# unpaired with after shuffling (same as above, just checking)\n","svcca(weight_matrix[:len(new_highest_correlations_indices_A)], weight_matrix_2[new_highest_correlations_indices_B, :], \"nd\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725403425928,"user_tz":240,"elapsed":2494,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c50347d4-7f9f-45ac-ad40-920c5b1a3ac6","id":"VBi12E6KIz0n"},"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.026999738130632504"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["score_rand(len(new_highest_correlations_indices_A), svcca, shapereq_bool=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MVdDeNQHD2iV","executionInfo":{"status":"ok","timestamp":1725403475407,"user_tz":240,"elapsed":11040,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3a28925a-f1dd-4077-9b5f-6c2c8a0d55e6"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["0.005161848614763211\n"]},{"output_type":"execute_result","data":{"text/plain":["0.005161848614763211"]},"metadata":{},"execution_count":55}]},{"cell_type":"markdown","source":["### 1-1 only"],"metadata":{"id":"yZRquYkbFQrF"}},{"cell_type":"code","source":["uniq_corr_indices_AB_forB = []\n","uniq_corr_indices_AB_forA = []\n","seen = set()\n","\n","# Iterate through each index, checking membership in the set\n","for ind_B, ind_A in enumerate(new_highest_correlations_indices_A):\n","    if ind_A not in seen:\n","        seen.add(ind_A)\n","        uniq_corr_indices_AB_forA.append(ind_A)\n","        uniq_corr_indices_AB_forB.append(ind_B)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1725403844696,"user_tz":240,"elapsed":633,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"TqzKyOIMFQrN"},"execution_count":68,"outputs":[]},{"cell_type":"code","source":["len(uniq_corr_indices_AB_forA)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NYBNkIIXFspk","executionInfo":{"status":"ok","timestamp":1725403944107,"user_tz":240,"elapsed":451,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"26d6baee-e267-4610-ff50-758ffb91e04e"},"execution_count":71,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2859"]},"metadata":{},"execution_count":71}]},{"cell_type":"code","source":["svcca(weight_matrix[uniq_corr_indices_AB_forA], weight_matrix_2[uniq_corr_indices_AB_forB], \"nd\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725403846081,"user_tz":240,"elapsed":614,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"7ce44adf-660c-4738-e14b-7256ad4f82f1","id":"Bee-gX7CFQrO"},"execution_count":69,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.012181013941657428"]},"metadata":{},"execution_count":69}]},{"cell_type":"code","source":["score_rand(len(uniq_corr_indices_AB_forA), svcca, shapereq_bool=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725403961669,"user_tz":240,"elapsed":5590,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b84d82b3-1525-45b6-964d-17b859207bc0","id":"QCEyxJFVFQrO"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["0.017364046266596433\n"]},{"output_type":"execute_result","data":{"text/plain":["0.017364046266596433"]},"metadata":{},"execution_count":72}]},{"cell_type":"markdown","source":["## remove all corr feats < 0.5"],"metadata":{"id":"5ghzSTDEEiQs"}},{"cell_type":"code","source":["new_highest_correlations_indices_A = []\n","new_highest_correlations_indices_B = []\n","new_highest_correlations_values = []\n","\n","ind_B = 0\n","for ind_A, val in zip(inds, vals):\n","    if val > 0.5:\n","        new_highest_correlations_indices_A.append(ind_A)\n","        new_highest_correlations_indices_B.append(ind_B)\n","        new_highest_correlations_values.append(val)\n","    ind_B += 1"],"metadata":{"executionInfo":{"status":"ok","timestamp":1725403654001,"user_tz":240,"elapsed":1656,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"x7HyEwnwEiQ7"},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["len(new_highest_correlations_indices_A)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725403654610,"user_tz":240,"elapsed":21,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e9691119-1d63-4563-f7d2-f244a1a335b5","id":"F2p6ZXmwEiQ8"},"execution_count":57,"outputs":[{"output_type":"execute_result","data":{"text/plain":["23151"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["len(list(set(new_highest_correlations_indices_A)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725403654610,"user_tz":240,"elapsed":19,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e2595ad9-a472-47a2-b1ea-60ce96fd3935","id":"croNSIlAEiQ8"},"execution_count":58,"outputs":[{"output_type":"execute_result","data":{"text/plain":["7324"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["len(list(set(new_highest_correlations_indices_B)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725403654610,"user_tz":240,"elapsed":19,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"00674def-eb24-428c-9b37-41e8655c5258","id":"F1xozjtTEiQ9"},"execution_count":59,"outputs":[{"output_type":"execute_result","data":{"text/plain":["23151"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["svcca_paired_above0_9 = svcca(weight_matrix[(new_highest_correlations_indices_A)], weight_matrix_2[new_highest_correlations_indices_B, :], \"nd\")\n","svcca_paired_above0_9"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725403659878,"user_tz":240,"elapsed":5286,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"1e55dce7-ddc1-468c-d169-cd57c768051c","id":"eDOfNX9NEiQ9"},"execution_count":60,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.04546068606691216"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","source":["# unpaired\n","svcca_unpaired_above0_9 = svcca(weight_matrix[:len(new_highest_correlations_indices_A)], weight_matrix_2[:len(new_highest_correlations_indices_B)], \"nd\")\n","svcca_unpaired_above0_9"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725403667081,"user_tz":240,"elapsed":7431,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"5a2cc6ad-1fa8-47f8-c3e7-a8f0970597b9","id":"b39kVc7tEiQ9"},"execution_count":61,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.002858210921672675"]},"metadata":{},"execution_count":61}]},{"cell_type":"code","source":["# unpaired with after shuffling (same as above, just checking)\n","svcca(weight_matrix[:len(new_highest_correlations_indices_A)], weight_matrix_2[new_highest_correlations_indices_B, :], \"nd\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725403672773,"user_tz":240,"elapsed":5924,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"075fb75c-026e-4e52-8a4c-0bd5ae26208e","id":"dV8ikjOlEiQ-"},"execution_count":62,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0012687584293675372"]},"metadata":{},"execution_count":62}]},{"cell_type":"code","source":["score_rand(len(new_highest_correlations_indices_A), svcca, shapereq_bool=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725403705218,"user_tz":240,"elapsed":32682,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"86fd7e10-534d-4cb7-fc3a-5e2cd13aeb27","id":"LxMEOaF5EiQ-"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["0.005308828398388607\n"]},{"output_type":"execute_result","data":{"text/plain":["0.005308828398388607"]},"metadata":{},"execution_count":63}]},{"cell_type":"markdown","source":["## 1-1 only"],"metadata":{"id":"FexPQGlcE1et"}},{"cell_type":"code","source":["uniq_corr_indices_AB_forB = []\n","uniq_corr_indices_AB_forA = []\n","seen = set()\n","\n","# Iterate through each index, checking membership in the set\n","for ind_B, ind_A in enumerate(new_highest_correlations_indices_A):\n","    if ind_A not in seen:\n","        seen.add(ind_A)\n","        uniq_corr_indices_AB_forA.append(ind_A)\n","        uniq_corr_indices_AB_forB.append(ind_B)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1725403764279,"user_tz":240,"elapsed":994,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"m35SJ_qcE1e1"},"execution_count":64,"outputs":[]},{"cell_type":"code","source":["svcca(weight_matrix[uniq_corr_indices_AB_forA], weight_matrix_2[uniq_corr_indices_AB_forB], \"nd\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725403766453,"user_tz":240,"elapsed":571,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"4f7ad895-4a87-43bc-c5a5-e720a8d0124a","id":"bmjPQZnsE1e1"},"execution_count":65,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.013236344709283936"]},"metadata":{},"execution_count":65}]},{"cell_type":"code","source":["score_rand(len(uniq_corr_indices_AB_forA), svcca, shapereq_bool=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725403780259,"user_tz":240,"elapsed":13815,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"59adcf2e-4f11-49a7-ceee-74abcbea5299","id":"uWa0C1KvE1e1"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["0.007050140073373184\n"]},{"output_type":"execute_result","data":{"text/plain":["0.007050140073373184"]},"metadata":{},"execution_count":66}]},{"cell_type":"markdown","source":["## 1-1, 2nd occur"],"metadata":{"id":"j5bPQ9igID_g"}},{"cell_type":"code","source":["uniq_corr_indices_AB_forB = []\n","uniq_corr_indices_AB_forA = []\n","seen_counts = {}\n","\n","# Iterate through each index, checking membership in the set\n","for ind_B, ind_A in enumerate(inds):\n","    # Update count for each element\n","    if ind_A in seen_counts:\n","        seen_counts[ind_A] += 1\n","    else:\n","        seen_counts[ind_A] = 1\n","\n","    # Add the element when it is seen the second time\n","    if seen_counts[ind_A] == 2:\n","        uniq_corr_indices_AB_forA.append(ind_A)\n","        uniq_corr_indices_AB_forB.append(ind_B)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1725404592012,"user_tz":240,"elapsed":602,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"O3NxWfMdHdvU"},"execution_count":87,"outputs":[]},{"cell_type":"code","source":["len(list(set(uniq_corr_indices_AB_forA)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725404594548,"user_tz":240,"elapsed":11,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"791a65b7-1805-48fd-e486-f957866896fb","id":"fxwaoE-6Hdvb"},"execution_count":88,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5703"]},"metadata":{},"execution_count":88}]},{"cell_type":"code","source":["len(list(set(uniq_corr_indices_AB_forB)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725404598190,"user_tz":240,"elapsed":1223,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"4a7bf122-83ad-4c2e-f445-3b147b267fbb","id":"CUd_J6FsHdvb"},"execution_count":89,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5703"]},"metadata":{},"execution_count":89}]},{"cell_type":"code","source":["unq_vals = [val for val in vals[uniq_corr_indices_AB_forB]]"],"metadata":{"id":"c2RMxYFZIl44","executionInfo":{"status":"ok","timestamp":1725404725457,"user_tz":240,"elapsed":644,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":92,"outputs":[]},{"cell_type":"code","source":["len(vals[uniq_corr_indices_AB_forB])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KNZFkFaoI0BG","executionInfo":{"status":"ok","timestamp":1725404762670,"user_tz":240,"elapsed":1118,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3d1fbf28-5090-4cc3-838a-9ce5ec779f51"},"execution_count":94,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5703"]},"metadata":{},"execution_count":94}]},{"cell_type":"code","source":["sum(unq_vals) / len(unq_vals)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qfFHxrQ5Is-T","executionInfo":{"status":"ok","timestamp":1725404735912,"user_tz":240,"elapsed":615,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"01fa9df8-d182-42d1-f58c-49dec239b1d8"},"execution_count":93,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6224459478628023"]},"metadata":{},"execution_count":93}]},{"cell_type":"code","source":["svcca(weight_matrix[uniq_corr_indices_AB_forA], weight_matrix_2[uniq_corr_indices_AB_forB], \"nd\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725404601865,"user_tz":240,"elapsed":893,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0c8df0b8-9e14-4ef9-c31d-2d3719f1aafd","id":"ScammASoHdvb"},"execution_count":90,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.37902361924584577"]},"metadata":{},"execution_count":90}]},{"cell_type":"code","source":["score_rand(len(uniq_corr_indices_AB_forA), svcca, shapereq_bool=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725404613977,"user_tz":240,"elapsed":9212,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"57334aad-aab3-4320-eca0-6bb6a3c973bc","id":"iNNrVPewHdvb"},"execution_count":91,"outputs":[{"output_type":"stream","name":"stdout","text":["0.006777720150612551\n"]},{"output_type":"execute_result","data":{"text/plain":["0.006777720150612551"]},"metadata":{},"execution_count":91}]},{"cell_type":"markdown","source":["# new run model actvs in batches- 1000"],"metadata":{"id":"KOxEj2nb41Bt"}},{"cell_type":"markdown","source":["## make data"],"metadata":{"id":"rCisMFi841Bu"}},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"status":"ok","timestamp":1725401539984,"user_tz":240,"elapsed":4039,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"TZE-yPeo41Bu"},"outputs":[],"source":["from datasets import load_dataset\n","dataset = load_dataset(\"Skylion007/openwebtext\", split=\"train\", streaming=True)"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"status":"ok","timestamp":1725401544513,"user_tz":240,"elapsed":4549,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"7lUQY5Qm41Bv"},"outputs":[],"source":["batch_size = 1000\n","\n","def get_next_batch(dataset_iter, batch_size=100):\n","    batch = []\n","    for _ in range(batch_size):\n","        try:\n","            sample = next(dataset_iter)\n","            batch.append(sample['text'])\n","        except StopIteration:\n","            break\n","    return batch\n","\n","# Get a batch of 100 samples\n","dataset_iter = iter(dataset)\n","batch = get_next_batch(dataset_iter, batch_size)\n","\n","# Tokenize the batch\n","inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=300)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1725401544518,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":240},"outputId":"a45968aa-3401-45e9-fa1b-b63e03115d76","id":"0-_DvlO241Bv"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1000, 300])"]},"metadata":{},"execution_count":17}],"source":["inputs['input_ids'].shape  # (batchnum, maxseqlen)"]},{"cell_type":"code","source":["inputs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725401544519,"user_tz":240,"elapsed":30,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"836ce694-35cc-4011-f279-290862bdb7fd","id":"-Jf8AkOm41Bv"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([[11688,    14,  1952,  ...,   253,   760,  7345],\n","        [28292, 14385,   273,  ...,    84,   417,  2590],\n","        [  510, 11626,  4469,  ...,   253,  3127,   296],\n","        ...,\n","        [ 3633,   253,  5962,  ...,   403, 24242,   281],\n","        [39153,  1556,    37,  ...,    13,  3778,   369],\n","        [26149,   366,  2892,  ...,   334,    84,   497]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        ...,\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1]])}"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["## get sae actvs"],"metadata":{"id":"p2QBkj9x41Bv"}},{"cell_type":"code","source":["from torch.utils.data import DataLoader, TensorDataset\n","\n","accumulated_outputs = None\n","batch_size = 100\n","maxseqlen = 300\n","\n","# Assuming 'inputs' is your input dictionary with 'input_ids' and 'attention_mask'\n","dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'])\n","loader = DataLoader(dataset, batch_size=16, shuffle=False)  # Adjust batch_size based on your memory constraints\n","\n","all_hidden_states = []\n","for batch in loader:\n","    input_ids, attention_mask = batch\n","\n","    # Prepare inputs for the model\n","    batch_inputs = {'input_ids': input_ids.to(model.device), 'attention_mask': attention_mask.to(model.device)}\n","    # Forward pass, set output_hidden_states to True to get hidden states\n","    with torch.no_grad():  # Disable gradient calculation for memory efficiency\n","        outputs = model(**batch_inputs, output_hidden_states=True)\n","        if accumulated_outputs is None:\n","            accumulated_outputs = outputs.hidden_states[layer_id]\n","        else:\n","            accumulated_outputs = torch.cat((accumulated_outputs, outputs.hidden_states[layer_id]), dim= 0)\n","\n","    # Clear memory to prevent OOM\n","    del batch_inputs, outputs\n","    torch.cuda.empty_cache()  # Only if you're using CUDA\n","    gc.collect()\n"],"metadata":{"executionInfo":{"status":"ok","timestamp":1725401562056,"user_tz":240,"elapsed":13809,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"Y4Y-fa9K41Bw"},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["feature_acts_model_A = None\n","batch_size = 100\n","\n","# while True:\n","for batch_id in range(10):\n","\n","    start = batch_id * batch_size\n","    end = min(start + batch_size, accumulated_outputs.shape[0])\n","    curr_inputs = accumulated_outputs[start:end].to(model.device)\n","    # inputs = {k: v.to(model.device) for k, v in inputs.items()}\n","\n","    with torch.inference_mode():\n","        outputs = sae.pre_acts(curr_inputs)\n","        if feature_acts_model_A is None:\n","            feature_acts_model_A = outputs\n","        else:\n","            feature_acts_model_A = torch.cat((feature_acts_model_A, outputs), dim= 0)\n","\n","    # Clear memory to prevent OOM\n","    del curr_inputs, outputs\n","    torch.cuda.empty_cache()  # Only if you're using CUDA\n","    gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"id":"m7Gchzq341Bw","executionInfo":{"status":"error","timestamp":1725401571722,"user_tz":240,"elapsed":1828,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"afd307f9-145d-4ef0-8e60-19b45978ada4"},"execution_count":20,"outputs":[{"output_type":"error","ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 18.31 GiB. GPU 0 has a total capacity of 39.56 GiB of which 11.50 GiB is free. Process 367489 has 28.05 GiB memory in use. Of the allocated memory 20.15 GiB is allocated by PyTorch, and 7.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-f41999d4b919>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mfeature_acts_model_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mfeature_acts_model_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_acts_model_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Clear memory to prevent OOM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 18.31 GiB. GPU 0 has a total capacity of 39.56 GiB of which 11.50 GiB is free. Process 367489 has 28.05 GiB memory in use. Of the allocated memory 20.15 GiB is allocated by PyTorch, and 7.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"]}]},{"cell_type":"code","source":["# with torch.inference_mode():\n","#     feature_acts_model_A = sae.pre_acts(accumulated_outputs)"],"metadata":{"executionInfo":{"status":"error","timestamp":1725400852633,"user_tz":240,"elapsed":70,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"BmarYrCM41Bw","outputId":"5a2088c5-4dc1-4c55-d1ec-59a19cc54189"},"execution_count":22,"outputs":[{"output_type":"error","ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 36.62 GiB. GPU 0 has a total capacity of 39.56 GiB of which 35.99 GiB is free. Process 329282 has 3.56 GiB memory in use. Of the allocated memory 2.98 GiB is allocated by PyTorch, and 90.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-0b8828154ef7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mfeature_acts_model_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_acts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccumulated_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sae/sae.py\u001b[0m in \u001b[0;36mpre_acts\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m# Remove decoder bias as per Anthropic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0msae_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_dec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msae_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 36.62 GiB. GPU 0 has a total capacity of 39.56 GiB of which 35.99 GiB is free. Process 329282 has 3.56 GiB memory in use. Of the allocated memory 2.98 GiB is allocated by PyTorch, and 90.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"]}]},{"cell_type":"code","source":["feature_acts_model_A.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rf6Z9nlR8MbK","executionInfo":{"status":"ok","timestamp":1725401588335,"user_tz":240,"elapsed":421,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"4a1811c3-7765-464f-a2a7-e94ae13db88e"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([400, 300, 32768])"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["first_dim_reshaped = feature_acts_model_A.shape[0] * feature_acts_model_A.shape[1]\n","reshaped_activations_A = feature_acts_model_A.reshape(first_dim_reshaped, feature_acts_model_A.shape[-1]).cpu()\n","del feature_acts_model_A\n","del accumulated_outputs\n","torch.cuda.empty_cache()"],"metadata":{"id":"A_gbgOvL41Bw","executionInfo":{"status":"ok","timestamp":1725401642152,"user_tz":240,"elapsed":11723,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader, TensorDataset\n","\n","accumulated_outputs = None\n","batch_size = 100\n","maxseqlen = 300\n","\n","# Assuming 'inputs' is your input dictionary with 'input_ids' and 'attention_mask'\n","dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'])\n","loader = DataLoader(dataset, batch_size=16, shuffle=False)  # Adjust batch_size based on your memory constraints\n","\n","all_hidden_states = []\n","for batch in loader:\n","    input_ids, attention_mask = batch\n","\n","    # Prepare inputs for the model\n","    batch_inputs = {'input_ids': input_ids.to(model.device), 'attention_mask': attention_mask.to(model.device)}\n","    # Forward pass, set output_hidden_states to True to get hidden states\n","    with torch.no_grad():  # Disable gradient calculation for memory efficiency\n","        outputs = model_2(**batch_inputs, output_hidden_states=True)\n","        if accumulated_outputs is None:\n","            accumulated_outputs = outputs.hidden_states[layer_id]\n","        else:\n","            accumulated_outputs = torch.cat((accumulated_outputs, outputs.hidden_states[layer_id]), dim= 0)\n","\n","    # Clear memory to prevent OOM\n","    del batch_inputs, outputs\n","    torch.cuda.empty_cache()  # Only if you're using CUDA\n","    gc.collect()\n"],"metadata":{"executionInfo":{"status":"ok","timestamp":1725401912898,"user_tz":240,"elapsed":15629,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"OmiRZDUi41Bw"},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["feature_acts_model_B = None\n","batch_size = 50\n","\n","# while True:\n","for batch_id in range(10):\n","    start = batch_id * batch_size\n","    end = min(start + batch_size, accumulated_outputs.shape[0])\n","    curr_inputs = accumulated_outputs[start:end].to(model.device)\n","    # inputs = {k: v.to(model.device) for k, v in inputs.items()}\n","\n","    with torch.inference_mode():\n","        outputs = sae_2.pre_acts(curr_inputs)\n","        if feature_acts_model_B is None:\n","            feature_acts_model_B = outputs\n","        else:\n","            feature_acts_model_B = torch.cat((feature_acts_model_B, outputs), dim= 0)\n","\n","    # Clear memory to prevent OOM\n","    del curr_inputs, outputs\n","    torch.cuda.empty_cache()  # Only if you're using CUDA\n","    gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"id":"rSrMiI3O9MHm","executionInfo":{"status":"error","timestamp":1725401929504,"user_tz":240,"elapsed":1935,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d4b5cafb-2af9-4b03-83a0-f06a3c3542d5"},"execution_count":30,"outputs":[{"output_type":"error","ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 10.99 GiB. GPU 0 has a total capacity of 39.56 GiB of which 8.41 GiB is free. Process 367489 has 31.14 GiB memory in use. Of the allocated memory 24.10 GiB is allocated by PyTorch, and 6.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-ddaf3d8a5ddd>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mfeature_acts_model_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mfeature_acts_model_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_acts_model_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Clear memory to prevent OOM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 10.99 GiB. GPU 0 has a total capacity of 39.56 GiB of which 8.41 GiB is free. Process 367489 has 31.14 GiB memory in use. Of the allocated memory 24.10 GiB is allocated by PyTorch, and 6.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"]}]},{"cell_type":"code","source":["# with torch.inference_mode():\n","#     feature_acts_model_B = sae_2.pre_acts(accumulated_outputs)"],"metadata":{"executionInfo":{"status":"aborted","timestamp":1725400852634,"user_tz":240,"elapsed":68,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"Z04VP7cw41Bw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["feature_acts_model_B.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8XfsCF5b9bWf","executionInfo":{"status":"ok","timestamp":1725401934102,"user_tz":240,"elapsed":421,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a732d492-d6e6-41ec-f060-09c1ac0e579d"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([250, 300, 32768])"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["first_dim_reshaped = feature_acts_model_B.shape[0] * feature_acts_model_B.shape[1]\n","reshaped_activations_B = feature_acts_model_B.reshape(first_dim_reshaped, feature_acts_model_B.shape[-1]).cpu()\n","del feature_acts_model_B\n","del accumulated_outputs\n","torch.cuda.empty_cache()"],"metadata":{"executionInfo":{"status":"ok","timestamp":1725401795709,"user_tz":240,"elapsed":8737,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"74e3dmSu41Bw"},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":["## use new corr fn on old data constr"],"metadata":{"id":"aDNMgDuu41Bx"}},{"cell_type":"code","source":["def normalize_byChunks(actv_tensor, chunk_size=10000): # chunk_size: Number of rows per chunk\n","    mean_A = actv_tensor.mean(dim=0, keepdim=True)\n","    std_A = actv_tensor.std(dim=0, keepdim=True)\n","\n","    num_chunks = actv_tensor.shape[0] // chunk_size\n","\n","    normalized_A = np.zeros_like(actv_tensor.cpu())  # Preallocate the normalized matrix\n","    # normalized_A = actv_tensor.new_zeros(actv_tensor.size())\n","\n","    for i in range(num_chunks):\n","        # print (i, num_chunks)\n","        start_index = i * chunk_size\n","        end_index = start_index + chunk_size\n","        chunk = actv_tensor[start_index:end_index]\n","        normalized_A[start_index:end_index] = (chunk - mean_A) / (std_A + 1e-8)\n","\n","    # Handle any remaining rows if the data size is not perfectly divisible by chunk_size\n","    if actv_tensor.shape[0] % chunk_size != 0:\n","        start_index = num_chunks * chunk_size\n","        chunk = actv_tensor[start_index:]\n","        normalized_A[start_index:] = (chunk - mean_A) / (std_A + 1e-8)\n","\n","    return torch.tensor(normalized_A)"],"metadata":{"executionInfo":{"status":"aborted","timestamp":1725400852634,"user_tz":240,"elapsed":68,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"jO_CwyV641Bx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def batched_correlation(reshaped_activations_A, reshaped_activations_B, batch_size=100):\n","    # Ensure tensors are on GPU\n","    # if torch.cuda.is_available():\n","    #     reshaped_activations_A = reshaped_activations_A.to('cuda')\n","    #     reshaped_activations_B = reshaped_activations_B.to('cuda')\n","\n","    normalized_A = normalize_byChunks(reshaped_activations_A, chunk_size=10000)\n","    normalized_B = normalize_byChunks(reshaped_activations_B, chunk_size=10000)\n","\n","    if torch.cuda.is_available():\n","        normalized_A = normalized_A.to('cuda')\n","        normalized_B = normalized_B.to('cuda')\n","\n","    num_batches = (normalized_B.shape[1] + batch_size - 1) // batch_size\n","    max_values = []\n","    max_indices = []\n","\n","    for batch in range(num_batches):\n","        start = batch * batch_size\n","        if start % 5000 == 0:\n","            print(start)\n","        end = min(start + batch_size, normalized_B.shape[1])\n","\n","        batch_corr_matrix = torch.matmul(normalized_A.t(), normalized_B[:, start:end]) / normalized_A.shape[0]\n","        max_val, max_idx = batch_corr_matrix.max(dim=0)\n","        max_values.append(max_val)\n","        max_indices.append(max_idx)  # Adjust indices for the batch offset\n","\n","        del batch_corr_matrix\n","        torch.cuda.empty_cache()\n","\n","    # return torch.cat(max_indices), torch.cat(max_values)\n","    return torch.cat(max_indices).cpu().numpy(), torch.cat(max_values).cpu().numpy()"],"metadata":{"executionInfo":{"status":"aborted","timestamp":1725400852634,"user_tz":240,"elapsed":68,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"yP8SOBBX41Bx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inds, vals = batched_correlation(reshaped_activations_A, reshaped_activations_B)"],"metadata":{"executionInfo":{"status":"aborted","timestamp":1725400852634,"user_tz":240,"elapsed":68,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"XSQnPuLz41Bx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_unq_pairs = len(list(set(inds.tolist())))\n","print(\"% unique: \", num_unq_pairs / len(inds))"],"metadata":{"executionInfo":{"status":"aborted","timestamp":1725400852634,"user_tz":240,"elapsed":67,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"hQvlCVwt41Bx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sum(vals) / len(vals)"],"metadata":{"executionInfo":{"status":"aborted","timestamp":1725400852634,"user_tz":240,"elapsed":67,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"_CXfN2nw41Bx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## sim metrics"],"metadata":{"id":"M3aAYTsv41By"}},{"cell_type":"code","source":["weight_matrix = sae.W_dec.cpu().detach().numpy()\n","weight_matrix_2 = sae_2.W_dec.cpu().detach().numpy()"],"metadata":{"executionInfo":{"status":"aborted","timestamp":1725400852634,"user_tz":240,"elapsed":67,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"vEqTKgkk41By"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svcca(weight_matrix[inds], weight_matrix_2, \"nd\")"],"metadata":{"executionInfo":{"status":"aborted","timestamp":1725400852634,"user_tz":240,"elapsed":67,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"HQVz0ogg41By"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svcca(weight_matrix, weight_matrix_2, \"nd\")"],"metadata":{"executionInfo":{"status":"aborted","timestamp":1725400852634,"user_tz":240,"elapsed":67,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"tV5bXkMt41By"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["score_rand(len(weight_matrix), svcca, shapereq_bool=True)"],"metadata":{"executionInfo":{"status":"aborted","timestamp":1725400852634,"user_tz":240,"elapsed":67,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"AaGCd_ZP41By"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1-1 only"],"metadata":{"id":"VrpwrypD41By"}},{"cell_type":"code","source":["uniq_corr_indices_AB_forB = []\n","uniq_corr_indices_AB_forA = []\n","seen = set()\n","\n","# Iterate through each index, checking membership in the set\n","for ind_B, ind_A in enumerate(inds.tolist()):\n","    if ind_A not in seen:\n","        seen.add(ind_A)\n","        uniq_corr_indices_AB_forA.append(ind_A)\n","        uniq_corr_indices_AB_forB.append(ind_B)"],"metadata":{"executionInfo":{"status":"aborted","timestamp":1725400852635,"user_tz":240,"elapsed":68,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"tyYmz1uB41By"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svcca(weight_matrix[uniq_corr_indices_AB_forA], weight_matrix_2[uniq_corr_indices_AB_forB], \"nd\")"],"metadata":{"executionInfo":{"status":"aborted","timestamp":1725400852635,"user_tz":240,"elapsed":68,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"5S9q8m5s41Bz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["score_rand(len(uniq_corr_indices_AB_forA), svcca, shapereq_bool=True)"],"metadata":{"executionInfo":{"status":"aborted","timestamp":1725400852635,"user_tz":240,"elapsed":68,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"E2fruDGk41Bz"},"execution_count":null,"outputs":[]}]}