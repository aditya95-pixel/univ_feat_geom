{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","toc_visible":true,"authorship_tag":"ABX9TyNZM1xllr0s7S832V53nB5k"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"cd9425dd9954474ba55586b8f7ea7d80":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8d9d13fc0bcb4ea6b224f4f62048a762","IPY_MODEL_76cc04159c42459e886fc51ace6f5f8a","IPY_MODEL_95b75bdc4a124416abc3efc820e8f46c"],"layout":"IPY_MODEL_5bcbeb73399246b89836b35b05db06da"}},"8d9d13fc0bcb4ea6b224f4f62048a762":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_835add2a0a9e48ae8cd8538a45e60f6b","placeholder":"​","style":"IPY_MODEL_e8e01c6fc9904477b667dc42e2b268b6","value":"tokenizer_config.json: 100%"}},"76cc04159c42459e886fc51ace6f5f8a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_390812621d344643801e3e2d8a412299","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c4740f4496a2470f8a63089442cce0e2","value":26}},"95b75bdc4a124416abc3efc820e8f46c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_66fd21d104c84f588c5c3701b0a66d99","placeholder":"​","style":"IPY_MODEL_32eaeb5a517f453dbacc447db698729f","value":" 26.0/26.0 [00:00&lt;00:00, 2.13kB/s]"}},"5bcbeb73399246b89836b35b05db06da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"835add2a0a9e48ae8cd8538a45e60f6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8e01c6fc9904477b667dc42e2b268b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"390812621d344643801e3e2d8a412299":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4740f4496a2470f8a63089442cce0e2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"66fd21d104c84f588c5c3701b0a66d99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32eaeb5a517f453dbacc447db698729f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b1a9902839a44772940589a0f344a44a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2aa0df33c22147059225e58c09af4655","IPY_MODEL_02afe8646d3f4db1a757fdee6cca5f78","IPY_MODEL_89702a3116814455aa8444a41115505f"],"layout":"IPY_MODEL_6b9249c4a9cb4eb1bc349ef90d971928"}},"2aa0df33c22147059225e58c09af4655":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d4bc1ad788b4c53a0374566f25950a5","placeholder":"​","style":"IPY_MODEL_e2182df0315940ef9814427feafec2f0","value":"config.json: 100%"}},"02afe8646d3f4db1a757fdee6cca5f78":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d19bab0b0d146cc9ee06737501be064","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0172e961dd6445c8b84c679a97da5e78","value":665}},"89702a3116814455aa8444a41115505f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c87c973f5e64a2abe9ec97fc6a9aa7e","placeholder":"​","style":"IPY_MODEL_578a0ccb02a74769848e73a0af153974","value":" 665/665 [00:00&lt;00:00, 46.9kB/s]"}},"6b9249c4a9cb4eb1bc349ef90d971928":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d4bc1ad788b4c53a0374566f25950a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2182df0315940ef9814427feafec2f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d19bab0b0d146cc9ee06737501be064":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0172e961dd6445c8b84c679a97da5e78":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8c87c973f5e64a2abe9ec97fc6a9aa7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"578a0ccb02a74769848e73a0af153974":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e6c7993185543bba36548537243788e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_635ed846cf9c45e5ba896e36a11f8f82","IPY_MODEL_64b682013baf44d492f6067c6ac59a14","IPY_MODEL_da813d6c54154ac49cc353358085881d"],"layout":"IPY_MODEL_6cc7f5cf99ca4ca58ccdd779e94846a8"}},"635ed846cf9c45e5ba896e36a11f8f82":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9596a6bf9755446bb26acc5573326667","placeholder":"​","style":"IPY_MODEL_85ef97a4c47340f9afa46e4d9824b7c2","value":"vocab.json: 100%"}},"64b682013baf44d492f6067c6ac59a14":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_25d7afcc6abb479e9770a9c3150edbd8","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6f0994bdf8184f08bd2868d794540174","value":1042301}},"da813d6c54154ac49cc353358085881d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e5050daef3d462dad40b1d6e3f179d7","placeholder":"​","style":"IPY_MODEL_42f93b089fa144d7bebeda688956cfbf","value":" 1.04M/1.04M [00:00&lt;00:00, 4.62MB/s]"}},"6cc7f5cf99ca4ca58ccdd779e94846a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9596a6bf9755446bb26acc5573326667":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85ef97a4c47340f9afa46e4d9824b7c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25d7afcc6abb479e9770a9c3150edbd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f0994bdf8184f08bd2868d794540174":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0e5050daef3d462dad40b1d6e3f179d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42f93b089fa144d7bebeda688956cfbf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"788779df987b4f8da4b2eb655107bf6f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b9874981882442a6be4ce1faa793dfc5","IPY_MODEL_0e61be38b2a64db785a9886555ce8717","IPY_MODEL_25d4544c1780486f83e4c4e17b5eecec"],"layout":"IPY_MODEL_c286608988f643ffad2b525aef428e19"}},"b9874981882442a6be4ce1faa793dfc5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_397ebb4e1299497ca4532ea4eadc75d6","placeholder":"​","style":"IPY_MODEL_e9b4c0ab4cd14c13a1d5cb81a5196112","value":"merges.txt: 100%"}},"0e61be38b2a64db785a9886555ce8717":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a43ea645dd2c4587b9110d5c9e124ab1","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5bef7cecb97a4e2fb0b8d70e4a1a14f7","value":456318}},"25d4544c1780486f83e4c4e17b5eecec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_34e697f8897f4393a15664290efe4495","placeholder":"​","style":"IPY_MODEL_2223f2b12d1e41aeb2e87a966a38bd31","value":" 456k/456k [00:00&lt;00:00, 2.12MB/s]"}},"c286608988f643ffad2b525aef428e19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"397ebb4e1299497ca4532ea4eadc75d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9b4c0ab4cd14c13a1d5cb81a5196112":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a43ea645dd2c4587b9110d5c9e124ab1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bef7cecb97a4e2fb0b8d70e4a1a14f7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"34e697f8897f4393a15664290efe4495":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2223f2b12d1e41aeb2e87a966a38bd31":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eab9e978671447a997d32df3d5a03792":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b79f2f667f7b4327a923ef07220253fd","IPY_MODEL_48f874b0b5a1491985288b8971dea74e","IPY_MODEL_8b01affba20d4aaf8afe2334512d25fe"],"layout":"IPY_MODEL_468f029cb4964707bb6217d00b5e238d"}},"b79f2f667f7b4327a923ef07220253fd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d239ea5683d84f6aae5efefa5dd7caa9","placeholder":"​","style":"IPY_MODEL_0ae63f870186471fa4a77f67c92988aa","value":"tokenizer.json: 100%"}},"48f874b0b5a1491985288b8971dea74e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8bf115ef0224fb9b356ece5004f83f5","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7a50896eb9944206985f791f9e28a01c","value":1355256}},"8b01affba20d4aaf8afe2334512d25fe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ae1acb69c8a4946a85d71c53cd5697b","placeholder":"​","style":"IPY_MODEL_26fb6248846843f3884768bf46479e89","value":" 1.36M/1.36M [00:00&lt;00:00, 6.12MB/s]"}},"468f029cb4964707bb6217d00b5e238d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d239ea5683d84f6aae5efefa5dd7caa9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ae63f870186471fa4a77f67c92988aa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f8bf115ef0224fb9b356ece5004f83f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a50896eb9944206985f791f9e28a01c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6ae1acb69c8a4946a85d71c53cd5697b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26fb6248846843f3884768bf46479e89":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"92b11eaf1a5e42c0a75e4e1f83df041f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_34d2d801ba6a4e2c896e8c990c0ed366","IPY_MODEL_18e8419a5f95494bb4cbcc7f94422553","IPY_MODEL_64a82e42aae340449bde6d0e364a2d98"],"layout":"IPY_MODEL_ad44a210f27541f08c5d53550b46a5df"}},"34d2d801ba6a4e2c896e8c990c0ed366":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5e1558f3dbd47bdb8579cb0e10a3be2","placeholder":"​","style":"IPY_MODEL_5d97573e5c014817b2a7d0089d87e7ac","value":"Map: 100%"}},"18e8419a5f95494bb4cbcc7f94422553":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_98f64c29268a4820927f8ad4ebb49319","max":21990,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1435f2aa5ed741ae8a024d707bd26dbd","value":21990}},"64a82e42aae340449bde6d0e364a2d98":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a486699d64c740bc9b16e508083d84ae","placeholder":"​","style":"IPY_MODEL_c58327d3b27744eb849aa763cdecdd04","value":" 21990/21990 [00:04&lt;00:00, 5395.43 examples/s]"}},"ad44a210f27541f08c5d53550b46a5df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5e1558f3dbd47bdb8579cb0e10a3be2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d97573e5c014817b2a7d0089d87e7ac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98f64c29268a4820927f8ad4ebb49319":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1435f2aa5ed741ae8a024d707bd26dbd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a486699d64c740bc9b16e508083d84ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c58327d3b27744eb849aa763cdecdd04":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"81fefd9f184246238f2c98e1693f4b50":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1365d1e89c3e4ac3bef9e5b36e4f2a61","IPY_MODEL_a61d5696ef614a919b488aa49ec2bd3a","IPY_MODEL_e6d7a22e1d6749ba98e4acc41ef83fef"],"layout":"IPY_MODEL_7a3b41ab99c940ea9fd652d5ec59ffad"}},"1365d1e89c3e4ac3bef9e5b36e4f2a61":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9951c940d6ec40e1a57a66c47ee912ea","placeholder":"​","style":"IPY_MODEL_0ed7cacf6fa14623bae9be1b76a4a373","value":"Map: 100%"}},"a61d5696ef614a919b488aa49ec2bd3a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_546b6c13edce49c3bf680a4e51c6b2aa","max":21990,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d95323e0147b4acf965cf58cb4bc8341","value":21990}},"e6d7a22e1d6749ba98e4acc41ef83fef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_afeaa408890747f88ad177d830fbd69a","placeholder":"​","style":"IPY_MODEL_4fb3f5d484214922b32ebfee7f08c88d","value":" 21990/21990 [00:04&lt;00:00, 4995.79 examples/s]"}},"7a3b41ab99c940ea9fd652d5ec59ffad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9951c940d6ec40e1a57a66c47ee912ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ed7cacf6fa14623bae9be1b76a4a373":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"546b6c13edce49c3bf680a4e51c6b2aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d95323e0147b4acf965cf58cb4bc8341":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"afeaa408890747f88ad177d830fbd69a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4fb3f5d484214922b32ebfee7f08c88d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9293fdb77e9249389ef71bf08362d5fc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6478f4d83379425ba8c1df8213144540","IPY_MODEL_6e68cb78d4bc4d048e3df152ee991615","IPY_MODEL_4093318f7cfe4bf29374460b053fdab0"],"layout":"IPY_MODEL_31c8c8adf6334634abdd6a9a70226da3"}},"6478f4d83379425ba8c1df8213144540":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_81daf63344eb41e4846a3641f0bed8ee","placeholder":"​","style":"IPY_MODEL_52343b7901c844568d9cf38a65c0c778","value":"Fetching 2 files: 100%"}},"6e68cb78d4bc4d048e3df152ee991615":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_27e063402dc5415cb5f5f6c1233bffe9","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_39635f1371f64ba69ccf44db92b39b58","value":2}},"4093318f7cfe4bf29374460b053fdab0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b03e9cad590a4577b94ca346823cd67f","placeholder":"​","style":"IPY_MODEL_ce3c5f2a52f0466db0d79359470abded","value":" 2/2 [00:00&lt;00:00, 149.49it/s]"}},"31c8c8adf6334634abdd6a9a70226da3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81daf63344eb41e4846a3641f0bed8ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52343b7901c844568d9cf38a65c0c778":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"27e063402dc5415cb5f5f6c1233bffe9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39635f1371f64ba69ccf44db92b39b58":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b03e9cad590a4577b94ca346823cd67f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce3c5f2a52f0466db0d79359470abded":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ac67abd72314e8c9f6c8f4e9b704cc0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2217bdf3a2d7403fba9015ecf50e5805","IPY_MODEL_ac9a2c497c8f431db25e386458a8a82c","IPY_MODEL_acc9bc4c815440838e0ed4e4a957ae16"],"layout":"IPY_MODEL_25bbcb7ce36040f3a5bc2edc32fc71f9"}},"2217bdf3a2d7403fba9015ecf50e5805":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6b930d4febc4880986beb6dc44cf001","placeholder":"​","style":"IPY_MODEL_1b4be3e1c3ec4879bc389cb6cb90df1d","value":"Fetching 2 files: 100%"}},"ac9a2c497c8f431db25e386458a8a82c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_70410c176f5b460d8f25af9a2b4acfae","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8c386bad78a542f6b931d7b9de05f4ed","value":2}},"acc9bc4c815440838e0ed4e4a957ae16":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f80fc36c98884b43b0fa6c711bb2c251","placeholder":"​","style":"IPY_MODEL_17e2c15a1ade4ed5a09e023089cf37ab","value":" 2/2 [00:00&lt;00:00, 126.94it/s]"}},"25bbcb7ce36040f3a5bc2edc32fc71f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6b930d4febc4880986beb6dc44cf001":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b4be3e1c3ec4879bc389cb6cb90df1d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"70410c176f5b460d8f25af9a2b4acfae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c386bad78a542f6b931d7b9de05f4ed":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f80fc36c98884b43b0fa6c711bb2c251":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17e2c15a1ade4ed5a09e023089cf37ab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13406b7e549048abb7ab6fc11b13612a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e47fdfa52c474db3bb39cf9287827ac6","IPY_MODEL_1af394b5036b45078d5c5252f9b5f57c","IPY_MODEL_cd2c690fb22147d6b87d4331aa4463be"],"layout":"IPY_MODEL_e55ce1cc237a41f2a6b77adc459cfe05"}},"e47fdfa52c474db3bb39cf9287827ac6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_325f7b8520c1455b9721827abd8635ce","placeholder":"​","style":"IPY_MODEL_d9ed56c8e1704b9a9dba16456ee30bde","value":"Fetching 2 files: 100%"}},"1af394b5036b45078d5c5252f9b5f57c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a5c2dc347af4abb9e292f91768a10cf","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f81c67ca91cd47b18d4dcb57a390e8b7","value":2}},"cd2c690fb22147d6b87d4331aa4463be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bfb6f7e8f04a4f23a37359758c353c1f","placeholder":"​","style":"IPY_MODEL_cd52761112f544f0b18858ea9433e8af","value":" 2/2 [00:00&lt;00:00, 117.80it/s]"}},"e55ce1cc237a41f2a6b77adc459cfe05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"325f7b8520c1455b9721827abd8635ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9ed56c8e1704b9a9dba16456ee30bde":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2a5c2dc347af4abb9e292f91768a10cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f81c67ca91cd47b18d4dcb57a390e8b7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bfb6f7e8f04a4f23a37359758c353c1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd52761112f544f0b18858ea9433e8af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"kUYRF57KNxrL"},"source":["# setup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20540,"status":"ok","timestamp":1724430229802,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":-60},"id":"5mOINJaL2svV","outputId":"e9021ad7-b604-4a1c-d7d8-74cb6b7fce5c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","source":["%%capture\n","!pip install git+https://github.com/EleutherAI/sae.git"],"metadata":{"id":"og3NgzELGzKN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install --upgrade git+https://github.com/EleutherAI/sae.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3oEUKt6MIr0p","executionInfo":{"status":"ok","timestamp":1724431659250,"user_tz":-60,"elapsed":8008,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"33da70c2-206d-484e-a3ad-540cefebea8f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/EleutherAI/sae.git\n","  Cloning https://github.com/EleutherAI/sae.git to /tmp/pip-req-build-m0xpa2eg\n","  Running command git clone --filter=blob:none --quiet https://github.com/EleutherAI/sae.git /tmp/pip-req-build-m0xpa2eg\n","  Resolved https://github.com/EleutherAI/sae.git to commit f60c38daedfade52da1baf12343b52447af0d654\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from sae==0.1.0) (0.32.1)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from sae==0.1.0) (2.21.0)\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from sae==0.1.0) (0.8.0)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from sae==0.1.0) (0.23.5)\n","Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (from sae==0.1.0) (8.4.0)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from sae==0.1.0) (0.4.4)\n","Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from sae==0.1.0) (0.1.5)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from sae==0.1.0) (2.3.1+cu121)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from sae==0.1.0) (4.42.4)\n","Requirement already satisfied: numpy<2.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate->sae==0.1.0) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->sae==0.1.0) (24.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->sae==0.1.0) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate->sae==0.1.0) (6.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->sae==0.1.0) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->sae==0.1.0) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->sae==0.1.0) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->sae==0.1.0) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->sae==0.1.0) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->sae==0.1.0) (2024.6.1)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->sae==0.1.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->sae==0.1.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->sae==0.1.0) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->sae==0.1.0) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->sae==0.1.0) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->sae==0.1.0) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->sae==0.1.0) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->sae==0.1.0) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->sae==0.1.0) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->sae==0.1.0) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->sae==0.1.0) (12.1.105)\n","Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->sae==0.1.0) (2.3.1)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->sae==0.1.0) (12.6.20)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->sae==0.1.0) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->sae==0.1.0) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->sae==0.1.0) (2.1.4)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets->sae==0.1.0) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets->sae==0.1.0) (4.66.5)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->sae==0.1.0) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->sae==0.1.0) (0.70.16)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->sae==0.1.0) (3.10.5)\n","Requirement already satisfied: docstring-parser~=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->sae==0.1.0) (0.16)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->sae==0.1.0) (2024.5.15)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->sae==0.1.0) (0.19.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->sae==0.1.0) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->sae==0.1.0) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->sae==0.1.0) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->sae==0.1.0) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->sae==0.1.0) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->sae==0.1.0) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->sae==0.1.0) (4.0.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->sae==0.1.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->sae==0.1.0) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->sae==0.1.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->sae==0.1.0) (2024.7.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->sae==0.1.0) (2.1.5)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->sae==0.1.0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->sae==0.1.0) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->sae==0.1.0) (2024.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->sae==0.1.0) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->sae==0.1.0) (1.16.0)\n"]}]},{"cell_type":"code","source":["# get the data and functions\n","# !git clone https://github.com/EleutherAI/sae.git"],"metadata":{"id":"Fdh5--MfYw7-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724430725138,"user_tz":-60,"elapsed":410,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a940754f-6b53-4349-8600-116aa0299ae9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'sae'...\n","remote: Enumerating objects: 382, done.\u001b[K\n","remote: Counting objects: 100% (206/206), done.\u001b[K\n","remote: Compressing objects: 100% (79/79), done.\u001b[K\n","remote: Total 382 (delta 157), reused 144 (delta 127), pack-reused 176 (from 1)\u001b[K\n","Receiving objects: 100% (382/382), 118.75 KiB | 4.40 MiB/s, done.\n","Resolving deltas: 100% (244/244), done.\n"]}]},{"cell_type":"code","source":["# import sys\n","# sys.path.append('/content/sae')"],"metadata":{"id":"b18lLEphGCt2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# %cd /content/sae/sae\n","# !pwd\n","# %ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MS__dGEZGJX-","executionInfo":{"status":"ok","timestamp":1724431015089,"user_tz":-60,"elapsed":345,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"58f6354a-2887-40eb-e939-554a81021f54"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/sae\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4H-vBfRa1pOo"},"outputs":[],"source":["import pickle\n","import numpy as np\n","\n","import torch\n","import matplotlib.pyplot as plt\n","\n","from torch import nn, Tensor\n","from jaxtyping import Float, Int\n","from typing import Optional, Callable, Union, List, Tuple"]},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\""],"metadata":{"id":"yUWzqfKmaRXj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## corr fns"],"metadata":{"id":"YOYUhykrUbI8"}},{"cell_type":"code","source":["def batched_correlation(reshaped_activations_A, reshaped_activations_B, batch_size=100):\n","    # Ensure tensors are on GPU\n","    if torch.cuda.is_available():\n","        reshaped_activations_A = reshaped_activations_A.to('cuda')\n","        reshaped_activations_B = reshaped_activations_B.to('cuda')\n","\n","    # Normalize columns of A\n","    mean_A = reshaped_activations_A.mean(dim=0, keepdim=True)\n","    std_A = reshaped_activations_A.std(dim=0, keepdim=True)\n","    normalized_A = (reshaped_activations_A - mean_A) / (std_A + 1e-8)  # Avoid division by zero\n","\n","    # Normalize columns of B\n","    mean_B = reshaped_activations_B.mean(dim=0, keepdim=True)\n","    std_B = reshaped_activations_B.std(dim=0, keepdim=True)\n","    normalized_B = (reshaped_activations_B - mean_B) / (std_B + 1e-8)  # Avoid division by zero\n","\n","    num_batches = (normalized_B.shape[1] + batch_size - 1) // batch_size\n","    max_values = []\n","    max_indices = []\n","\n","    for batch in range(num_batches):\n","        start = batch * batch_size\n","        end = min(start + batch_size, normalized_B.shape[1])\n","        batch_corr_matrix = torch.matmul(normalized_A.t(), normalized_B[:, start:end]) / normalized_A.shape[0]\n","        max_val, max_idx = batch_corr_matrix.max(dim=0)\n","        max_values.append(max_val)\n","        # max_indices.append(max_idx + start)  # Adjust indices for the batch offset\n","        max_indices.append(max_idx)  # Adjust indices for the batch offset\n","\n","        del batch_corr_matrix\n","        torch.cuda.empty_cache()\n","\n","    return torch.cat(max_indices), torch.cat(max_values)"],"metadata":{"id":"SaotL1OHcZ3_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## sim fns"],"metadata":{"id":"vlKdEehFvC86"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rl7IYESN1irP"},"outputs":[],"source":["import functools\n","from typing import Any, Callable, Dict, List, Tuple, Union\n","\n","import numpy as np\n","import numpy.typing as npt\n","import torch\n","\n","\n","def to_numpy_if_needed(*args: Union[torch.Tensor, npt.NDArray]) -> List[npt.NDArray]:\n","    def convert(x: Union[torch.Tensor, npt.NDArray]) -> npt.NDArray:\n","        return x if isinstance(x, np.ndarray) else x.numpy()\n","\n","    return list(map(convert, args))\n","\n","\n","def to_torch_if_needed(*args: Union[torch.Tensor, npt.NDArray]) -> List[torch.Tensor]:\n","    def convert(x: Union[torch.Tensor, npt.NDArray]) -> torch.Tensor:\n","        return x if isinstance(x, torch.Tensor) else torch.from_numpy(x)\n","\n","    return list(map(convert, args))\n","\n","\n","def adjust_dimensionality(\n","    R: npt.NDArray, Rp: npt.NDArray, strategy=\"zero_pad\"\n",") -> Tuple[npt.NDArray, npt.NDArray]:\n","    D = R.shape[1]\n","    Dp = Rp.shape[1]\n","    if strategy == \"zero_pad\":\n","        if D - Dp == 0:\n","            return R, Rp\n","        elif D - Dp > 0:\n","            return R, np.concatenate((Rp, np.zeros((Rp.shape[0], D - Dp))), axis=1)\n","        else:\n","            return np.concatenate((R, np.zeros((R.shape[0], Dp - D))), axis=1), Rp\n","    else:\n","        raise NotImplementedError()\n","\n","\n","def center_columns(R: npt.NDArray) -> npt.NDArray:\n","    return R - R.mean(axis=0)[None, :]\n","\n","\n","def normalize_matrix_norm(R: npt.NDArray) -> npt.NDArray:\n","    return R / np.linalg.norm(R, ord=\"fro\")\n","\n","\n","def sim_random_baseline(\n","    rep1: torch.Tensor, rep2: torch.Tensor, sim_func: Callable, n_permutations: int = 10\n",") -> Dict[str, Any]:\n","    torch.manual_seed(1234)\n","    scores = []\n","    for _ in range(n_permutations):\n","        perm = torch.randperm(rep1.size(0))\n","\n","        score = sim_func(rep1[perm, :], rep2)\n","        score = score if isinstance(score, float) else score[\"score\"]\n","\n","        scores.append(score)\n","\n","    return {\"baseline_scores\": np.array(scores)}\n","\n","\n","class Pipeline:\n","    def __init__(\n","        self,\n","        preprocess_funcs: List[Callable[[npt.NDArray], npt.NDArray]],\n","        similarity_func: Callable[[npt.NDArray, npt.NDArray], Dict[str, Any]],\n","    ) -> None:\n","        self.preprocess_funcs = preprocess_funcs\n","        self.similarity_func = similarity_func\n","\n","    def __call__(self, R: npt.NDArray, Rp: npt.NDArray) -> Dict[str, Any]:\n","        for preprocess_func in self.preprocess_funcs:\n","            R = preprocess_func(R)\n","            Rp = preprocess_func(Rp)\n","        return self.similarity_func(R, Rp)\n","\n","    def __str__(self) -> str:\n","        def func_name(func: Callable) -> str:\n","            return (\n","                func.__name__\n","                if not isinstance(func, functools.partial)\n","                else func.func.__name__\n","            )\n","\n","        def partial_keywords(func: Callable) -> str:\n","            if not isinstance(func, functools.partial):\n","                return \"\"\n","            else:\n","                return str(func.keywords)\n","\n","        return (\n","            \"Pipeline(\"\n","            + (\n","                \"+\".join(map(func_name, self.preprocess_funcs))\n","                + \"+\"\n","                + func_name(self.similarity_func)\n","                + partial_keywords(self.similarity_func)\n","            )\n","            + \")\"\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RgcXEjdcXAOj"},"outputs":[],"source":["from typing import List, Set, Union\n","\n","import numpy as np\n","import numpy.typing as npt\n","import sklearn.neighbors\n","import torch\n","\n","# from llmcomp.measures.utils import to_numpy_if_needed\n","\n","\n","def _jac_sim_i(idx_R: Set[int], idx_Rp: Set[int]) -> float:\n","    return len(idx_R.intersection(idx_Rp)) / len(idx_R.union(idx_Rp))\n","\n","\n","def jaccard_similarity(\n","    R: Union[torch.Tensor, npt.NDArray],\n","    Rp: Union[torch.Tensor, npt.NDArray],\n","    k: int = 10,\n","    inner: str = \"cosine\",\n","    n_jobs: int = 8,\n",") -> float:\n","    R, Rp = to_numpy_if_needed(R, Rp)\n","\n","    indices_R = nn_array_to_setlist(top_k_neighbors(R, k, inner, n_jobs))\n","    indices_Rp = nn_array_to_setlist(top_k_neighbors(Rp, k, inner, n_jobs))\n","\n","    return float(\n","        np.mean(\n","            [_jac_sim_i(idx_R, idx_Rp) for idx_R, idx_Rp in zip(indices_R, indices_Rp)]\n","        )\n","    )\n","\n","\n","def top_k_neighbors(\n","    R: npt.NDArray,\n","    k: int,\n","    inner: str,\n","    n_jobs: int,\n",") -> npt.NDArray:\n","    # k+1 nearest neighbors, because we pass in all the data, which means that a point\n","    # will be the nearest neighbor to itself. We remove this point from the results and\n","    # report only the k nearest neighbors distinct from the point itself.\n","    nns = sklearn.neighbors.NearestNeighbors(\n","        n_neighbors=k + 1, metric=inner, n_jobs=n_jobs\n","    )\n","    nns.fit(R)\n","    _, nns = nns.kneighbors(R)\n","    return nns[:, 1:]\n","\n","\n","def nn_array_to_setlist(nn: npt.NDArray) -> List[Set[int]]:\n","    return [set(idx) for idx in nn]"]},{"cell_type":"code","source":["import functools\n","import logging\n","from abc import ABC\n","from abc import abstractmethod\n","from dataclasses import dataclass\n","from dataclasses import field\n","from typing import Any\n","from typing import Callable\n","from typing import get_args\n","from typing import List\n","from typing import Literal\n","from typing import Optional\n","from typing import Protocol\n","from typing import Tuple\n","from typing import Union\n","\n","import numpy as np\n","import numpy.typing as npt\n","import torch\n","from einops import rearrange\n","# from loguru import logger\n","\n","log = logging.getLogger(__name__)\n","\n","\n","SHAPE_TYPE = Literal[\"nd\", \"ntd\", \"nchw\"]\n","\n","ND_SHAPE, NTD_SHAPE, NCHW_SHAPE = get_args(SHAPE_TYPE)[0], get_args(SHAPE_TYPE)[1], get_args(SHAPE_TYPE)[2]\n","\n","\n","class SimilarityFunction(Protocol):\n","    def __call__(  # noqa: E704\n","        self,\n","        R: torch.Tensor | npt.NDArray,\n","        Rp: torch.Tensor | npt.NDArray,\n","        shape: SHAPE_TYPE,\n","    ) -> float: ...\n","\n","\n","class RSMSimilarityFunction(Protocol):\n","    def __call__(  # noqa: E704\n","        self, R: torch.Tensor | npt.NDArray, Rp: torch.Tensor | npt.NDArray, shape: SHAPE_TYPE, n_jobs: int\n","    ) -> float: ...\n","\n","\n","@dataclass\n","class BaseSimilarityMeasure(ABC):\n","    larger_is_more_similar: bool\n","    is_symmetric: bool\n","\n","    is_metric: bool | None = None\n","    invariant_to_affine: bool | None = None\n","    invariant_to_invertible_linear: bool | None = None\n","    invariant_to_ortho: bool | None = None\n","    invariant_to_permutation: bool | None = None\n","    invariant_to_isotropic_scaling: bool | None = None\n","    invariant_to_translation: bool | None = None\n","    name: str = field(init=False)\n","\n","    def __post_init__(self):\n","        self.name = self.__class__.__name__\n","\n","    @abstractmethod\n","    def __call__(self, *args: Any, **kwds: Any) -> Any:\n","        raise NotImplementedError\n","\n","\n","class FunctionalSimilarityMeasure(BaseSimilarityMeasure):\n","    @abstractmethod\n","    def __call__(self, output_a: torch.Tensor | npt.NDArray, output_b: torch.Tensor | npt.NDArray) -> float:\n","        raise NotImplementedError\n","\n","\n","@dataclass(kw_only=True)\n","class RepresentationalSimilarityMeasure(BaseSimilarityMeasure):\n","    sim_func: SimilarityFunction\n","\n","    def __call__(\n","        self,\n","        R: torch.Tensor | npt.NDArray,\n","        Rp: torch.Tensor | npt.NDArray,\n","        shape: SHAPE_TYPE,\n","    ) -> float:\n","        return self.sim_func(R, Rp, shape)\n","\n","\n","class RSMSimilarityMeasure(RepresentationalSimilarityMeasure):\n","    sim_func: RSMSimilarityFunction\n","\n","    @staticmethod\n","    def estimate_good_number_of_jobs(R: torch.Tensor | npt.NDArray, Rp: torch.Tensor | npt.NDArray) -> int:\n","        # RSMs in are NxN (or DxD) so the number of jobs should roughly scale quadratically with increase in N (or D).\n","        # False! As long as sklearn-native metrics are used, they will use parallel implementations regardless of job\n","        # count. Each job would spawn their own threads, which leads to oversubscription of cores and thus slowdown.\n","        # This seems to be not fully correct (n_jobs=2 seems to actually use two cores), but using n_jobs=1 seems the\n","        # fastest.\n","        return 1\n","\n","    def __call__(\n","        self,\n","        R: torch.Tensor | npt.NDArray,\n","        Rp: torch.Tensor | npt.NDArray,\n","        shape: SHAPE_TYPE,\n","        n_jobs: Optional[int] = None,\n","    ) -> float:\n","        if n_jobs is None:\n","            n_jobs = self.estimate_good_number_of_jobs(R, Rp)\n","        return self.sim_func(R, Rp, shape, n_jobs=n_jobs)\n","\n","\n","def to_numpy_if_needed(*args: Union[torch.Tensor, npt.NDArray]) -> List[npt.NDArray]:\n","    def convert(x: Union[torch.Tensor, npt.NDArray]) -> npt.NDArray:\n","        return x if isinstance(x, np.ndarray) else x.numpy()\n","\n","    return list(map(convert, args))\n","\n","\n","def to_torch_if_needed(*args: Union[torch.Tensor, npt.NDArray]) -> List[torch.Tensor]:\n","    def convert(x: Union[torch.Tensor, npt.NDArray]) -> torch.Tensor:\n","        return x if isinstance(x, torch.Tensor) else torch.from_numpy(x)\n","\n","    return list(map(convert, args))\n","\n","\n","def adjust_dimensionality(R: npt.NDArray, Rp: npt.NDArray, strategy=\"zero_pad\") -> Tuple[npt.NDArray, npt.NDArray]:\n","    D = R.shape[1]\n","    Dp = Rp.shape[1]\n","    if strategy == \"zero_pad\":\n","        if D - Dp == 0:\n","            return R, Rp\n","        elif D - Dp > 0:\n","            return R, np.concatenate((Rp, np.zeros((Rp.shape[0], D - Dp))), axis=1)\n","        else:\n","            return np.concatenate((R, np.zeros((R.shape[0], Dp - D))), axis=1), Rp\n","    else:\n","        raise NotImplementedError()\n","\n","\n","def center_columns(R: npt.NDArray) -> npt.NDArray:\n","    return R - R.mean(axis=0)[None, :]\n","\n","\n","def normalize_matrix_norm(R: npt.NDArray) -> npt.NDArray:\n","    return R / np.linalg.norm(R, ord=\"fro\")\n","\n","\n","def normalize_row_norm(R: npt.NDArray) -> npt.NDArray:\n","    return R / np.linalg.norm(R, ord=2, axis=1, keepdims=True)\n","\n","\n","def standardize(R: npt.NDArray) -> npt.NDArray:\n","    return (R - R.mean(axis=0, keepdims=True)) / R.std(axis=0)\n","\n","\n","def double_center(x: npt.NDArray) -> npt.NDArray:\n","    return x - x.mean(axis=0, keepdims=True) - x.mean(axis=1, keepdims=True) + x.mean()\n","\n","\n","def align_spatial_dimensions(R: npt.NDArray, Rp: npt.NDArray) -> Tuple[npt.NDArray, npt.NDArray]:\n","    \"\"\"\n","    Aligns spatial representations by resizing them to the smallest spatial dimension.\n","    Subsequent aligned spatial representations are flattened, with the spatial aligned representations\n","    moving into the *sample* dimension.\n","    \"\"\"\n","    R_re, Rp_re = resize_wh_reps(R, Rp)\n","    R_re = rearrange(R_re, \"n c h w -> (n h w) c\")\n","    Rp_re = rearrange(Rp_re, \"n c h w -> (n h w) c\")\n","    if R_re.shape[0] > 5000:\n","        logger.info(f\"Got {R_re.shape[0]} samples in N after flattening. Subsampling to reduce compute.\")\n","        subsample = R_re.shape[0] // 5000\n","        R_re = R_re[::subsample]\n","        Rp_re = Rp_re[::subsample]\n","\n","    return R_re, Rp_re\n","\n","\n","def average_pool_downsample(R, resize: bool, new_size: tuple[int, int]):\n","    if not resize:\n","        return R  # do nothing\n","    else:\n","        is_numpy = isinstance(R, np.ndarray)\n","        R_torch = torch.from_numpy(R) if is_numpy else R\n","        R_torch = torch.nn.functional.adaptive_avg_pool2d(R_torch, new_size)\n","        return R_torch.numpy() if is_numpy else R_torch\n","\n","\n","def resize_wh_reps(R: npt.NDArray, Rp: npt.NDArray) -> Tuple[npt.NDArray, npt.NDArray]:\n","    \"\"\"\n","    Function for resizing spatial representations that are not the same size.\n","    Does through fourier transform and resizing.\n","\n","    Args:\n","        R: numpy array of shape  [batch_size, height, width, num_channels]\n","        RP: numpy array of shape [batch_size, height, width, num_channels]\n","\n","    Returns:\n","        fft_acts1: numpy array of shape [batch_size, (new) height, (new) width, num_channels]\n","        fft_acts2: numpy array of shape [batch_size, (new) height, (new) width, num_channels]\n","\n","    \"\"\"\n","    height1, width1 = R.shape[2], R.shape[3]\n","    height2, width2 = Rp.shape[2], Rp.shape[3]\n","    if height1 != height2 or width1 != width2:\n","        height = min(height1, height2)\n","        width = min(width1, width2)\n","        new_size = [height, width]\n","        resize = True\n","    else:\n","        height = height1\n","        width = width1\n","        new_size = None\n","        resize = False\n","\n","    # resize and preprocess with fft\n","    avg_ds1 = average_pool_downsample(R, resize=resize, new_size=new_size)\n","    avg_ds2 = average_pool_downsample(Rp, resize=resize, new_size=new_size)\n","    return avg_ds1, avg_ds2\n","\n","\n","def fft_resize(images, resize=False, new_size=None):\n","    \"\"\"Function for applying DFT and resizing.\n","\n","    This function takes in an array of images, applies the 2-d fourier transform\n","    and resizes them according to new_size, keeping the frequencies that overlap\n","    between the two sizes.\n","\n","    Args:\n","              images: a numpy array with shape\n","                      [batch_size, height, width, num_channels]\n","              resize: boolean, whether or not to resize\n","              new_size: a tuple (size, size), with height and width the same\n","\n","    Returns:\n","              im_fft_downsampled: a numpy array with shape\n","                           [batch_size, (new) height, (new) width, num_channels]\n","    \"\"\"\n","    assert len(images.shape) == 4, \"expecting images to be\" \"[batch_size, height, width, num_channels]\"\n","    if resize:\n","        # FFT --> remove high frequencies --> inverse FFT\n","        im_complex = images.astype(\"complex64\")\n","        im_fft = np.fft.fft2(im_complex, axes=(1, 2))\n","        im_shifted = np.fft.fftshift(im_fft, axes=(1, 2))\n","\n","        center_width = im_shifted.shape[2] // 2\n","        center_height = im_shifted.shape[1] // 2\n","        half_w = new_size[0] // 2\n","        half_h = new_size[1] // 2\n","        cropped_fft = im_shifted[\n","            :, center_height - half_h : center_height + half_h, center_width - half_w : center_width + half_w, :\n","        ]\n","        cropped_fft_shifted_back = np.fft.ifft2(cropped_fft, axes=(1, 2))\n","        return cropped_fft_shifted_back.real\n","    else:\n","        return images\n","\n","\n","class Pipeline:\n","    def __init__(\n","        self,\n","        preprocess_funcs: List[Callable[[npt.NDArray], npt.NDArray]],\n","        similarity_func: Callable[[npt.NDArray, npt.NDArray, SHAPE_TYPE], float],\n","    ) -> None:\n","        self.preprocess_funcs = preprocess_funcs\n","        self.similarity_func = similarity_func\n","\n","    def __call__(self, R: npt.NDArray, Rp: npt.NDArray, shape: SHAPE_TYPE) -> float:\n","        try:\n","            for preprocess_func in self.preprocess_funcs:\n","                R = preprocess_func(R)\n","                Rp = preprocess_func(Rp)\n","            return self.similarity_func(R, Rp, shape)\n","        except ValueError as e:\n","            log.info(f\"Pipeline failed: {e}\")\n","            return np.nan\n","\n","    def __str__(self) -> str:\n","        def func_name(func: Callable) -> str:\n","            return func.__name__ if not isinstance(func, functools.partial) else func.func.__name__\n","\n","        def partial_keywords(func: Callable) -> str:\n","            if not isinstance(func, functools.partial):\n","                return \"\"\n","            else:\n","                return str(func.keywords)\n","\n","        return (\n","            \"Pipeline(\"\n","            + (\n","                \"+\".join(map(func_name, self.preprocess_funcs))\n","                + \"+\"\n","                + func_name(self.similarity_func)\n","                + partial_keywords(self.similarity_func)\n","            )\n","            + \")\"\n","        )\n","\n","\n","def flatten(*args: Union[torch.Tensor, npt.NDArray], shape: SHAPE_TYPE) -> List[Union[torch.Tensor, npt.NDArray]]:\n","    if shape == \"ntd\":\n","        return list(map(flatten_nxtxd_to_ntxd, args))\n","    elif shape == \"nd\":\n","        return list(args)\n","    elif shape == \"nchw\":\n","        return list(map(flatten_nxcxhxw_to_nxchw, args))  # Flattening non-trivial for nchw\n","    else:\n","        raise ValueError(\"Unknown shape of representations. Must be one of 'ntd', 'nchw', 'nd'.\")\n","\n","\n","def flatten_nxtxd_to_ntxd(R: Union[torch.Tensor, npt.NDArray]) -> torch.Tensor:\n","    R = to_torch_if_needed(R)[0]\n","    log.debug(\"Shape before flattening: %s\", str(R.shape))\n","    R = torch.flatten(R, start_dim=0, end_dim=1)\n","    log.debug(\"Shape after flattening: %s\", str(R.shape))\n","    return R\n","\n","\n","def flatten_nxcxhxw_to_nxchw(R: Union[torch.Tensor, npt.NDArray]) -> torch.Tensor:\n","    R = to_torch_if_needed(R)[0]\n","    log.debug(\"Shape before flattening: %s\", str(R.shape))\n","    R = torch.reshape(R, (R.shape[0], -1))\n","    log.debug(\"Shape after flattening: %s\", str(R.shape))\n","    return R"],"metadata":{"id":"K8QY53-0umRk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from typing import Optional\n","from typing import Union\n","\n","import numpy as np\n","import numpy.typing as npt\n","import scipy.spatial.distance\n","import scipy.stats\n","import sklearn.metrics\n","import torch\n","# from repsim.measures.utils import flatten\n","# from repsim.measures.utils import RSMSimilarityMeasure\n","# from repsim.measures.utils import SHAPE_TYPE\n","# from repsim.measures.utils import to_numpy_if_needed\n","\n","\n","def representational_similarity_analysis(\n","    R: Union[torch.Tensor, npt.NDArray],\n","    Rp: Union[torch.Tensor, npt.NDArray],\n","    shape: SHAPE_TYPE,\n","    inner=\"correlation\",\n","    outer=\"spearman\",\n","    n_jobs: Optional[int] = None,\n",") -> float:\n","    \"\"\"Representational similarity analysis\n","\n","    Args:\n","        R (Union[torch.Tensor, npt.NDArray]): N x D representation\n","        Rp (Union[torch.Tensor, npt.NDArray]): N x D' representation\n","        inner (str, optional): inner similarity function for RSM. Must be one of\n","            scipy.spatial.distance.pdist identifiers . Defaults to \"correlation\".\n","        outer (str, optional): outer similarity function that compares RSMs. Defaults to\n","             \"spearman\". Must be one of \"spearman\", \"euclidean\"\n","\n","    Returns:\n","        float: _description_\n","    \"\"\"\n","    R, Rp = flatten(R, Rp, shape=shape)\n","    R, Rp = to_numpy_if_needed(R, Rp)\n","\n","    if inner == \"correlation\":\n","        # n_jobs only works if metric is in PAIRWISE_DISTANCES as defined in sklearn, i.e., not for correlation.\n","        # But correlation = 1 - cosine dist of row-centered data, so we use the faster cosine metric and center the data.\n","        R = R - R.mean(axis=1, keepdims=True)\n","        S = scipy.spatial.distance.squareform(  # take the lower triangle of RSM\n","            1 - sklearn.metrics.pairwise_distances(R, metric=\"cosine\", n_jobs=n_jobs),  # type:ignore\n","            checks=False,\n","        )\n","        Rp = Rp - Rp.mean(axis=1, keepdims=True)\n","        Sp = scipy.spatial.distance.squareform(\n","            1 - sklearn.metrics.pairwise_distances(Rp, metric=\"cosine\", n_jobs=n_jobs),  # type:ignore\n","            checks=False,\n","        )\n","    elif inner == \"euclidean\":\n","        # take the lower triangle of RSM\n","        S = scipy.spatial.distance.squareform(\n","            sklearn.metrics.pairwise_distances(R, metric=inner, n_jobs=n_jobs), checks=False\n","        )\n","        Sp = scipy.spatial.distance.squareform(\n","            sklearn.metrics.pairwise_distances(Rp, metric=inner, n_jobs=n_jobs), checks=False\n","        )\n","    else:\n","        raise NotImplementedError(f\"{inner=}\")\n","\n","    if outer == \"spearman\":\n","        return scipy.stats.spearmanr(S, Sp).statistic  # type:ignore\n","    elif outer == \"euclidean\":\n","        return float(np.linalg.norm(S - Sp, ord=2))\n","    else:\n","        raise ValueError(f\"Unknown outer similarity function: {outer}\")\n","\n","\n","class RSA(RSMSimilarityMeasure):\n","    def __init__(self):\n","        # choice of inner/outer in __call__ if fixed to default values, so these values are always the same\n","        super().__init__(\n","            sim_func=representational_similarity_analysis,\n","            larger_is_more_similar=True,\n","            is_metric=False,\n","            is_symmetric=True,\n","            invariant_to_affine=False,\n","            invariant_to_invertible_linear=False,\n","            invariant_to_ortho=False,\n","            invariant_to_permutation=True,\n","            invariant_to_isotropic_scaling=True,\n","            invariant_to_translation=True,\n","        )"],"metadata":{"id":"MU_QCO_UvFKl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##################################################################################\n","# Copied from https://github.com/google/svcca/blob/1f3fbf19bd31bd9b76e728ef75842aa1d9a4cd2b/cca_core.py\n","# Copyright 2018 Google Inc.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","\"\"\"\n","The core code for applying Canonical Correlation Analysis to deep networks.\n","\n","This module contains the core functions to apply canonical correlation analysis\n","to deep neural networks. The main function is get_cca_similarity, which takes in\n","two sets of activations, typically the neurons in two layers and their outputs\n","on all of the datapoints D = [d_1,...,d_m] that have been passed through.\n","\n","Inputs have shape (num_neurons1, m), (num_neurons2, m). This can be directly\n","applied used on fully connected networks. For convolutional layers, the 3d block\n","of neurons can either be flattened entirely, along channels, or alternatively,\n","the dft_ccas (Discrete Fourier Transform) module can be used.\n","\n","See:\n","https://arxiv.org/abs/1706.05806\n","https://arxiv.org/abs/1806.05759\n","for full details.\n","\n","\"\"\"\n","import numpy as np\n","# from repsim.measures.utils import align_spatial_dimensions\n","\n","num_cca_trials = 5\n","\n","\n","def positivedef_matrix_sqrt(array):\n","    \"\"\"Stable method for computing matrix square roots, supports complex matrices.\n","\n","    Args:\n","              array: A numpy 2d array, can be complex valued that is a positive\n","                     definite symmetric (or hermitian) matrix\n","\n","    Returns:\n","              sqrtarray: The matrix square root of array\n","    \"\"\"\n","    w, v = np.linalg.eigh(array)\n","    #  A - np.dot(v, np.dot(np.diag(w), v.T))\n","    wsqrt = np.sqrt(w)\n","    sqrtarray = np.dot(v, np.dot(np.diag(wsqrt), np.conj(v).T))\n","    return sqrtarray\n","\n","\n","def remove_small(sigma_xx, sigma_xy, sigma_yx, sigma_yy, epsilon):\n","    \"\"\"Takes covariance between X, Y, and removes values of small magnitude.\n","\n","    Args:\n","              sigma_xx: 2d numpy array, variance matrix for x\n","              sigma_xy: 2d numpy array, crossvariance matrix for x,y\n","              sigma_yx: 2d numpy array, crossvariance matrixy for x,y,\n","                        (conjugate) transpose of sigma_xy\n","              sigma_yy: 2d numpy array, variance matrix for y\n","              epsilon : cutoff value for norm below which directions are thrown\n","                         away\n","\n","    Returns:\n","              sigma_xx_crop: 2d array with low x norm directions removed\n","              sigma_xy_crop: 2d array with low x and y norm directions removed\n","              sigma_yx_crop: 2d array with low x and y norm directiosn removed\n","              sigma_yy_crop: 2d array with low y norm directions removed\n","              x_idxs: indexes of sigma_xx that were removed\n","              y_idxs: indexes of sigma_yy that were removed\n","    \"\"\"\n","\n","    x_diag = np.abs(np.diagonal(sigma_xx))\n","    y_diag = np.abs(np.diagonal(sigma_yy))\n","    x_idxs = x_diag >= epsilon\n","    y_idxs = y_diag >= epsilon\n","\n","    sigma_xx_crop = sigma_xx[x_idxs][:, x_idxs]\n","    sigma_xy_crop = sigma_xy[x_idxs][:, y_idxs]\n","    sigma_yx_crop = sigma_yx[y_idxs][:, x_idxs]\n","    sigma_yy_crop = sigma_yy[y_idxs][:, y_idxs]\n","\n","    return (sigma_xx_crop, sigma_xy_crop, sigma_yx_crop, sigma_yy_crop, x_idxs, y_idxs)\n","\n","\n","def compute_ccas(sigma_xx, sigma_xy, sigma_yx, sigma_yy, epsilon, verbose=True):\n","    \"\"\"Main cca computation function, takes in variances and crossvariances.\n","\n","    This function takes in the covariances and cross covariances of X, Y,\n","    preprocesses them (removing small magnitudes) and outputs the raw results of\n","    the cca computation, including cca directions in a rotated space, and the\n","    cca correlation coefficient values.\n","\n","    Args:\n","              sigma_xx: 2d numpy array, (num_neurons_x, num_neurons_x)\n","                        variance matrix for x\n","              sigma_xy: 2d numpy array, (num_neurons_x, num_neurons_y)\n","                        crossvariance matrix for x,y\n","              sigma_yx: 2d numpy array, (num_neurons_y, num_neurons_x)\n","                        crossvariance matrix for x,y (conj) transpose of sigma_xy\n","              sigma_yy: 2d numpy array, (num_neurons_y, num_neurons_y)\n","                        variance matrix for y\n","              epsilon:  small float to help with stabilizing computations\n","              verbose:  boolean on whether to print intermediate outputs\n","\n","    Returns:\n","              [ux, sx, vx]: [numpy 2d array, numpy 1d array, numpy 2d array]\n","                            ux and vx are (conj) transposes of each other, being\n","                            the canonical directions in the X subspace.\n","                            sx is the set of canonical correlation coefficients-\n","                            how well corresponding directions in vx, Vy correlate\n","                            with each other.\n","              [uy, sy, vy]: Same as above, but for Y space\n","              invsqrt_xx:   Inverse square root of sigma_xx to transform canonical\n","                            directions back to original space\n","              invsqrt_yy:   Same as above but for sigma_yy\n","              x_idxs:       The indexes of the input sigma_xx that were pruned\n","                            by remove_small\n","              y_idxs:       Same as above but for sigma_yy\n","    \"\"\"\n","\n","    (sigma_xx, sigma_xy, sigma_yx, sigma_yy, x_idxs, y_idxs) = remove_small(\n","        sigma_xx, sigma_xy, sigma_yx, sigma_yy, epsilon\n","    )\n","\n","    numx = sigma_xx.shape[0]\n","    numy = sigma_yy.shape[0]\n","\n","    if numx == 0 or numy == 0:\n","        return (\n","            [0, 0, 0],\n","            [0, 0, 0],\n","            np.zeros_like(sigma_xx),\n","            np.zeros_like(sigma_yy),\n","            x_idxs,\n","            y_idxs,\n","        )\n","\n","    if verbose:\n","        print(\"adding eps to diagonal and taking inverse\")\n","    sigma_xx += epsilon * np.eye(numx)\n","    sigma_yy += epsilon * np.eye(numy)\n","    inv_xx = np.linalg.pinv(sigma_xx)\n","    inv_yy = np.linalg.pinv(sigma_yy)\n","\n","    if verbose:\n","        print(\"taking square root\")\n","    invsqrt_xx = positivedef_matrix_sqrt(inv_xx)\n","    invsqrt_yy = positivedef_matrix_sqrt(inv_yy)\n","\n","    if verbose:\n","        print(\"dot products...\")\n","    arr = np.dot(invsqrt_xx, np.dot(sigma_xy, invsqrt_yy))\n","\n","    if verbose:\n","        print(\"trying to take final svd\")\n","    u, s, v = np.linalg.svd(arr)\n","\n","    if verbose:\n","        print(\"computed everything!\")\n","\n","    return [u, np.abs(s), v], invsqrt_xx, invsqrt_yy, x_idxs, y_idxs\n","\n","\n","def sum_threshold(array, threshold):\n","    \"\"\"Computes threshold index of decreasing nonnegative array by summing.\n","\n","    This function takes in a decreasing array nonnegative floats, and a\n","    threshold between 0 and 1. It returns the index i at which the sum of the\n","    array up to i is threshold*total mass of the array.\n","\n","    Args:\n","              array: a 1d numpy array of decreasing, nonnegative floats\n","              threshold: a number between 0 and 1\n","\n","    Returns:\n","              i: index at which np.sum(array[:i]) >= threshold\n","    \"\"\"\n","    assert (threshold >= 0) and (threshold <= 1), \"print incorrect threshold\"\n","\n","    for i in range(len(array)):\n","        if np.sum(array[:i]) / np.sum(array) >= threshold:\n","            return i\n","\n","\n","def create_zero_dict(compute_dirns, dimension):\n","    \"\"\"Outputs a zero dict when neuron activation norms too small.\n","\n","    This function creates a return_dict with appropriately shaped zero entries\n","    when all neuron activations are very small.\n","\n","    Args:\n","              compute_dirns: boolean, whether to have zero vectors for directions\n","              dimension: int, defines shape of directions\n","\n","    Returns:\n","              return_dict: a dict of appropriately shaped zero entries\n","    \"\"\"\n","    return_dict = {}\n","    return_dict[\"mean\"] = (np.asarray(0), np.asarray(0))\n","    return_dict[\"sum\"] = (np.asarray(0), np.asarray(0))\n","    return_dict[\"cca_coef1\"] = np.asarray(0)\n","    return_dict[\"cca_coef2\"] = np.asarray(0)\n","    return_dict[\"idx1\"] = 0\n","    return_dict[\"idx2\"] = 0\n","\n","    if compute_dirns:\n","        return_dict[\"cca_dirns1\"] = np.zeros((1, dimension))\n","        return_dict[\"cca_dirns2\"] = np.zeros((1, dimension))\n","\n","    return return_dict\n","\n","\n","def get_cca_similarity(\n","    acts1,\n","    acts2,\n","    epsilon=0.0,\n","    threshold=0.98,\n","    compute_coefs=True,\n","    compute_dirns=False,\n","    verbose=True,\n","):\n","    \"\"\"The main function for computing cca similarities.\n","\n","    This function computes the cca similarity between two sets of activations,\n","    returning a dict with the cca coefficients, a few statistics of the cca\n","    coefficients, and (optionally) the actual directions.\n","\n","    Args:\n","              acts1: (num_neurons1, data_points) a 2d numpy array of neurons by\n","                     datapoints where entry (i,j) is the output of neuron i on\n","                     datapoint j.\n","              acts2: (num_neurons2, data_points) same as above, but (potentially)\n","                     for a different set of neurons. Note that acts1 and acts2\n","                     can have different numbers of neurons, but must agree on the\n","                     number of datapoints\n","\n","              epsilon: small float to help stabilize computations\n","\n","              threshold: float between 0, 1 used to get rid of trailing zeros in\n","                         the cca correlation coefficients to output more accurate\n","                         summary statistics of correlations.\n","\n","\n","              compute_coefs: boolean value determining whether coefficients\n","                             over neurons are computed. Needed for computing\n","                             directions\n","\n","              compute_dirns: boolean value determining whether actual cca\n","                             directions are computed. (For very large neurons and\n","                             datasets, may be better to compute these on the fly\n","                             instead of store in memory.)\n","\n","              verbose: Boolean, whether intermediate outputs are printed\n","\n","    Returns:\n","              return_dict: A dictionary with outputs from the cca computations.\n","                           Contains neuron coefficients (combinations of neurons\n","                           that correspond to cca directions), the cca correlation\n","                           coefficients (how well aligned directions correlate),\n","                           x and y idxs (for computing cca directions on the fly\n","                           if compute_dirns=False), and summary statistics. If\n","                           compute_dirns=True, the cca directions are also\n","                           computed.\n","    \"\"\"\n","\n","    # assert dimensionality equal\n","    assert acts1.shape[1] == acts2.shape[1], \"dimensions don't match\"\n","    # check that acts1, acts2 are transposition\n","    assert acts1.shape[0] < acts1.shape[1], \"input must be number of neurons\" \"by datapoints\"\n","    return_dict = {}\n","\n","    # compute covariance with numpy function for extra stability\n","    numx = acts1.shape[0]\n","    numy = acts2.shape[0]\n","\n","    covariance = np.cov(acts1, acts2)\n","    sigmaxx = covariance[:numx, :numx]\n","    sigmaxy = covariance[:numx, numx:]\n","    sigmayx = covariance[numx:, :numx]\n","    sigmayy = covariance[numx:, numx:]\n","\n","    # rescale covariance to make cca computation more stable\n","    xmax = np.max(np.abs(sigmaxx))\n","    ymax = np.max(np.abs(sigmayy))\n","    sigmaxx /= xmax\n","    sigmayy /= ymax\n","    sigmaxy /= np.sqrt(xmax * ymax)\n","    sigmayx /= np.sqrt(xmax * ymax)\n","\n","    ([u, s, v], invsqrt_xx, invsqrt_yy, x_idxs, y_idxs) = compute_ccas(\n","        sigmaxx, sigmaxy, sigmayx, sigmayy, epsilon=epsilon, verbose=verbose\n","    )\n","\n","    # if x_idxs or y_idxs is all false, return_dict has zero entries\n","    if (not np.any(x_idxs)) or (not np.any(y_idxs)):\n","        return create_zero_dict(compute_dirns, acts1.shape[1])\n","\n","    if compute_coefs:\n","        # also compute full coefficients over all neurons\n","        x_mask = np.dot(x_idxs.reshape((-1, 1)), x_idxs.reshape((1, -1)))\n","        y_mask = np.dot(y_idxs.reshape((-1, 1)), y_idxs.reshape((1, -1)))\n","\n","        return_dict[\"coef_x\"] = u.T\n","        return_dict[\"invsqrt_xx\"] = invsqrt_xx\n","        return_dict[\"full_coef_x\"] = np.zeros((numx, numx))\n","        np.place(return_dict[\"full_coef_x\"], x_mask, return_dict[\"coef_x\"])\n","        return_dict[\"full_invsqrt_xx\"] = np.zeros((numx, numx))\n","        np.place(return_dict[\"full_invsqrt_xx\"], x_mask, return_dict[\"invsqrt_xx\"])\n","\n","        return_dict[\"coef_y\"] = v\n","        return_dict[\"invsqrt_yy\"] = invsqrt_yy\n","        return_dict[\"full_coef_y\"] = np.zeros((numy, numy))\n","        np.place(return_dict[\"full_coef_y\"], y_mask, return_dict[\"coef_y\"])\n","        return_dict[\"full_invsqrt_yy\"] = np.zeros((numy, numy))\n","        np.place(return_dict[\"full_invsqrt_yy\"], y_mask, return_dict[\"invsqrt_yy\"])\n","\n","        # compute means\n","        neuron_means1 = np.mean(acts1, axis=1, keepdims=True)\n","        neuron_means2 = np.mean(acts2, axis=1, keepdims=True)\n","        return_dict[\"neuron_means1\"] = neuron_means1\n","        return_dict[\"neuron_means2\"] = neuron_means2\n","\n","    if compute_dirns:\n","        # orthonormal directions that are CCA directions\n","        cca_dirns1 = (\n","            np.dot(\n","                np.dot(return_dict[\"full_coef_x\"], return_dict[\"full_invsqrt_xx\"]),\n","                (acts1 - neuron_means1),\n","            )\n","            + neuron_means1\n","        )\n","        cca_dirns2 = (\n","            np.dot(\n","                np.dot(return_dict[\"full_coef_y\"], return_dict[\"full_invsqrt_yy\"]),\n","                (acts2 - neuron_means2),\n","            )\n","            + neuron_means2\n","        )\n","\n","    # get rid of trailing zeros in the cca coefficients\n","    idx1 = sum_threshold(s, threshold)\n","    idx2 = sum_threshold(s, threshold)\n","\n","    return_dict[\"cca_coef1\"] = s\n","    return_dict[\"cca_coef2\"] = s\n","    return_dict[\"x_idxs\"] = x_idxs\n","    return_dict[\"y_idxs\"] = y_idxs\n","    # summary statistics\n","    return_dict[\"mean\"] = (np.mean(s[:idx1]), np.mean(s[:idx2]))\n","    return_dict[\"sum\"] = (np.sum(s), np.sum(s))\n","\n","    if compute_dirns:\n","        return_dict[\"cca_dirns1\"] = cca_dirns1\n","        return_dict[\"cca_dirns2\"] = cca_dirns2\n","\n","    return return_dict\n","\n","\n","def robust_cca_similarity(acts1, acts2, threshold=0.98, epsilon=1e-6, compute_dirns=True):\n","    \"\"\"Calls get_cca_similarity multiple times while adding noise.\n","\n","    This function is very similar to get_cca_similarity, and can be used if\n","    get_cca_similarity doesn't converge for some pair of inputs. This function\n","    adds some noise to the activations to help convergence.\n","\n","    Args:\n","              acts1: (num_neurons1, data_points) a 2d numpy array of neurons by\n","                     datapoints where entry (i,j) is the output of neuron i on\n","                     datapoint j.\n","              acts2: (num_neurons2, data_points) same as above, but (potentially)\n","                     for a different set of neurons. Note that acts1 and acts2\n","                     can have different numbers of neurons, but must agree on the\n","                     number of datapoints\n","\n","              threshold: float between 0, 1 used to get rid of trailing zeros in\n","                         the cca correlation coefficients to output more accurate\n","                         summary statistics of correlations.\n","\n","              epsilon: small float to help stabilize computations\n","\n","              compute_dirns: boolean value determining whether actual cca\n","                             directions are computed. (For very large neurons and\n","                             datasets, may be better to compute these on the fly\n","                             instead of store in memory.)\n","\n","    Returns:\n","              return_dict: A dictionary with outputs from the cca computations.\n","                           Contains neuron coefficients (combinations of neurons\n","                           that correspond to cca directions), the cca correlation\n","                           coefficients (how well aligned directions correlate),\n","                           x and y idxs (for computing cca directions on the fly\n","                           if compute_dirns=False), and summary statistics. If\n","                           compute_dirns=True, the cca directions are also\n","                           computed.\n","    \"\"\"\n","\n","    for trial in range(num_cca_trials):\n","        try:\n","            return_dict = get_cca_similarity(acts1, acts2, threshold, compute_dirns)\n","        except np.linalg.LinAlgError:\n","            acts1 = acts1 * 1e-1 + np.random.normal(size=acts1.shape) * epsilon\n","            acts2 = acts2 * 1e-1 + np.random.normal(size=acts1.shape) * epsilon\n","            if trial + 1 == num_cca_trials:\n","                raise\n","\n","    return return_dict\n","    # End of copy from https://github.com/google/svcca/blob/1f3fbf19bd31bd9b76e728ef75842aa1d9a4cd2b/cca_core.py\n","\n","\n","def top_k_pca_comps(singular_values, threshold=0.99):\n","    total_variance = np.sum(singular_values**2)\n","    explained_variance = (singular_values**2) / total_variance\n","    cumulative_variance = np.cumsum(explained_variance)\n","    return np.argmax(cumulative_variance >= threshold * total_variance) + 1\n","\n","\n","def _svcca_original(acts1, acts2):\n","    # Copy from https://github.com/google/svcca/blob/1f3fbf19bd31bd9b76e728ef75842aa1d9a4cd2b/tutorials/001_Introduction.ipynb\n","    # Modification: get_cca_similarity is in the same file.\n","    # Modification: top-k PCA component selection s.t. explained variance > 0.99 total variance\n","    # Mean subtract activations\n","    cacts1 = acts1 - np.mean(acts1, axis=1, keepdims=True)\n","    cacts2 = acts2 - np.mean(acts2, axis=1, keepdims=True)\n","\n","    # Perform SVD\n","    U1, s1, V1 = np.linalg.svd(cacts1, full_matrices=False)\n","    U2, s2, V2 = np.linalg.svd(cacts2, full_matrices=False)\n","\n","    # top-k PCA components only\n","    k1 = top_k_pca_comps(s1)\n","    k2 = top_k_pca_comps(s2)\n","\n","    svacts1 = np.dot(s1[:k1] * np.eye(k1), V1[:k1])\n","    # can also compute as svacts1 = np.dot(U1.T[:20], cacts1)\n","    svacts2 = np.dot(s2[:k2] * np.eye(k2), V2[:k2])\n","    # can also compute as svacts1 = np.dot(U2.T[:20], cacts2)\n","\n","    svcca_results = get_cca_similarity(svacts1, svacts2, epsilon=1e-10, verbose=False)\n","    # End of copy from https://github.com/google/svcca/blob/1f3fbf19bd31bd9b76e728ef75842aa1d9a4cd2b/tutorials/001_Introduction.ipynb\n","    return np.mean(svcca_results[\"cca_coef1\"])\n","\n","\n","# Copied from https://github.com/google/svcca/blob/1f3fbf19bd31bd9b76e728ef75842aa1d9a4cd2b/pwcca.py\n","# Modification: get_cca_similarity is in the same file.\n","def compute_pwcca(acts1, acts2, epsilon=0.0):\n","    \"\"\"Computes projection weighting for weighting CCA coefficients\n","\n","    Args:\n","         acts1: 2d numpy array, shaped (neurons, num_datapoints)\n","         acts2: 2d numpy array, shaped (neurons, num_datapoints)\n","\n","    Returns:\n","         Original cca coefficient mean and weighted mean\n","\n","    \"\"\"\n","    sresults = get_cca_similarity(\n","        acts1,\n","        acts2,\n","        epsilon=epsilon,\n","        compute_dirns=False,\n","        compute_coefs=True,\n","        verbose=False,\n","    )\n","    if np.sum(sresults[\"x_idxs\"]) <= np.sum(sresults[\"y_idxs\"]):\n","        dirns = (\n","            np.dot(\n","                sresults[\"coef_x\"],\n","                (acts1[sresults[\"x_idxs\"]] - sresults[\"neuron_means1\"][sresults[\"x_idxs\"]]),\n","            )\n","            + sresults[\"neuron_means1\"][sresults[\"x_idxs\"]]\n","        )\n","        coefs = sresults[\"cca_coef1\"]\n","        acts = acts1\n","        idxs = sresults[\"x_idxs\"]\n","    else:\n","        dirns = (\n","            np.dot(\n","                sresults[\"coef_y\"],\n","                (acts1[sresults[\"y_idxs\"]] - sresults[\"neuron_means2\"][sresults[\"y_idxs\"]]),\n","            )\n","            + sresults[\"neuron_means2\"][sresults[\"y_idxs\"]]\n","        )\n","        coefs = sresults[\"cca_coef2\"]\n","        acts = acts2\n","        idxs = sresults[\"y_idxs\"]\n","    P, _ = np.linalg.qr(dirns.T)\n","    weights = np.sum(np.abs(np.dot(P.T, acts[idxs].T)), axis=1)\n","    weights = weights / np.sum(weights)\n","\n","    return np.sum(weights * coefs), weights, coefs\n","    # End of copy from https://github.com/google/svcca/blob/1f3fbf19bd31bd9b76e728ef75842aa1d9a4cd2b/pwcca.py\n","\n","\n","##################################################################################\n","\n","from typing import Union  # noqa:e402\n","\n","import numpy.typing as npt  # noqa:e402\n","import torch  # noqa:e402\n","\n","# from repsim.measures.utils import (\n","#     SHAPE_TYPE,\n","#     flatten,\n","#     resize_wh_reps,\n","#     to_numpy_if_needed,\n","#     RepresentationalSimilarityMeasure,\n","# )  # noqa:e402\n","\n","\n","def svcca(\n","    R: Union[torch.Tensor, npt.NDArray],\n","    Rp: Union[torch.Tensor, npt.NDArray],\n","    shape: SHAPE_TYPE,\n",") -> float:\n","    R, Rp = flatten(R, Rp, shape=shape)\n","    R, Rp = to_numpy_if_needed(R, Rp)\n","    return _svcca_original(R.T, Rp.T)\n","\n","\n","def pwcca(\n","    R: Union[torch.Tensor, npt.NDArray],\n","    Rp: Union[torch.Tensor, npt.NDArray],\n","    shape: SHAPE_TYPE,\n",") -> float:\n","    R, Rp = flatten(R, Rp, shape=shape)\n","    R, Rp = to_numpy_if_needed(R, Rp)\n","    return compute_pwcca(R.T, Rp.T)[0]\n","\n","\n","class SVCCA(RepresentationalSimilarityMeasure):\n","    def __init__(self):\n","        super().__init__(\n","            sim_func=svcca,\n","            larger_is_more_similar=True,\n","            is_metric=False,\n","            is_symmetric=True,\n","            invariant_to_affine=False,\n","            invariant_to_invertible_linear=False,\n","            invariant_to_ortho=True,\n","            invariant_to_permutation=True,\n","            invariant_to_isotropic_scaling=True,\n","            invariant_to_translation=True,\n","        )\n","\n","    def __call__(self, R: torch.Tensor | npt.NDArray, Rp: torch.Tensor | npt.NDArray, shape: SHAPE_TYPE) -> float:\n","        if shape == \"nchw\":\n","            # Move spatial dimensions into the sample dimension\n","            # If not the same spatial dimension, resample via FFT.\n","            R, Rp = align_spatial_dimensions(R, Rp)\n","            shape = \"nd\"\n","\n","        return self.sim_func(R, Rp, shape)\n","\n","\n","class PWCCA(RepresentationalSimilarityMeasure):\n","    def __init__(self):\n","        super().__init__(\n","            sim_func=pwcca,\n","            larger_is_more_similar=True,\n","            is_metric=False,\n","            is_symmetric=False,\n","            invariant_to_affine=False,\n","            invariant_to_invertible_linear=False,\n","            invariant_to_ortho=False,\n","            invariant_to_permutation=False,\n","            invariant_to_isotropic_scaling=True,\n","            invariant_to_translation=True,\n","        )\n","\n","    def __call__(self, R: torch.Tensor | npt.NDArray, Rp: torch.Tensor | npt.NDArray, shape: SHAPE_TYPE) -> float:\n","        if shape == \"nchw\":\n","            # Move spatial dimensions into the sample dimension\n","            # If not the same spatial dimension, resample via FFT.\n","            R, Rp = align_spatial_dimensions(R, Rp)\n","            shape = \"nd\"\n","\n","        return self.sim_func(R, Rp, shape)"],"metadata":{"id":"LO8o8I5owA7p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## get rand"],"metadata":{"id":"aQ_3rxDtd3Mc"}},{"cell_type":"code","source":["def score_rand(num_feats, sim_fn, shapereq_bool=False):\n","    all_rand_scores = []\n","    # num_feats = len(uniq_corr_indices_AB_forA)\n","    for i in range(10):\n","        rand_modA_feats = np.random.randint(low=0, high=weight_matrix_np.shape[0], size=num_feats).tolist()\n","        rand_modB_feats = np.random.randint(low=0, high=weight_matrix_2.shape[0], size=num_feats).tolist()\n","\n","        if shapereq_bool:\n","            score = sim_fn(weight_matrix_np[rand_modA_feats], weight_matrix_2[rand_modB_feats], \"nd\")\n","        else:\n","            score = sim_fn(weight_matrix_np[rand_modA_feats], weight_matrix_2[rand_modB_feats])\n","        all_rand_scores.append(score)\n","    print(sum(all_rand_scores) / len(all_rand_scores))\n","    plt.hist(all_rand_scores)\n","    plt.show()\n","    return sum(all_rand_scores) / len(all_rand_scores)"],"metadata":{"id":"BqIiTtkid4qA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import random\n","# row_idxs = list(range(weight_matrix_2.shape[0]))\n","# random.shuffle(row_idxs)\n","# jaccard_similarity(weight_matrix_np, weight_matrix_2[row_idxs])"],"metadata":{"id":"4MuzPsULu30o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# load models"],"metadata":{"id":"0szD4V-dtAYx"}},{"cell_type":"code","source":["from transformer_lens import HookedTransformer\n","model = HookedTransformer.from_pretrained(\"gpt2-small\", device = device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9RUsdhgPxJro","executionInfo":{"status":"ok","timestamp":1724428481634,"user_tz":-60,"elapsed":4918,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"6314c04a-ccfa-4d66-fda6-949a70fe7c59"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Loaded pretrained model gpt2-small into HookedTransformer\n"]}]},{"cell_type":"code","source":["model_2 = HookedTransformer.from_pretrained(\"pythia-70m-deduped\", device = device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"87AkxrOp2l-S","executionInfo":{"status":"ok","timestamp":1724428483225,"user_tz":-60,"elapsed":1597,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"8ec68a8b-fcda-405a-e238-c8d1d878d7f9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"stream","name":"stdout","text":["Loaded pretrained model pythia-70m-deduped into HookedTransformer\n"]}]},{"cell_type":"code","source":["model_2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"49O9ylWi48ln","executionInfo":{"status":"ok","timestamp":1724427522220,"user_tz":-60,"elapsed":440,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"333a6cd6-9f0c-4235-bedf-51405a3c91ea"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["HookedTransformer(\n","  (embed): Embed()\n","  (hook_embed): HookPoint()\n","  (blocks): ModuleList(\n","    (0-5): 6 x TransformerBlock(\n","      (ln1): LayerNormPre(\n","        (hook_scale): HookPoint()\n","        (hook_normalized): HookPoint()\n","      )\n","      (ln2): LayerNormPre(\n","        (hook_scale): HookPoint()\n","        (hook_normalized): HookPoint()\n","      )\n","      (attn): Attention(\n","        (hook_k): HookPoint()\n","        (hook_q): HookPoint()\n","        (hook_v): HookPoint()\n","        (hook_z): HookPoint()\n","        (hook_attn_scores): HookPoint()\n","        (hook_pattern): HookPoint()\n","        (hook_result): HookPoint()\n","        (hook_rot_k): HookPoint()\n","        (hook_rot_q): HookPoint()\n","      )\n","      (mlp): MLP(\n","        (hook_pre): HookPoint()\n","        (hook_post): HookPoint()\n","      )\n","      (hook_attn_in): HookPoint()\n","      (hook_q_input): HookPoint()\n","      (hook_k_input): HookPoint()\n","      (hook_v_input): HookPoint()\n","      (hook_mlp_in): HookPoint()\n","      (hook_attn_out): HookPoint()\n","      (hook_mlp_out): HookPoint()\n","      (hook_resid_pre): HookPoint()\n","      (hook_resid_post): HookPoint()\n","    )\n","  )\n","  (ln_final): LayerNormPre(\n","    (hook_scale): HookPoint()\n","    (hook_normalized): HookPoint()\n","  )\n","  (unembed): Unembed()\n",")"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","source":["# compare dataset tokenization"],"metadata":{"id":"wtaez_m7u7V2"}},{"cell_type":"code","source":["# import pickle\n","# file_path = '/content/drive/MyDrive/sae_files/batch_tokens_anySamps_v1.pkl'\n","# with open(file_path, 'rb') as f:\n","#     batch_tokens = pickle.load(f)\n","\n","# batch_tokens = batch_tokens[:100]"],"metadata":{"id":"1TbQ6V10kiYv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from transformers import AutoTokenizer\n","\n","# tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")"],"metadata":{"id":"2rU8hg2Iz7HX","executionInfo":{"status":"ok","timestamp":1724426706384,"user_tz":-60,"elapsed":3661,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["cd9425dd9954474ba55586b8f7ea7d80","8d9d13fc0bcb4ea6b224f4f62048a762","76cc04159c42459e886fc51ace6f5f8a","95b75bdc4a124416abc3efc820e8f46c","5bcbeb73399246b89836b35b05db06da","835add2a0a9e48ae8cd8538a45e60f6b","e8e01c6fc9904477b667dc42e2b268b6","390812621d344643801e3e2d8a412299","c4740f4496a2470f8a63089442cce0e2","66fd21d104c84f588c5c3701b0a66d99","32eaeb5a517f453dbacc447db698729f","b1a9902839a44772940589a0f344a44a","2aa0df33c22147059225e58c09af4655","02afe8646d3f4db1a757fdee6cca5f78","89702a3116814455aa8444a41115505f","6b9249c4a9cb4eb1bc349ef90d971928","5d4bc1ad788b4c53a0374566f25950a5","e2182df0315940ef9814427feafec2f0","7d19bab0b0d146cc9ee06737501be064","0172e961dd6445c8b84c679a97da5e78","8c87c973f5e64a2abe9ec97fc6a9aa7e","578a0ccb02a74769848e73a0af153974","7e6c7993185543bba36548537243788e","635ed846cf9c45e5ba896e36a11f8f82","64b682013baf44d492f6067c6ac59a14","da813d6c54154ac49cc353358085881d","6cc7f5cf99ca4ca58ccdd779e94846a8","9596a6bf9755446bb26acc5573326667","85ef97a4c47340f9afa46e4d9824b7c2","25d7afcc6abb479e9770a9c3150edbd8","6f0994bdf8184f08bd2868d794540174","0e5050daef3d462dad40b1d6e3f179d7","42f93b089fa144d7bebeda688956cfbf","788779df987b4f8da4b2eb655107bf6f","b9874981882442a6be4ce1faa793dfc5","0e61be38b2a64db785a9886555ce8717","25d4544c1780486f83e4c4e17b5eecec","c286608988f643ffad2b525aef428e19","397ebb4e1299497ca4532ea4eadc75d6","e9b4c0ab4cd14c13a1d5cb81a5196112","a43ea645dd2c4587b9110d5c9e124ab1","5bef7cecb97a4e2fb0b8d70e4a1a14f7","34e697f8897f4393a15664290efe4495","2223f2b12d1e41aeb2e87a966a38bd31","eab9e978671447a997d32df3d5a03792","b79f2f667f7b4327a923ef07220253fd","48f874b0b5a1491985288b8971dea74e","8b01affba20d4aaf8afe2334512d25fe","468f029cb4964707bb6217d00b5e238d","d239ea5683d84f6aae5efefa5dd7caa9","0ae63f870186471fa4a77f67c92988aa","f8bf115ef0224fb9b356ece5004f83f5","7a50896eb9944206985f791f9e28a01c","6ae1acb69c8a4946a85d71c53cd5697b","26fb6248846843f3884768bf46479e89"],"height":177},"outputId":"16ded9b4-60b0-4214-afc3-79d51330f59c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd9425dd9954474ba55586b8f7ea7d80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1a9902839a44772940589a0f344a44a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e6c7993185543bba36548537243788e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"788779df987b4f8da4b2eb655107bf6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eab9e978671447a997d32df3d5a03792"}},"metadata":{}}]},{"cell_type":"code","source":["from transformer_lens.utils import tokenize_and_concatenate\n","from datasets import load_dataset\n","\n","dataset = load_dataset(\"roneneldan/TinyStories\", streaming=False)\n","test_dataset = dataset['validation']"],"metadata":{"id":"5S1OJhS07DCD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eB4faILY9ZnK","executionInfo":{"status":"ok","timestamp":1724428690114,"user_tz":-60,"elapsed":539,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"97245244-4e61-440f-ab2d-3dcf9fcbec20"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['text'],\n","    num_rows: 21990\n","})"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["test_dataset['text'][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"id":"az4HwwB09bqj","executionInfo":{"status":"ok","timestamp":1724428709602,"user_tz":-60,"elapsed":612,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"48438f82-0d2c-4e21-b5f9-5ea8709b4f60"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Spot. Spot saw the shiny car and said, \"Wow, Kitty, your car is so bright and clean!\" Kitty smiled and replied, \"Thank you, Spot. I polish it every day.\"\\n\\nAfter playing with the car, Kitty and Spot felt thirsty. They found a small pond with clear water. They drank the water and felt very happy. They played together all day and became best friends.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["onesamp_tokens = model.tokenizer.encode(test_dataset['text'][0])\n","len(onesamp_tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PKrSCLPV9jDF","executionInfo":{"status":"ok","timestamp":1724428786438,"user_tz":-60,"elapsed":527,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"47490d5a-2daf-42b9-beaa-0a0aac5aa031"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["82"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["token_dataset = tokenize_and_concatenate(\n","    dataset = test_dataset,\n","    tokenizer = model.tokenizer, # type: ignore\n","    streaming=True,\n","    # max_length=sae.cfg.context_size,\n","    max_length=128,\n","    # add_bos_token=sae.cfg.prepend_bos,\n","    add_bos_token=False,\n",")"],"metadata":{"id":"iaZTIla7b0hH","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["92b11eaf1a5e42c0a75e4e1f83df041f","34d2d801ba6a4e2c896e8c990c0ed366","18e8419a5f95494bb4cbcc7f94422553","64a82e42aae340449bde6d0e364a2d98","ad44a210f27541f08c5d53550b46a5df","b5e1558f3dbd47bdb8579cb0e10a3be2","5d97573e5c014817b2a7d0089d87e7ac","98f64c29268a4820927f8ad4ebb49319","1435f2aa5ed741ae8a024d707bd26dbd","a486699d64c740bc9b16e508083d84ae","c58327d3b27744eb849aa763cdecdd04"]},"executionInfo":{"status":"ok","timestamp":1724428673788,"user_tz":-60,"elapsed":4076,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"175ba202-6d79-4fe1-edf1-c39fa170c57f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/21990 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92b11eaf1a5e42c0a75e4e1f83df041f"}},"metadata":{}}]},{"cell_type":"code","source":["token_dataset_2 = tokenize_and_concatenate(\n","    dataset = test_dataset,\n","    tokenizer = model_2.tokenizer, # type: ignore\n","    streaming=True,\n","    # max_length=sae.cfg.context_size,\n","    max_length=128,\n","    # add_bos_token=sae.cfg.prepend_bos,\n","    add_bos_token=False,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["81fefd9f184246238f2c98e1693f4b50","1365d1e89c3e4ac3bef9e5b36e4f2a61","a61d5696ef614a919b488aa49ec2bd3a","e6d7a22e1d6749ba98e4acc41ef83fef","7a3b41ab99c940ea9fd652d5ec59ffad","9951c940d6ec40e1a57a66c47ee912ea","0ed7cacf6fa14623bae9be1b76a4a373","546b6c13edce49c3bf680a4e51c6b2aa","d95323e0147b4acf965cf58cb4bc8341","afeaa408890747f88ad177d830fbd69a","4fb3f5d484214922b32ebfee7f08c88d"]},"id":"XKwtaOpf6k50","executionInfo":{"status":"ok","timestamp":1724428669729,"user_tz":-60,"elapsed":4753,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"dc3218d0-f0c1-4086-f3ef-63168c0df654"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/21990 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81fefd9f184246238f2c98e1693f4b50"}},"metadata":{}}]},{"cell_type":"code","source":["token_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"neLJUlPN7r7_","executionInfo":{"status":"ok","timestamp":1724428673788,"user_tz":-60,"elapsed":19,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"26d4653d-b95c-44c0-db07-764fddce0951"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['tokens'],\n","    num_rows: 37054\n","})"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["token_dataset_2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hzqbcx687tb2","executionInfo":{"status":"ok","timestamp":1724428674645,"user_tz":-60,"elapsed":8,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"70a25a87-b0c6-4e2d-968e-396ab1cbdc99"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['tokens'],\n","    num_rows: 37124\n","})"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["print(token_dataset[\"tokens\"].shape)\n","token_dataset_2[\"tokens\"].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xhJ1hquS8Dh8","executionInfo":{"status":"ok","timestamp":1724428875251,"user_tz":-60,"elapsed":10,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c0db094e-dbaf-46d3-94e7-0d077483631a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([37054, 128])\n"]},{"output_type":"execute_result","data":{"text/plain":["torch.Size([37124, 128])"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["batch_tokens_1 = token_dataset[:500][\"tokens\"]\n","batch_tokens_1.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ikCJcUvR70yr","executionInfo":{"status":"ok","timestamp":1724428871742,"user_tz":-60,"elapsed":568,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"1bfffcf7-e472-4d5d-dfa7-efc7da378b1f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([500, 128])"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["batch_tokens_1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nScrvN0L78MK","executionInfo":{"status":"ok","timestamp":1724428873822,"user_tz":-60,"elapsed":8,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"2555f48e-f6ce-47b4-9342-bb2e0725cf77"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[32565,    13, 15899,  ..., 30284, 12788,    13],\n","        [ 1375,   550,  1239,  ...,   617,  1263,  5667],\n","        [  284,  1234,   739,  ...,   714, 12080,  1997],\n","        ...,\n","        [   13,  1375,  6151,  ...,   340,   355,   922],\n","        [  355,   649,   526,  ...,   366,  1026,   338],\n","        [ 1165,  1327,   284,  ...,   257,  1263,  6769]])"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["batch_tokens_2 = token_dataset_2[:500][\"tokens\"]\n","batch_tokens_2.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P9LYNePm75FX","executionInfo":{"status":"ok","timestamp":1724428866802,"user_tz":-60,"elapsed":536,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f9344fca-f724-410b-b499-39620d58ce5a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([500, 128])"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["batch_tokens_2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1ZX9F1HL-BbK","executionInfo":{"status":"ok","timestamp":1724428868458,"user_tz":-60,"elapsed":8,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9e89983b-8b16-4838-e6fd-1bc555775d21"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[46450,    15, 28238,  ..., 42947, 13599,    15],\n","        [ 1500,   574,  1620,  ...,   690,  1943,  6505],\n","        [  281,  1691,   762,  ...,   812, 12394,  2712],\n","        ...,\n","        [  285,  6518,  1016,  ...,  9187, 19880,   587],\n","        [   15,  1500,  2427,  ...,  2243,    15,   346],\n","        [24681,  2577,    13,  ...,  1652,  3226,  4907]])"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["model.tokenizer.decode(batch_tokens_1[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":88},"id":"8LSaHWOo-Let","executionInfo":{"status":"ok","timestamp":1724428912762,"user_tz":-60,"elapsed":856,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"561be85b-5a09-4dd1-b69e-6209fac3419d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Spot. Spot saw the shiny car and said, \"Wow, Kitty, your car is so bright and clean!\" Kitty smiled and replied, \"Thank you, Spot. I polish it every day.\"\\n\\nAfter playing with the car, Kitty and Spot felt thirsty. They found a small pond with clear water. They drank the water and felt very happy. They played together all day and became best friends.Once upon a time, in a big forest, there lived a rhinoceros named Roxy. Roxy loved to climb. She climbed trees, rocks, and hills. One day, Roxy found an icy hill.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["model_2.tokenizer.decode(batch_tokens_1[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":88},"id":"mTNhSqcN-cSp","executionInfo":{"status":"ok","timestamp":1724428966261,"user_tz":-60,"elapsed":888,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"406062a0-5535-4a6a-d003-12e8c0c57682"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'stre,�^{-it foam bothentone*ateuran* builds* which bothation cont handleent++iction builds Momentnut*ateARD con*�,ly ordinance yons thoseorm\\x15\\x15 knew anythingodit both* buildsent� ur PW, found\\n     enrayusionsodably redu, found330it reduent ur diffe autom, found occur keep\\n    thoseentuclegg image, OfficeNameenake*roen studyeffect* ev sexualen σ wment Schools ;quRole,quRolereesaspay, state wounds quarter*enz*entrowing, self those*quRole\\n      to FBagent,'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["model_2.tokenizer.decode(batch_tokens_2[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":88},"id":"4PTHraZV-Rxk","executionInfo":{"status":"ok","timestamp":1724429010452,"user_tz":-60,"elapsed":619,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b60abb74-f670-46b9-8f5a-affda4a329d6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Spot. Spot saw the shiny car and said, \"Wow, Kitty, your car is so bright and clean!\" Kitty smiled and replied, \"Thank you, Spot. I polish it every day.\"\\n\\nAfter playing with the car, Kitty and Spot felt thirsty. They found a small pond with clear water. They drank the water and felt very happy. They played together all day and became best friends.Once upon a time, in a big forest, there lived a rhinoceros named Roxy. Roxy loved to climb. She climbed trees, rocks, and hills. One day, Roxy found an icy hill.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["model.tokenizer.decode(batch_tokens_1[80])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":88},"id":"PKGM4ryq-pst","executionInfo":{"status":"ok","timestamp":1724429020570,"user_tz":-60,"elapsed":706,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"83731dab-bf63-4e20-9aba-55e42fbb33f5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["' too much for her and she felt a little deaf. She decided to leave the factory and go home with her mom. But she was happy because she found her doll and she knew that it came from the factory.Once upon a time, there was a little girl named Lily. She loved to play with her toys and eat yummy snacks. One day, her mommy made her a delicious lunch with a sandwich and some fruit.\\n\\nBut when Lily tried to eat her sandwich, she got frustrated because it was too big to fit in her mouth. She tried to take a bite, but it just fell apart. So, she'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["model_2.tokenizer.decode(batch_tokens_2[80])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":88},"id":"RCCOqztd-rwC","executionInfo":{"status":"ok","timestamp":1724429028161,"user_tz":-60,"elapsed":456,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"62cd1e65-3153-4d28-a121-5465537ea806"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["' Lily saw a lot of dolls that looked just like hers. She was so happy! But then she heard a loud noise and covered her ears. Her mom explained that the noise was coming from the factory machines and that they were very loud.\\n\\nLily realized that the noise was too much for her and she felt a little deaf. She decided to leave the factory and go home with her mom. But she was happy because she found her doll and she knew that it came from the factory.Once upon a time, there was a little girl named Lily. She loved to play with her toys and eat yummy snacks. One'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":48}]},{"cell_type":"markdown","metadata":{"id":"BDOowypRDotz"},"source":["# load sae weights"]},{"cell_type":"markdown","source":["## use hf default"],"metadata":{"id":"ynsaFwWVQGi4"}},{"cell_type":"code","source":["!huggingface-cli login"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jjO2jjjLON_l","executionInfo":{"status":"ok","timestamp":1724433158627,"user_tz":-60,"elapsed":8233,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b7fa6f97-aeaa-4e8e-e606-ef583762593e"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n","    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n","    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n","    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n","    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n","\n","    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n","Enter your token (input will not be visible): \n","Add token as git credential? (Y/n) n\n","Token is valid (permission: write).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}]},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM\n","model_path = \"EleutherAI/sae-pythia-70m-32k/layers.4\"\n","model = AutoModelForCausalLM.from_pretrained(model_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":529},"id":"z9fs6Li0OIH7","executionInfo":{"status":"error","timestamp":1724433192936,"user_tz":-60,"elapsed":403,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e7ed37f1-0108-4040-8b4e-d50131a6fd79"},"execution_count":38,"outputs":[{"output_type":"error","ename":"OSError","evalue":"Incorrect path_or_model_id: 'EleutherAI/sae-pythia-70m-32k/layers.4'. Please provide either the path to a local folder or the repo_id of a model on the Hub.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"repo_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mvalidate_repo_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrepo_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         raise HFValidationError(\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;34m\"Repo id must be in the form 'repo_name' or 'namespace/repo_name':\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'EleutherAI/sae-pythia-70m-32k/layers.4'. Use `repo_type` argument if needed.","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-38-0c1f1dd851f2>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"EleutherAI/sae-pythia-70m-32k/layers.4\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m                 \u001b[0;31m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    486\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m                     \u001b[0mCONFIG_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"There was a specific connection error when trying to load {path_or_repo_id}:\\n{err}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHFValidationError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    467\u001b[0m             \u001b[0;34mf\"Incorrect path_or_model_id: '{path_or_repo_id}'. Please provide either the path to a local folder or the repo_id of a model on the Hub.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         ) from e\n","\u001b[0;31mOSError\u001b[0m: Incorrect path_or_model_id: 'EleutherAI/sae-pythia-70m-32k/layers.4'. Please provide either the path to a local folder or the repo_id of a model on the Hub."]}]},{"cell_type":"code","source":["from huggingface_hub import snapshot_download, hf_hub_download\n","from pathlib import Path\n","import torch\n","\n","# Download the specific directory\n","repo_name = \"EleutherAI/sae-pythia-70m-32k\"\n","layer_dir = \"layers.4\"\n","\n","repo_path = Path(\n","    snapshot_download(\n","        repo_name,\n","        allow_patterns=f\"{layer_dir}/*\"\n","    )\n",")\n","\n","print(f\"Downloaded directory: {repo_path / layer_dir}\")\n","\n","# Download the config.json from the main directory\n","config_path = hf_hub_download(repo_name, \"config.json\")\n","print(f\"Downloaded config: {config_path}\")\n","\n","# Load the layer\n","layer_path = repo_path / layer_dir / \"layer.safetensors\"\n","layer = torch.load(layer_path, map_location=\"cpu\")\n","\n","print(\"Layer loaded successfully\")\n","print(f\"Layer keys: {layer.keys()}\")\n","\n","# If you need to use the config\n","import json\n","with open(config_path, 'r') as f:\n","    config = json.load(f)\n","\n","print(f\"Model config: {config}\")\n","\n","# Note: You can't directly use this layer for inference as it's just a part of the model\n","# You would need to integrate it into a complete model architecture to use it"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":512,"referenced_widgets":["9ac67abd72314e8c9f6c8f4e9b704cc0","2217bdf3a2d7403fba9015ecf50e5805","ac9a2c497c8f431db25e386458a8a82c","acc9bc4c815440838e0ed4e4a957ae16","25bbcb7ce36040f3a5bc2edc32fc71f9","a6b930d4febc4880986beb6dc44cf001","1b4be3e1c3ec4879bc389cb6cb90df1d","70410c176f5b460d8f25af9a2b4acfae","8c386bad78a542f6b931d7b9de05f4ed","f80fc36c98884b43b0fa6c711bb2c251","17e2c15a1ade4ed5a09e023089cf37ab"]},"id":"cLZ-mdVdOyAr","executionInfo":{"status":"error","timestamp":1724433323137,"user_tz":-60,"elapsed":391,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"64df8820-a522-4983-9381-886b81279375"},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":["Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ac67abd72314e8c9f6c8f4e9b704cc0"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Downloaded directory: /root/.cache/huggingface/hub/models--EleutherAI--sae-pythia-70m-32k/snapshots/63999ba8720bb4817d02466d7fe11b887ad4e3cc/layers.4\n"]},{"output_type":"error","ename":"EntryNotFoundError","evalue":"404 Client Error. (Request ID: Root=1-66c8c3aa-06fba3df3919547b3a68adfd;3f004087-d9e8-4b21-950a-e98655aa7da8)\n\nEntry Not Found for url: https://huggingface.co/EleutherAI/sae-pythia-70m-32k/resolve/main/config.json.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/EleutherAI/sae-pythia-70m-32k/resolve/main/config.json","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mEntryNotFoundError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-885bafe449f1>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Download the config.json from the main directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mconfig_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhf_hub_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Downloaded config: {config_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1219\u001b[0m         )\n\u001b[1;32m   1220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m   1222\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, headers, proxies, etag_timeout, endpoint, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     \u001b[0;31m# Try to get metadata (etag, commit_hash, url, size) from the server.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m     \u001b[0;31m# If we can't, a HEAD request error is returned.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1282\u001b[0;31m     (url_to_download, etag, commit_hash, expected_size, head_call_error) = _get_metadata_or_catch_error(\n\u001b[0m\u001b[1;32m   1283\u001b[0m         \u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1720\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1722\u001b[0;31m                 \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_hf_file_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1723\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mEntryNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhttp_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1724\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstorage_folder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrelative_filename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1646\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m         \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;31m# Recursively follow relative redirects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    373\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;31m# Perform request and return if status_code is not in the retry list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0merror_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"EntryNotFound\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{response.status_code} Client Error.\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf\"Entry Not Found for url: {response.url}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mEntryNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0merror_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"GatedRepo\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mEntryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-66c8c3aa-06fba3df3919547b3a68adfd;3f004087-d9e8-4b21-950a-e98655aa7da8)\n\nEntry Not Found for url: https://huggingface.co/EleutherAI/sae-pythia-70m-32k/resolve/main/config.json."]}]},{"cell_type":"markdown","source":["## use repo code"],"metadata":{"id":"u9nkrV1ZPJTI"}},{"cell_type":"code","source":["import json\n","from fnmatch import fnmatch\n","from pathlib import Path\n","from typing import NamedTuple\n","\n","import einops\n","import torch\n","from huggingface_hub import snapshot_download\n","from natsort import natsorted\n","from safetensors.torch import load_model, save_model\n","from torch import Tensor, nn\n","\n","# from .config import SaeConfig\n","# from .utils import decoder_impl\n","\n","from sae.config import SaeConfig\n","from sae.utils import decoder_impl"],"metadata":{"id":"zOQZCTiMKqCe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["name = \"EleutherAI/sae-pythia-70m-32k\"\n","hookpoint = \"layers.4\"\n","\n","repo_path = Path(\n","            snapshot_download(\n","                name,\n","                allow_patterns=f\"{hookpoint}/*\" if hookpoint is not None else None,\n","                # allow_patterns = None\n","            )\n","        )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["13406b7e549048abb7ab6fc11b13612a","e47fdfa52c474db3bb39cf9287827ac6","1af394b5036b45078d5c5252f9b5f57c","cd2c690fb22147d6b87d4331aa4463be","e55ce1cc237a41f2a6b77adc459cfe05","325f7b8520c1455b9721827abd8635ce","d9ed56c8e1704b9a9dba16456ee30bde","2a5c2dc347af4abb9e292f91768a10cf","f81c67ca91cd47b18d4dcb57a390e8b7","bfb6f7e8f04a4f23a37359758c353c1f","cd52761112f544f0b18858ea9433e8af"]},"id":"GV4sHK-2KlI8","executionInfo":{"status":"ok","timestamp":1724433491604,"user_tz":-60,"elapsed":312,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f5a1d0b3-4730-414b-cf16-9507cbf06e0d"},"execution_count":47,"outputs":[{"output_type":"display_data","data":{"text/plain":["Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13406b7e549048abb7ab6fc11b13612a"}},"metadata":{}}]},{"cell_type":"code","source":["repo_path"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a6SHyX2bK6y9","executionInfo":{"status":"ok","timestamp":1724433494624,"user_tz":-60,"elapsed":14,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"be7e92b3-8031-4b56-83dc-acf849a37a4a"},"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PosixPath('/root/.cache/huggingface/hub/models--EleutherAI--sae-pythia-70m-32k/snapshots/63999ba8720bb4817d02466d7fe11b887ad4e3cc')"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["if hookpoint is not None:\n","    repo_path = repo_path / hookpoint\n","repo_path"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c1UGe1tEPviz","executionInfo":{"status":"ok","timestamp":1724433504145,"user_tz":-60,"elapsed":392,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c2ce7f9f-8540-4509-d776-dd89dfbd218f"},"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PosixPath('/root/.cache/huggingface/hub/models--EleutherAI--sae-pythia-70m-32k/snapshots/63999ba8720bb4817d02466d7fe11b887ad4e3cc/layers.4')"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["path = Path(repo_path)\n","path"],"metadata":{"id":"us0AVskXMZIw","executionInfo":{"status":"ok","timestamp":1724433508139,"user_tz":-60,"elapsed":349,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4a778ec2-fc4e-4d7c-a5b0-4564eaf78b77"},"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PosixPath('/root/.cache/huggingface/hub/models--EleutherAI--sae-pythia-70m-32k/snapshots/63999ba8720bb4817d02466d7fe11b887ad4e3cc/layers.4')"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["# f = path / \"cfg.json\"\n","# cfg_dict = json.load(f)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":280},"id":"uPg_l37vKQq-","executionInfo":{"status":"error","timestamp":1724433513363,"user_tz":-60,"elapsed":327,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0fd682c1-320e-4cc1-9fdd-35a0abec51bd"},"execution_count":51,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'PosixPath' object has no attribute 'read'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-51-12af1c00ab44>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"cfg.json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcfg_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mkwarg\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mJSONDecoder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m     return loads(fp.read(),\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'PosixPath' object has no attribute 'read'"]}]},{"cell_type":"code","source":["# cfg_dict = {\"expansion_factor\": 32, \"normalize_decoder\": true, \"num_latents\": 32768, \"k\": 16, \"signed\": false, \"d_in\": 512}\n","cfg_dict = {\"expansion_factor\": 32, \"normalize_decoder\": True, \"num_latents\": 32768, \"k\": 16, \"d_in\": 512}"],"metadata":{"id":"bjYIVrknLS64"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["d_in = cfg_dict.pop(\"d_in\")\n","cfg = SaeConfig(**cfg_dict)"],"metadata":{"id":"ir8cF8XjLjct"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","decoder = True"],"metadata":{"id":"LpvDwVMlMFZg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sae = Sae(d_in, cfg, device=device, decoder=decoder)"],"metadata":{"id":"BK1VziauLzoF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# customname = Path(\"EleutherAI/sae-pythia-70m-32k/layers.4\")\n","customname = Path(\"/root/.cache/huggingface/hub/models--EleutherAI--sae-pythia-70m-32k/layers.4\")\n","\n","load_model(\n","    model=sae,\n","    filename=str(path / \"sae.safetensors\"),\n","    # filename=str(customname / \"sae.safetensors\"),\n","    device=str(device),\n","    # TODO: Maybe be more fine-grained about this in the future?\n","    strict=decoder,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3q6kPLTILapP","executionInfo":{"status":"ok","timestamp":1724433526118,"user_tz":-60,"elapsed":275,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9a3bccc4-64b1-4cd3-b98f-c33ad3b50404"},"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(set(), [])"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["sae"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ioUzh3xCP7AZ","executionInfo":{"status":"ok","timestamp":1724433807559,"user_tz":-60,"elapsed":301,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"37a784b7-909c-43f0-cb92-99dff282d114"},"execution_count":59,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sae(\n","  (encoder): Linear(in_features=512, out_features=32768, bias=True)\n",")"]},"metadata":{},"execution_count":59}]},{"cell_type":"markdown","source":["## readme code"],"metadata":{"id":"FGAJsdS-P5v0"}},{"cell_type":"code","source":["from sae import Sae\n","\n","sae = Sae.load_from_hub(\"EleutherAI/sae-pythia-70m-32k\", hookpoint=\"layers.4\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":475,"referenced_widgets":["9293fdb77e9249389ef71bf08362d5fc","6478f4d83379425ba8c1df8213144540","6e68cb78d4bc4d048e3df152ee991615","4093318f7cfe4bf29374460b053fdab0","31c8c8adf6334634abdd6a9a70226da3","81daf63344eb41e4846a3641f0bed8ee","52343b7901c844568d9cf38a65c0c778","27e063402dc5415cb5f5f6c1233bffe9","39635f1371f64ba69ccf44db92b39b58","b03e9cad590a4577b94ca346823cd67f","ce3c5f2a52f0466db0d79359470abded"]},"id":"-R_wdhu1Dbyi","executionInfo":{"status":"error","timestamp":1724431701711,"user_tz":-60,"elapsed":332,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"6a226ae3-66d4-4b97-9fec-5deb74f123d2"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9293fdb77e9249389ef71bf08362d5fc"}},"metadata":{}},{"output_type":"error","ename":"TypeError","evalue":"SaeConfig.__init__() got an unexpected keyword argument 'signed'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-3a1ce6ff41c0>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msae\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSae\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_hub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"EleutherAI/sae-pythia-70m-32k\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhookpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"layers.4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sae/sae.py\u001b[0m in \u001b[0;36mload_from_hub\u001b[0;34m(name, hookpoint, device, decoder)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No config file found; try specifying a layer.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sae/sae.py\u001b[0m in \u001b[0;36mload_from_disk\u001b[0;34m(path, device, decoder)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mcfg_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0md_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"d_in\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaeConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcfg_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0msae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: SaeConfig.__init__() got an unexpected keyword argument 'signed'"]}]},{"cell_type":"markdown","source":["## get weights"],"metadata":{"id":"LTIalnLOP9jK"}},{"cell_type":"code","source":["# i=4\n","# layer_name = f\"blocks.{i}.hook_mlp_out\""],"metadata":{"id":"lx8vu9EO2PGX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","import torch\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-70m\")\n","inputs = tokenizer(\"Hello, world!\", return_tensors=\"pt\")\n","\n","with torch.inference_mode():\n","    model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/pythia-70m\")\n","    outputs = model(**inputs, output_hidden_states=True)\n","\n","    latent_acts = []\n","    # for sae, hidden_state in zip(sae.values(), outputs.hidden_states):\n","    #     latent_acts.append(sae.encode(hidden_state))\n","    hidden_state = outputs.hidden_states[0].to(\"cuda\")\n","    latent_acts.append(sae.encode(hidden_state))\n","\n","# Do stuff with the latent activations"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"urO2FVq5QMGR","executionInfo":{"status":"ok","timestamp":1724433891526,"user_tz":-60,"elapsed":922,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c64a0537-e452-403b-d8a9-07687c3accc4"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["latent_acts[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rm-ic9tsRfhy","executionInfo":{"status":"ok","timestamp":1724434006199,"user_tz":-60,"elapsed":378,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a0314e21-8c50-4d97-870d-304a358ad9b6"},"execution_count":71,"outputs":[{"output_type":"execute_result","data":{"text/plain":["EncoderOutput(top_acts=tensor([[[1.7851, 1.6191, 4.9452, 1.4809, 3.4012, 1.4681, 2.0225, 1.8950,\n","          1.5732, 1.9552, 1.4505, 2.1096, 1.5919, 1.5391, 2.2954, 1.4151],\n","         [1.8857, 1.7425, 5.0603, 1.5747, 3.4103, 1.9822, 1.9028, 1.5522,\n","          2.0212, 1.5189, 2.1694, 1.5825, 1.6180, 1.4946, 2.3708, 1.4733],\n","         [1.8152, 1.7859, 5.0465, 1.5751, 3.4583, 1.4827, 2.0198, 1.9277,\n","          1.5339, 1.9976, 1.5091, 2.1539, 1.6178, 1.6473, 2.3836, 1.4505],\n","         [1.8291, 1.7551, 5.0321, 1.5352, 3.4493, 2.1081, 1.8326, 1.5591,\n","          2.0776, 1.5363, 2.1388, 1.6869, 1.5125, 1.4824, 2.3061, 1.4664]]],\n","       device='cuda:0'), top_indices=tensor([[[ 3090,  5741,  6666,  7475,  7510,  7924, 10884, 12341, 13332, 14823,\n","          18072, 18262, 20333, 28071, 31917,  9588],\n","         [ 3090,  5741,  6666,  7475,  7510, 10884, 12341, 13332, 14823, 18072,\n","          18262, 20333, 28071, 31692, 31917,  9588],\n","         [ 3090,  5741,  6666,  7475,  7510,  7924, 10884, 12341, 13332, 14823,\n","          18072, 18262, 20333, 28071, 31917,  9588],\n","         [ 3090,  5741,  6666,  7475,  7510, 10884, 12341, 13332, 14823, 18072,\n","          18262, 20333, 28071, 31692, 31917,  9588]]], device='cuda:0'))"]},"metadata":{},"execution_count":71}]},{"cell_type":"markdown","source":["# get llm actvs"],"metadata":{"id":"xoH3oFoj2aj_"}},{"cell_type":"code","source":["h_store = torch.zeros((batch_tokens_1.shape[0], batch_tokens_1.shape[1], model.cfg.d_model), device=model.cfg.device)\n","\n","def store_h_hook(\n","    pattern: Float[Tensor, \"batch seqlen d_model\"],\n","    hook\n","):\n","    h_store[:] = pattern  # this works b/c changes values, not replaces entire thing\n","\n","model.run_with_hooks(\n","    batch_tokens_1,\n","    return_type = None,\n","    fwd_hooks=[\n","        (layer_name, store_h_hook),\n","    ]\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"Jh5dZAPh2YuH","executionInfo":{"status":"error","timestamp":1724428444830,"user_tz":-60,"elapsed":1832,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0af8424f-3851-4d18-ac0a-49c2f54e41be"},"execution_count":null,"outputs":[{"output_type":"error","ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 376.00 MiB. GPU ","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-54-c8a57091096a>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mh_store\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpattern\u001b[0m  \u001b[0;31m# this works b/c changes values, not replaces entire thing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m model.run_with_hooks(\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mbatch_tokens_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mreturn_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/hook_points.py\u001b[0m in \u001b[0;36mrun_with_hooks\u001b[0;34m(self, fwd_hooks, bwd_hooks, reset_hooks_end, clear_contexts, *model_args, **model_kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfwd_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbwd_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_hooks_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_contexts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhooked_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mhooked_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     def add_caching_hooks(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/HookedTransformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    559\u001b[0m                     )\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m                 residual = block(\n\u001b[0m\u001b[1;32m    562\u001b[0m                     \u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                     \u001b[0;31m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/components/transformer_block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;31m# queries, keys and values, independently.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;31m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             self.attn(\n\u001b[0m\u001b[1;32m    160\u001b[0m                 \u001b[0mquery_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mshortformer_pos_embed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mshortformer_pos_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/components/abstract_attention.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query_input, key_input, value_input, past_kv_cache_entry, additive_attention_mask, attention_mask, position_bias)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mattn_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhook_attn_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhook_pattern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [batch, head_index, query_pos, key_pos]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 376.00 MiB. GPU "]}]},{"cell_type":"code","source":["h_store.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zbX2szJh42v4","executionInfo":{"status":"ok","timestamp":1724428444831,"user_tz":-60,"elapsed":130,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0e934d96-bd0d-4dff-be7d-50bd4bc10ce7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([500, 128, 768])"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["h_store_2 = torch.zeros((batch_tokens.shape[0], batch_tokens.shape[1], model_2.cfg.d_model), device=model_2.cfg.device)\n","\n","def store_h_hook_2(\n","    pattern: Float[Tensor, \"batch seqlen d_model\"],\n","    hook\n","):\n","    h_store_2[:] = pattern  # this works b/c changes values, not replaces entire thing\n","\n","model_2.run_with_hooks(\n","    batch_tokens,\n","    return_type = None,\n","    fwd_hooks=[\n","        (layer_name, store_h_hook_2),\n","    ]\n",")"],"metadata":{"id":"xYUfSLCr4oC2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["h_store_2.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BN_nSnw744iu","executionInfo":{"status":"ok","timestamp":1724427574412,"user_tz":-60,"elapsed":24,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"1b231522-a5db-4860-a795-c1fc015d57bb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([100, 128, 512])"]},"metadata":{},"execution_count":33}]},{"cell_type":"markdown","source":["# get sae actvs"],"metadata":{"id":"UI9Mokc92WJ2"}},{"cell_type":"code","source":["sae.eval()  # prevents error if we're expecting a dead neuron mask for who grads\n","with torch.no_grad():\n","    feature_acts_model_A = sae.encode(h_store)"],"metadata":{"id":"hHYvI3JW2XyL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["feature_acts_model_A.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F15aPBpQ5fbi","executionInfo":{"status":"ok","timestamp":1724427666580,"user_tz":-60,"elapsed":662,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c953eec7-414f-47c8-cfd0-11b63aab62d5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([100, 128, 32768])"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["sae_2.eval()  # prevents error if we're expecting a dead neuron mask for who grads\n","with torch.no_grad():\n","    feature_acts_model_B = sae_2.encode(h_store_2)"],"metadata":{"id":"C-Dc5tHL5LxO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["feature_acts_model_B.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"STOI9wFe5hC5","executionInfo":{"status":"ok","timestamp":1724427674556,"user_tz":-60,"elapsed":548,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3786f972-2000-46f6-9929-300f820baeba"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([100, 128, 32768])"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["first_dim_reshaped = feature_acts_model_A.shape[0] * feature_acts_model_A.shape[1]\n","reshaped_activations_A = feature_acts_model_A.reshape(first_dim_reshaped, feature_acts_model_A.shape[-1]).cpu()\n","# del feature_acts_model_A\n","# torch.cuda.empty_cache()"],"metadata":{"id":"wz-wGtquQ4Yz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reshaped_activations_B = feature_acts_model_B.reshape(first_dim_reshaped, feature_acts_model_B.shape[-1]).cpu()\n","# del feature_acts_model_B\n","# torch.cuda.empty_cache()"],"metadata":{"id":"bpZp2hL55Yfn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# align actvs by common phrase"],"metadata":{"id":"ME1t8l3p_J_m"}},{"cell_type":"code","source":[],"metadata":{"id":"rQXyL5_r_MTi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# get corrs"],"metadata":{"id":"laEABwbq5WUn"}},{"cell_type":"markdown","source":["`batched_correlation(reshaped_activations_B, reshaped_activations_A)` : highest_correlations_indices_AB contains modA's feats as inds, and modB's feats as vals. Use the list with smaller number of features (cols) as the second arg"],"metadata":{"id":"MilBqMRI5vSQ"}},{"cell_type":"code","source":["highest_correlations_indices_AB, highest_correlations_values_AB = batched_correlation(reshaped_activations_B, reshaped_activations_A)\n","highest_correlations_indices_AB = highest_correlations_indices_AB.cpu().numpy()\n","highest_correlations_values_AB = highest_correlations_values_AB.cpu().numpy()"],"metadata":{"id":"ATEVgois5XHb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_unq_pairs = len(list(set(highest_correlations_indices_AB)))\n","print(num_unq_pairs)\n","num_unq_pairs / len(highest_correlations_indices_AB)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1rRyG85M59j2","executionInfo":{"status":"ok","timestamp":1724427790494,"user_tz":-60,"elapsed":450,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9d12d33b-4c5e-4a2d-ef72-4ad3d360d4e4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["5281\n"]},{"output_type":"execute_result","data":{"text/plain":["0.161163330078125"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["sum(highest_correlations_values_AB) / len(highest_correlations_values_AB)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wF1AQkJi50GX","executionInfo":{"status":"ok","timestamp":1724427799196,"user_tz":-60,"elapsed":554,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"dc0f3829-b4fa-4572-b7f9-00843b21377f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.2529074617563083"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["highest_correlations_indices_AB, highest_correlations_values_AB = batched_correlation(reshaped_activations_A, reshaped_activations_B)\n","highest_correlations_indices_AB = highest_correlations_indices_AB.cpu().numpy()\n","highest_correlations_values_AB = highest_correlations_values_AB.cpu().numpy()"],"metadata":{"id":"i7lBeoG16P6X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_unq_pairs = len(list(set(highest_correlations_indices_AB)))\n","print(num_unq_pairs)\n","num_unq_pairs / len(highest_correlations_indices_AB)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724427875556,"user_tz":-60,"elapsed":91,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d29dd12e-104a-470c-dab6-55a612ac8380","id":"r1K58omN6P6Y"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3984\n"]},{"output_type":"execute_result","data":{"text/plain":["0.12158203125"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["sum(highest_correlations_values_AB) / len(highest_correlations_values_AB)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724427879754,"user_tz":-60,"elapsed":627,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a6e13fdd-7187-4b33-ef11-b7960e8c1144","id":"0qHuD5ru6P6Y"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.13051667143872692"]},"metadata":{},"execution_count":45}]},{"cell_type":"markdown","source":["# loop compare gpt2 sae actvs"],"metadata":{"id":"xASAlRVvZgwy"}},{"cell_type":"code","source":["# layer_to_dictscores = {}\n","\n","for i in range(8, 9): # 0, 12\n","    layer_name = f\"blocks.{i}.hook_mlp_out\"\n","    dictscores = {}\n","\n","    sae, cfg_dict, sparsity = SAE.from_pretrained(\n","        release = \"gpt2-small-mlp-out-v5-32k\",\n","        sae_id = layer_name,\n","        device = device\n","    )\n","\n","    weight_matrix_2 = sae.W_dec.cpu()\n","    weight_matrix_2 = weight_matrix_2.detach().numpy()\n","\n","    h_store = torch.zeros((batch_tokens.shape[0], batch_tokens.shape[1], model.cfg.d_model), device=model.cfg.device)\n","    # h_store.shape\n","\n","    def store_h_hook(\n","        pattern: Float[Tensor, \"batch seqlen d_model\"],\n","        hook\n","    ):\n","        h_store[:] = pattern  # this works b/c changes values, not replaces entire thing\n","\n","    model.run_with_hooks(\n","        batch_tokens,\n","        return_type = None,\n","        fwd_hooks=[\n","            (layer_name, store_h_hook),\n","        ]\n","    )\n","\n","    sae.eval()  # prevents error if we're expecting a dead neuron mask for who grads\n","    with torch.no_grad():\n","        feature_acts_model_B = sae.encode(h_store)\n","\n","    reshaped_activations_B = feature_acts_model_B.reshape(first_dim_reshaped, feature_acts_model_B.shape[-1]).cpu()\n","    del feature_acts_model_B\n","    torch.cuda.empty_cache()\n","\n","    \"\"\"\n","    `batched_correlation(reshaped_activations_B, reshaped_activations_A)` : highest_correlations_indices_AB contains modA's feats as inds, and modB's feats as vals. Use the list with smaller number of features (cols) as the second arg\n","    \"\"\"\n","    highest_correlations_indices_AB, highest_correlations_values_AB = batched_correlation(reshaped_activations_B, reshaped_activations_A)\n","    highest_correlations_indices_AB = highest_correlations_indices_AB.cpu().numpy()\n","    highest_correlations_values_AB = highest_correlations_values_AB.cpu().numpy()\n","\n","    # num_unq_pairs = len(list(set(highest_correlations_indices_AB)))\n","    # print(num_unq_pairs)\n","    # num_unq_pairs / len(highest_correlations_indices_AB)\n","\n","    dictscores[\"mean_actv_corr\"] = sum(highest_correlations_values_AB) / len(highest_correlations_values_AB)\n","    # plt.hist(highest_correlations_values_AB)\n","    # plt.show()\n","\n","    ###########\n","    # sim tests\n","\n","    dictscores[\"jaccard_paired\"] = jaccard_similarity(weight_matrix_np, weight_matrix_2[highest_correlations_indices_AB])\n","    # jacc_paired\n","\n","    dictscores[\"jaccard_unpaired\"] = jaccard_similarity(weight_matrix_np, weight_matrix_2)\n","    # jacc_unpaired\n","    # # this takes too long, so just do 1 to 3 runs\n","    # num_feats = len(highest_correlations_indices_AB)\n","    # jacc_unpaired = score_rand(num_feats, jaccard_similarity, shapereq_bool=False)\n","\n","    dictscores[\"svcca_paired\"] = svcca(weight_matrix_np, weight_matrix_2[highest_correlations_indices_AB], \"nd\")\n","    # svcca_paired\n","\n","    dictscores[\"svcca_unpaired\"] = svcca(weight_matrix_np, weight_matrix_2, \"nd\")\n","    # svcca_unpaired\n","    # num_feats = len(highest_correlations_indices_AB)\n","    # svcca_unpaired = score_rand(num_feats, svcca, shapereq_bool=True)\n","\n","    print(\"Layer: \" + str(i))\n","    for key, value in dictscores.items():\n","        print(key + \": \" + str(value))\n","    print(\"\\n\")\n","\n","    layer_to_dictscores[i] = dictscores\n","\n","    # print(\"Jaccard paired: \", jacc_paired)\n","    # print(\"Jaccard unpaired: \", jacc_unpaired)\n","    # print(\"\\n\")\n","    # print(\"SVCCA paired: \", svcca_paired)\n","    # print(\"SVCCA unpaired: \", svcca_unpaired)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391,"referenced_widgets":["bc51cd1c90b24fca96112b7469b523d8","f72ef8e798814259be015cd7f028938b","8e50bb93eb354dbebcc2b03f84808c78","d80df9ff6b974204b45f1b4a15f53daa","2ab07d43507f400abef21adf6f2035af","0e8ecf1b4c52484e87eab3de0508a85a","0d5e8c9d9e914f66825ba392b450ea71","d7fb392070254c0497a527ed17984d1e","39ba615b8a234c4b8a265a3f98035779","08693f8c3d0c4d97bb7e57d079767d01","2c588ea8b3734fc8b196594374fc9dd8","6944176833f84cf4b2fb8d1aea313303","3090ddc4df684922b8a492b06ecf19b2","61d1d8f932eb432e87c7b4d2ea6871d7","1b875baa916748c1aea7a9cdb0de61b2","17c43a62a9d34c2191d56afa24c74e26","e5faf2612ed3412b80cb5833f253f319","8f993f2b416841c88bc74810f9ba3d3d","d5bf14ae97ae449f813f76f373f62e64","04cd8e3b91b4405b881cd41436a1b050","db00c0b4ef804633b53365660608dea4","c5e954a8634643d59513803a166097d3","1055579cb6a3447c8acaef06420a93bd","8d0edce633e9477b8db17be6dc8de527","1c602f52850c4e1e85742b1aaee55730","777b2341229840ff92a280caaa1c8477","48ce739d70fe4ec2a293f8b28dd4f9e6","99f919d5218a4d259175e82581f60028","ef114cd711414ad4be1ea2f902b7cc7c","a088a42752fa42deb8735ed8578b6d98","e9bbea999319420bb22a1db633cbdf88","7fef79beb792460592fe39400718b7d0","44dd4ca5f3d84b3787d75fb275c9538e"]},"id":"nKhAWytXs5dD","executionInfo":{"status":"ok","timestamp":1724346725563,"user_tz":-60,"elapsed":337979,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ba245bc7-9390-4ad9-a651-602e0a64bd61"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Layer: 10\n","mean_actv_corr: 0.4909806964890322\n","jaccard_paired: 0.06071517720056032\n","jaccard_unpaired: 0.0001784653691520468\n","svcca_paired: 0.15264124210467317\n","svcca_unpaired: 0.005066994057900606\n","\n","\n"]},{"output_type":"display_data","data":{"text/plain":["v5_32k_layer_11/cfg.json:   0%|          | 0.00/534 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc51cd1c90b24fca96112b7469b523d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["sae_weights.safetensors:   0%|          | 0.00/201M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6944176833f84cf4b2fb8d1aea313303"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["sparsity.safetensors:   0%|          | 0.00/131k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1055579cb6a3447c8acaef06420a93bd"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Layer: 11\n","mean_actv_corr: 0.4564948389295296\n","jaccard_paired: 0.06165754438504395\n","jaccard_unpaired: 0.00017989309210526315\n","svcca_paired: 0.16128687596529637\n","svcca_unpaired: 0.004618518077183098\n","\n","\n"]}]}]}