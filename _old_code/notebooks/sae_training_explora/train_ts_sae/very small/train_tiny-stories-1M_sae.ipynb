{"cells":[{"cell_type":"markdown","metadata":{"id":"5O8tQblzOVHu"},"source":["# A very basic SAE Training Tutorial\n","\n","Please note that it is very easy for tutorial code to go stale so please have a low bar for raising an issue in the"]},{"cell_type":"markdown","metadata":{"id":"shAFb9-lOVHu"},"source":["## Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":234914,"status":"ok","timestamp":1720554329584,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":-60},"id":"LeRi_tw2dhae","outputId":"74b49c9d-6495-43df-b3f2-a00c7a78b13a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sae-lens\n","  Downloading sae_lens-3.12.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.7/79.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting transformer-lens\n","  Downloading transformer_lens-2.2.0-py3-none-any.whl (174 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.3/174.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting circuitsvis\n","  Downloading circuitsvis-1.43.2-py3-none-any.whl (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting automated-interpretability<0.0.4,>=0.0.3 (from sae-lens)\n","  Downloading automated_interpretability-0.0.3-py3-none-any.whl (56 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting babe<0.0.8,>=0.0.7 (from sae-lens)\n","  Downloading babe-0.0.7-py3-none-any.whl (6.9 kB)\n","Collecting datasets<3.0.0,>=2.17.1 (from sae-lens)\n","  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting matplotlib<4.0.0,>=3.8.3 (from sae-lens)\n","  Downloading matplotlib-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib-inline<0.2.0,>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (0.1.7)\n","Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (3.8.1)\n","Collecting plotly<6.0.0,>=5.19.0 (from sae-lens)\n","  Downloading plotly-5.22.0-py3-none-any.whl (16.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting plotly-express<0.5.0,>=0.4.1 (from sae-lens)\n","  Downloading plotly_express-0.4.1-py2.py3-none-any.whl (2.9 kB)\n","Collecting pytest-profiling<2.0.0,>=1.7.0 (from sae-lens)\n","  Downloading pytest_profiling-1.7.0-py2.py3-none-any.whl (8.3 kB)\n","Collecting python-dotenv<2.0.0,>=1.0.1 (from sae-lens)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Requirement already satisfied: pyyaml<7.0.0,>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (6.0.1)\n","Collecting pyzmq==26.0.0 (from sae-lens)\n","  Downloading pyzmq-26.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (920 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m920.0/920.0 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: safetensors<0.5.0,>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (0.4.3)\n","Requirement already satisfied: transformers<5.0.0,>=4.38.1 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (4.41.2)\n","Requirement already satisfied: typer<0.13.0,>=0.12.3 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (0.12.3)\n","Requirement already satisfied: typing-extensions<5.0.0,>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (4.12.2)\n","Collecting zstandard<0.23.0,>=0.22.0 (from sae-lens)\n","  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m102.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting accelerate>=0.23.0 (from transformer-lens)\n","  Downloading accelerate-0.32.1-py3-none-any.whl (314 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.1/314.1 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting beartype<0.15.0,>=0.14.1 (from transformer-lens)\n","  Downloading beartype-0.14.1-py3-none-any.whl (739 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting better-abc<0.0.4,>=0.0.3 (from transformer-lens)\n","  Downloading better_abc-0.0.3-py3-none-any.whl (3.5 kB)\n","Collecting einops>=0.6.0 (from transformer-lens)\n","  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fancy-einsum>=0.0.3 (from transformer-lens)\n","  Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n","Collecting jaxtyping>=0.2.11 (from transformer-lens)\n","  Downloading jaxtyping-0.2.31-py3-none-any.whl (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (1.25.2)\n","Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (2.0.3)\n","Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (13.7.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (0.1.99)\n","Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (2.3.0+cu121)\n","Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (4.66.4)\n","Collecting wandb>=0.13.5 (from transformer-lens)\n","  Downloading wandb-0.17.4-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: importlib-metadata>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (8.0.0)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from circuitsvis)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from circuitsvis)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from circuitsvis)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from circuitsvis)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from circuitsvis)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from circuitsvis)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from circuitsvis)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from circuitsvis)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from circuitsvis)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.18.1 (from circuitsvis)\n","  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from circuitsvis)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Collecting triton==2.1.0 (from circuitsvis)\n","  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->circuitsvis)\n","  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.1.0->circuitsvis) (3.15.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens) (24.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens) (5.9.5)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens) (0.23.4)\n","Collecting blobfile<3.0.0,>=2.1.1 (from automated-interpretability<0.0.4,>=0.0.3->sae-lens)\n","  Downloading blobfile-2.1.1-py3-none-any.whl (73 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting boostedblob<0.16.0,>=0.15.3 (from automated-interpretability<0.0.4,>=0.0.3->sae-lens)\n","  Downloading boostedblob-0.15.4-py3-none-any.whl (59 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpx<0.28.0,>=0.27.0 (from automated-interpretability<0.0.4,>=0.0.3->sae-lens)\n","  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting numpy>=1.24 (from transformer-lens)\n","  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting orjson<4.0.0,>=3.10.1 (from automated-interpretability<0.0.4,>=0.0.3->sae-lens)\n","  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pytest<9.0.0,>=8.1.2 (from automated-interpretability<0.0.4,>=0.0.3->sae-lens)\n","  Downloading pytest-8.2.2-py3-none-any.whl (339 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m339.9/339.9 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting scikit-learn<2.0.0,>=1.4.2 (from automated-interpretability<0.0.4,>=0.0.3->sae-lens)\n","  Downloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m111.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tiktoken<0.7.0,>=0.6.0 (from automated-interpretability<0.0.4,>=0.0.3->sae-lens)\n","  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting py2store (from babe<0.0.8,>=0.0.7->sae-lens)\n","  Downloading py2store-0.1.20.tar.gz (143 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting graze (from babe<0.0.8,>=0.0.7->sae-lens)\n","  Downloading graze-0.1.17-py3-none-any.whl (17 kB)\n","Collecting pyarrow>=15.0.0 (from datasets<3.0.0,>=2.17.1->sae-lens)\n","  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (0.6)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets<3.0.0,>=2.17.1->sae-lens)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting requests>=2.32.2 (from datasets<3.0.0,>=2.17.1->sae-lens)\n","  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting xxhash (from datasets<3.0.0,>=2.17.1->sae-lens)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets<3.0.0,>=2.17.1->sae-lens)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (3.9.5)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=5.1.0->circuitsvis) (3.19.2)\n","Collecting typeguard==2.13.3 (from jaxtyping>=0.2.11->transformer-lens)\n","  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (4.53.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (1.4.5)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (2.8.2)\n","Requirement already satisfied: traitlets in /usr/local/lib/python3.10/dist-packages (from matplotlib-inline<0.2.0,>=0.1.6->sae-lens) (5.7.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->sae-lens) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->sae-lens) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->sae-lens) (2024.5.15)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens) (2024.1)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly<6.0.0,>=5.19.0->sae-lens) (8.4.2)\n","Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from plotly-express<0.5.0,>=0.4.1->sae-lens) (0.14.2)\n","Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.10/dist-packages (from plotly-express<0.5.0,>=0.4.1->sae-lens) (1.11.4)\n","Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.10/dist-packages (from plotly-express<0.5.0,>=0.4.1->sae-lens) (0.5.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pytest-profiling<2.0.0,>=1.7.0->sae-lens) (1.16.0)\n","Collecting gprof2dot (from pytest-profiling<2.0.0,>=1.7.0->sae-lens)\n","  Downloading gprof2dot-2024.6.6-py2.py3-none-any.whl (34 kB)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens) (2.16.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens) (3.1.4)\n","INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n","Collecting torch>=1.10 (from transformer-lens)\n","  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.1->sae-lens) (0.19.1)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<0.13.0,>=0.12.3->sae-lens) (1.5.4)\n","Collecting docker-pycreds>=0.4.0 (from wandb>=0.13.5->transformer-lens)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting gitpython!=3.1.29,>=1.0.0 (from wandb>=0.13.5->transformer-lens)\n","  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens) (4.2.2)\n","Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens) (3.20.3)\n","Collecting sentry-sdk>=1.0.0 (from wandb>=0.13.5->transformer-lens)\n","  Downloading sentry_sdk-2.8.0-py2.py3-none-any.whl (300 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.6/300.6 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting setproctitle (from wandb>=0.13.5->transformer-lens)\n","  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens) (67.7.2)\n","Collecting pycryptodomex~=3.8 (from blobfile<3.0.0,>=2.1.1->automated-interpretability<0.0.4,>=0.0.3->sae-lens)\n","  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from blobfile<3.0.0,>=2.1.1->automated-interpretability<0.0.4,>=0.0.3->sae-lens) (2.0.7)\n","Requirement already satisfied: lxml~=4.9 in /usr/local/lib/python3.10/dist-packages (from blobfile<3.0.0,>=2.1.1->automated-interpretability<0.0.4,>=0.0.3->sae-lens) (4.9.4)\n","Collecting uvloop>=0.16.0 (from boostedblob<0.16.0,>=0.15.3->automated-interpretability<0.0.4,>=0.0.3->sae-lens)\n","  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (4.0.3)\n","Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens)\n","  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<0.0.4,>=0.0.3->sae-lens) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<0.0.4,>=0.0.3->sae-lens) (2024.6.2)\n","Collecting httpcore==1.* (from httpx<0.28.0,>=0.27.0->automated-interpretability<0.0.4,>=0.0.3->sae-lens)\n","  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<0.0.4,>=0.0.3->sae-lens) (3.7)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<0.0.4,>=0.0.3->sae-lens) (1.3.1)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<0.28.0,>=0.27.0->automated-interpretability<0.0.4,>=0.0.3->sae-lens)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer-lens) (0.1.2)\n","Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest<9.0.0,>=8.1.2->automated-interpretability<0.0.4,>=0.0.3->sae-lens) (2.0.0)\n","Requirement already satisfied: pluggy<2.0,>=1.5 in /usr/local/lib/python3.10/dist-packages (from pytest<9.0.0,>=8.1.2->automated-interpretability<0.0.4,>=0.0.3->sae-lens) (1.5.0)\n","Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest<9.0.0,>=8.1.2->automated-interpretability<0.0.4,>=0.0.3->sae-lens) (1.2.1)\n","Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from pytest<9.0.0,>=8.1.2->automated-interpretability<0.0.4,>=0.0.3->sae-lens) (2.0.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets<3.0.0,>=2.17.1->sae-lens) (3.3.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.4.2->automated-interpretability<0.0.4,>=0.0.3->sae-lens) (3.5.0)\n","Collecting dol (from graze->babe<0.0.8,>=0.0.7->sae-lens)\n","  Downloading dol-0.2.49-py3-none-any.whl (221 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.1/221.1 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->transformer-lens) (2.1.5)\n","Collecting config2py (from py2store->babe<0.0.8,>=0.0.7->sae-lens)\n","  Downloading config2py-0.1.33-py3-none-any.whl (31 kB)\n","Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from py2store->babe<0.0.8,>=0.0.7->sae-lens) (6.4.0)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->transformer-lens) (1.3.0)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens)\n","  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Collecting i2 (from config2py->py2store->babe<0.0.8,>=0.0.7->sae-lens)\n","  Downloading i2-0.1.17-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.0/190.0 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: py2store\n","  Building wheel for py2store (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py2store: filename=py2store-0.1.20-py3-none-any.whl size=118411 sha256=d0582d683b50abfab535708e7a94bf9f6142326765838409224868b6ba8b42f1\n","  Stored in directory: /root/.cache/pip/wheels/ff/40/40/fa84c63029cbb45f4f3824be4be62c6838436ad4cb264b5585\n","Successfully built py2store\n","Installing collected packages: i2, dol, better-abc, zstandard, xxhash, uvloop, typeguard, triton, smmap, setproctitle, sentry-sdk, requests, pyzmq, python-dotenv, pytest, pycryptodomex, plotly, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, h11, gprof2dot, fancy-einsum, einops, docker-pycreds, dill, config2py, beartype, tiktoken, pytest-profiling, pyarrow, py2store, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, jaxtyping, httpcore, graze, gitdb, blobfile, scikit-learn, nvidia-cusolver-cu12, matplotlib, httpx, gitpython, boostedblob, babe, wandb, torch, plotly-express, datasets, automated-interpretability, circuitsvis, accelerate, transformer-lens, sae-lens\n","  Attempting uninstall: triton\n","    Found existing installation: triton 2.3.0\n","    Uninstalling triton-2.3.0:\n","      Successfully uninstalled triton-2.3.0\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.31.0\n","    Uninstalling requests-2.31.0:\n","      Successfully uninstalled requests-2.31.0\n","  Attempting uninstall: pyzmq\n","    Found existing installation: pyzmq 24.0.1\n","    Uninstalling pyzmq-24.0.1:\n","      Successfully uninstalled pyzmq-24.0.1\n","  Attempting uninstall: pytest\n","    Found existing installation: pytest 7.4.4\n","    Uninstalling pytest-7.4.4:\n","      Successfully uninstalled pytest-7.4.4\n","  Attempting uninstall: plotly\n","    Found existing installation: plotly 5.15.0\n","    Uninstalling plotly-5.15.0:\n","      Successfully uninstalled plotly-5.15.0\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.25.2\n","    Uninstalling numpy-1.25.2:\n","      Successfully uninstalled numpy-1.25.2\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 14.0.2\n","    Uninstalling pyarrow-14.0.2:\n","      Successfully uninstalled pyarrow-14.0.2\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.2.2\n","    Uninstalling scikit-learn-1.2.2:\n","      Successfully uninstalled scikit-learn-1.2.2\n","  Attempting uninstall: matplotlib\n","    Found existing installation: matplotlib 3.7.1\n","    Uninstalling matplotlib-3.7.1:\n","      Successfully uninstalled matplotlib-3.7.1\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.3.0+cu121\n","    Uninstalling torch-2.3.0+cu121:\n","      Successfully uninstalled torch-2.3.0+cu121\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n","google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n","ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\n","notebook 6.5.5 requires pyzmq<25,>=17, but you have pyzmq 26.0.0 which is incompatible.\n","torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.1.2 which is incompatible.\n","torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.1.2 which is incompatible.\n","torchvision 0.18.0+cu121 requires torch==2.3.0, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed accelerate-0.32.1 automated-interpretability-0.0.3 babe-0.0.7 beartype-0.14.1 better-abc-0.0.3 blobfile-2.1.1 boostedblob-0.15.4 circuitsvis-1.43.2 config2py-0.1.33 datasets-2.20.0 dill-0.3.8 docker-pycreds-0.4.0 dol-0.2.49 einops-0.8.0 fancy-einsum-0.0.3 gitdb-4.0.11 gitpython-3.1.43 gprof2dot-2024.6.6 graze-0.1.17 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 i2-0.1.17 jaxtyping-0.2.31 matplotlib-3.9.1 multiprocess-0.70.16 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 orjson-3.10.6 plotly-5.22.0 plotly-express-0.4.1 py2store-0.1.20 pyarrow-16.1.0 pycryptodomex-3.20.0 pytest-8.2.2 pytest-profiling-1.7.0 python-dotenv-1.0.1 pyzmq-26.0.0 requests-2.32.3 sae-lens-3.12.0 scikit-learn-1.5.1 sentry-sdk-2.8.0 setproctitle-1.3.3 smmap-5.0.1 tiktoken-0.6.0 torch-2.1.2 transformer-lens-2.2.0 triton-2.1.0 typeguard-2.13.3 uvloop-0.19.0 wandb-0.17.4 xxhash-3.4.1 zstandard-0.22.0\n"]}],"source":["try:\n","    #import google.colab # type: ignore\n","    #from google.colab import output\n","    %pip install sae-lens transformer-lens\n","except:\n","    from IPython import get_ipython # type: ignore\n","    ipython = get_ipython(); assert ipython is not None\n","    ipython.run_line_magic(\"load_ext\", \"autoreload\")\n","    ipython.run_line_magic(\"autoreload\", \"2\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4204,"status":"ok","timestamp":1720554333778,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":-60},"id":"uy-b3CcSOVHu","outputId":"f0066b84-6af5-4de3-a039-64f343b36c31"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"source":["import torch\n","import os\n","\n","from sae_lens import LanguageModelSAERunnerConfig, SAETrainingRunner\n","\n","if torch.cuda.is_available():\n","    device = \"cuda\"\n","elif torch.backends.mps.is_available():\n","    device = \"mps\"\n","else:\n","    device = \"cpu\"\n","\n","print(\"Using device:\", device)\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""]},{"cell_type":"markdown","metadata":{"id":"oe2nlqf-OVHv"},"source":["# Model Selection and Evaluation"]},{"cell_type":"markdown","metadata":{"id":"er3H1TDoOVHw"},"source":["# Training an SAE\n","\n","Now we're ready to train out SAE. We'll make a runner config, instantiate the runner and the rest is taken care of for us!\n","\n","During training, you use weights and biases to check key metrics which indicate how well we are able to optimize the variables we care about.\n","\n","To get a better sense of which variables to look at, you can read my (Joseph's) post [here](https://www.lesswrong.com/posts/f9EgfLSurAiqRJySD/open-source-sparse-autoencoders-for-all-residual-stream) and especially look at my weights and biases report [here](https://links-cdn.wandb.ai/wandb-public-images/links/jbloom/uue9i416.html).\n","\n","A few tips:\n","- Feel free to reorganize your wandb dashboard to put L0, CE_Loss_score, explained variance and other key metrics in one section at the top.\n","- Make a [run comparer](https://docs.wandb.ai/guides/app/features/panels/run-comparer) when tuning hyperparameters.\n","- You can download the resulting sparse autoencoder / sparsity estimate from wandb and upload them to huggingface if you want to share your SAE with other.\n","    - cfg.json (training config)\n","    - sae_weight.safetensors (model weights)\n","    - sparsity.safetensors (sparsity estimate)"]},{"cell_type":"markdown","metadata":{"id":"jCHtPycOOVHw"},"source":["## MLP Out\n","\n","I've tuned the hyperparameters below for a decent SAE which achieves 86% CE Loss recovered and an L0 of ~85, and runs in about 2 hours on an M3 Max. You can get an SAE that looks better faster if you only consider L0 and CE loss but it will likely have more dense features and more dead features. Here's a link to my output with two runs with two different L1's: https://wandb.ai/jbloom/sae_lens_tutorial ."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["28498b5b3f8a47a3a0dac902bf5d64d9","7e7ff04181934dc4aadd66dbbeff9e9d","a73bd1833fa2449d8356cbe3ddc32642","d56497be3d77453798f326b301c1c081","2bf7a5d1158149a186bf09fabeb4a459","aae2595001054f6fa644a1dd5343dc83","d2c813a7f0a4458aa43b50e078ba48c0","ba6eba4c00e04376a891dbb42d147e83","ae60b6065bca44179f6c87e74035a7a9","92d394ce5f3546f080106dbfb0943ed8","1d8219a03b8640b684a67cc27a24e51c","9a8904beef23454aa3166fed62d72066","a2f8ddce6417450b90829c5e4092b87e","775a18713d7e431488829721fbdb0dea","c44d48162916417597bdab965a4ed74f","aa2ebb44480442439dc92518fa75dbdc"]},"id":"oAsZCAdJOVHw","executionInfo":{"status":"ok","timestamp":1720555855897,"user_tz":-60,"elapsed":1163507,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3b050265-7518-40bf-a08d-75c682a8019c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Run name: 1024-L1-5-LR-5e-05-Tokens-1.229e+08\n","n_tokens_per_buffer (millions): 0.524288\n","Lower bound: n_contexts_per_buffer (millions): 0.001024\n","Total training steps: 30000\n","Total wandb updates: 1000\n","n_tokens_per_feature_sampling_window (millions): 2097.152\n","n_tokens_per_dead_feature_window (millions): 2097.152\n","We will reset the sparsity calculation 30 times.\n","Number tokens in sparsity calculation window: 4.10e+06\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Loaded pretrained model tiny-stories-1M into HookedTransformer\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Finishing last run (ID:xekjt044) before initializing another..."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28498b5b3f8a47a3a0dac902bf5d64d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">16384-L1-5-LR-5e-05-Tokens-1.229e+08</strong> at: <a href='https://wandb.ai/wlg100/tiny-stories-1M_MLP0_sae/runs/xekjt044' target=\"_blank\">https://wandb.ai/wlg100/tiny-stories-1M_MLP0_sae/runs/xekjt044</a><br/> View project at: <a href='https://wandb.ai/wlg100/tiny-stories-1M_MLP0_sae' target=\"_blank\">https://wandb.ai/wlg100/tiny-stories-1M_MLP0_sae</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20240709_194831-xekjt044/logs</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Successfully finished last run (ID:xekjt044). Initializing new run:<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.17.4"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20240709_195137-svodk83r</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/wlg100/tiny-stories-1M_MLP0_sae/runs/svodk83r' target=\"_blank\">1024-L1-5-LR-5e-05-Tokens-1.229e+08</a></strong> to <a href='https://wandb.ai/wlg100/tiny-stories-1M_MLP0_sae' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/wlg100/tiny-stories-1M_MLP0_sae' target=\"_blank\">https://wandb.ai/wlg100/tiny-stories-1M_MLP0_sae</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/wlg100/tiny-stories-1M_MLP0_sae/runs/svodk83r' target=\"_blank\">https://wandb.ai/wlg100/tiny-stories-1M_MLP0_sae/runs/svodk83r</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py:2310: UserWarning: Run (xekjt044) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n","  lambda data: self._console_raw_callback(\"stderr\", data),\n","Training SAE:   0%|          | 0/122880000 [03:11<?, ?it/s]\n","Training SAE:   0%|          | 0/122880000 [00:00<?, ?it/s]\n","Estimating norm scaling factor:   0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\n","Estimating norm scaling factor:   0%|          | 1/1000 [00:02<43:37,  2.62s/it]\u001b[A\n","Estimating norm scaling factor:   1%|          | 9/1000 [00:02<03:41,  4.47it/s]\u001b[A\n","Estimating norm scaling factor:   2%|▏         | 17/1000 [00:02<01:42,  9.56it/s]\u001b[A\n","Estimating norm scaling factor:   2%|▏         | 24/1000 [00:02<01:05, 14.82it/s]\u001b[A\n","Estimating norm scaling factor:   3%|▎         | 32/1000 [00:03<00:44, 21.84it/s]\u001b[A\n","Estimating norm scaling factor:   4%|▍         | 40/1000 [00:03<00:32, 29.37it/s]\u001b[A\n","Estimating norm scaling factor:   5%|▍         | 48/1000 [00:03<00:25, 36.93it/s]\u001b[A\n","Estimating norm scaling factor:   6%|▌         | 56/1000 [00:03<00:21, 43.84it/s]\u001b[A\n","Estimating norm scaling factor:   6%|▋         | 64/1000 [00:03<00:18, 50.14it/s]\u001b[A\n","Estimating norm scaling factor:   7%|▋         | 72/1000 [00:04<00:56, 16.33it/s]\u001b[A\n","Estimating norm scaling factor:   8%|▊         | 80/1000 [00:04<00:42, 21.50it/s]\u001b[A\n","Estimating norm scaling factor:   9%|▉         | 88/1000 [00:04<00:33, 27.47it/s]\u001b[A\n","Estimating norm scaling factor:  10%|▉         | 96/1000 [00:05<00:26, 33.87it/s]\u001b[A\n","Estimating norm scaling factor:  10%|█         | 104/1000 [00:05<00:22, 40.43it/s]\u001b[A\n","Estimating norm scaling factor:  11%|█         | 111/1000 [00:05<00:20, 44.21it/s]\u001b[A\n","Estimating norm scaling factor:  12%|█▏        | 119/1000 [00:05<00:17, 50.47it/s]\u001b[A\n","Estimating norm scaling factor:  13%|█▎        | 127/1000 [00:05<00:15, 55.85it/s]\u001b[A\n","Estimating norm scaling factor:  13%|█▎        | 134/1000 [00:06<00:56, 15.32it/s]\u001b[A\n","Estimating norm scaling factor:  14%|█▍        | 142/1000 [00:06<00:42, 20.36it/s]\u001b[A\n","Estimating norm scaling factor:  15%|█▌        | 150/1000 [00:07<00:32, 26.18it/s]\u001b[A\n","Estimating norm scaling factor:  16%|█▌        | 157/1000 [00:07<00:26, 31.52it/s]\u001b[A\n","Estimating norm scaling factor:  16%|█▋        | 165/1000 [00:07<00:21, 38.32it/s]\u001b[A\n","Estimating norm scaling factor:  17%|█▋        | 173/1000 [00:07<00:18, 45.01it/s]\u001b[A\n","Estimating norm scaling factor:  18%|█▊        | 181/1000 [00:07<00:16, 51.17it/s]\u001b[A\n","Estimating norm scaling factor:  19%|█▉        | 189/1000 [00:07<00:14, 56.45it/s]\u001b[A\n","Estimating norm scaling factor:  20%|█▉        | 197/1000 [00:08<00:44, 17.94it/s]\u001b[A\n","Estimating norm scaling factor:  20%|██        | 205/1000 [00:08<00:34, 23.24it/s]\u001b[A\n","Estimating norm scaling factor:  21%|██▏       | 213/1000 [00:08<00:26, 29.25it/s]\u001b[A\n","Estimating norm scaling factor:  22%|██▏       | 221/1000 [00:09<00:21, 35.70it/s]\u001b[A\n","Estimating norm scaling factor:  23%|██▎       | 229/1000 [00:09<00:18, 42.11it/s]\u001b[A\n","Estimating norm scaling factor:  24%|██▎       | 237/1000 [00:09<00:15, 48.17it/s]\u001b[A\n","Estimating norm scaling factor:  24%|██▍       | 245/1000 [00:09<00:14, 53.73it/s]\u001b[A\n","Estimating norm scaling factor:  25%|██▌       | 253/1000 [00:09<00:12, 58.58it/s]\u001b[A\n","Estimating norm scaling factor:  26%|██▌       | 261/1000 [00:10<00:41, 17.82it/s]\u001b[A\n","Estimating norm scaling factor:  27%|██▋       | 267/1000 [00:10<00:38, 18.83it/s]\u001b[A\n","Estimating norm scaling factor:  27%|██▋       | 274/1000 [00:11<00:30, 23.85it/s]\u001b[A\n","Estimating norm scaling factor:  28%|██▊       | 282/1000 [00:11<00:23, 30.40it/s]\u001b[A\n","Estimating norm scaling factor:  29%|██▉       | 290/1000 [00:11<00:19, 37.14it/s]\u001b[A\n","Estimating norm scaling factor:  30%|██▉       | 298/1000 [00:11<00:16, 43.77it/s]\u001b[A\n","Estimating norm scaling factor:  31%|███       | 306/1000 [00:11<00:13, 49.95it/s]\u001b[A\n","Estimating norm scaling factor:  31%|███▏      | 314/1000 [00:11<00:12, 55.45it/s]\u001b[A\n","Estimating norm scaling factor:  32%|███▏      | 321/1000 [00:12<00:39, 17.28it/s]\u001b[A\n","Estimating norm scaling factor:  33%|███▎      | 329/1000 [00:12<00:29, 22.66it/s]\u001b[A\n","Estimating norm scaling factor:  34%|███▎      | 337/1000 [00:12<00:23, 28.75it/s]\u001b[A\n","Estimating norm scaling factor:  34%|███▍      | 345/1000 [00:13<00:18, 35.18it/s]\u001b[A\n","Estimating norm scaling factor:  35%|███▌      | 353/1000 [00:13<00:15, 41.89it/s]\u001b[A\n","Estimating norm scaling factor:  36%|███▌      | 361/1000 [00:13<00:13, 48.27it/s]\u001b[A\n","Estimating norm scaling factor:  37%|███▋      | 368/1000 [00:13<00:12, 52.60it/s]\u001b[A\n","Estimating norm scaling factor:  38%|███▊      | 376/1000 [00:13<00:10, 57.53it/s]\u001b[A\n","Estimating norm scaling factor:  38%|███▊      | 384/1000 [00:13<00:10, 61.40it/s]\u001b[A\n","Estimating norm scaling factor:  39%|███▉      | 392/1000 [00:14<00:34, 17.78it/s]\u001b[A\n","Estimating norm scaling factor:  40%|███▉      | 398/1000 [00:15<00:32, 18.66it/s]\u001b[A\n","Estimating norm scaling factor:  40%|████      | 404/1000 [00:15<00:26, 22.73it/s]\u001b[A\n","Estimating norm scaling factor:  41%|████      | 411/1000 [00:15<00:20, 28.44it/s]\u001b[A\n","Estimating norm scaling factor:  42%|████▏     | 419/1000 [00:15<00:16, 35.59it/s]\u001b[A\n","Estimating norm scaling factor:  43%|████▎     | 427/1000 [00:15<00:13, 42.54it/s]\u001b[A\n","Estimating norm scaling factor:  44%|████▎     | 435/1000 [00:15<00:11, 48.80it/s]\u001b[A\n","Estimating norm scaling factor:  44%|████▍     | 443/1000 [00:15<00:10, 54.23it/s]\u001b[A\n","Estimating norm scaling factor:  45%|████▌     | 450/1000 [00:16<00:32, 17.00it/s]\u001b[A\n","Estimating norm scaling factor:  46%|████▌     | 458/1000 [00:16<00:24, 22.37it/s]\u001b[A\n","Estimating norm scaling factor:  46%|████▋     | 465/1000 [00:17<00:19, 27.64it/s]\u001b[A\n","Estimating norm scaling factor:  47%|████▋     | 473/1000 [00:17<00:15, 34.38it/s]\u001b[A\n","Estimating norm scaling factor:  48%|████▊     | 481/1000 [00:17<00:12, 41.21it/s]\u001b[A\n","Estimating norm scaling factor:  49%|████▉     | 489/1000 [00:17<00:10, 47.41it/s]\u001b[A\n","Estimating norm scaling factor:  50%|████▉     | 497/1000 [00:17<00:09, 53.17it/s]\u001b[A\n","Estimating norm scaling factor:  50%|█████     | 505/1000 [00:17<00:08, 57.94it/s]\u001b[A\n","Estimating norm scaling factor:  51%|█████▏    | 513/1000 [00:18<00:27, 18.00it/s]\u001b[A\n","Estimating norm scaling factor:  52%|█████▏    | 521/1000 [00:18<00:20, 23.23it/s]\u001b[A\n","Estimating norm scaling factor:  53%|█████▎    | 529/1000 [00:18<00:16, 29.23it/s]\u001b[A\n","Estimating norm scaling factor:  54%|█████▎    | 536/1000 [00:19<00:16, 27.96it/s]\u001b[A\n","Estimating norm scaling factor:  54%|█████▍    | 544/1000 [00:19<00:13, 34.58it/s]\u001b[A\n","Estimating norm scaling factor:  55%|█████▌    | 552/1000 [00:19<00:10, 41.23it/s]\u001b[A\n","Estimating norm scaling factor:  56%|█████▌    | 560/1000 [00:19<00:09, 47.66it/s]\u001b[A\n","Estimating norm scaling factor:  57%|█████▋    | 568/1000 [00:19<00:08, 53.48it/s]\u001b[A\n","Estimating norm scaling factor:  58%|█████▊    | 576/1000 [00:19<00:07, 58.25it/s]\u001b[A\n","Estimating norm scaling factor:  58%|█████▊    | 583/1000 [00:20<00:23, 17.44it/s]\u001b[A\n","Estimating norm scaling factor:  59%|█████▉    | 591/1000 [00:21<00:17, 22.81it/s]\u001b[A\n","Estimating norm scaling factor:  60%|█████▉    | 598/1000 [00:21<00:14, 28.00it/s]\u001b[A\n","Estimating norm scaling factor:  61%|██████    | 606/1000 [00:21<00:11, 34.71it/s]\u001b[A\n","Estimating norm scaling factor:  61%|██████▏   | 614/1000 [00:21<00:09, 41.33it/s]\u001b[A\n","Estimating norm scaling factor:  62%|██████▏   | 622/1000 [00:21<00:07, 47.68it/s]\u001b[A\n","Estimating norm scaling factor:  63%|██████▎   | 630/1000 [00:21<00:06, 53.40it/s]\u001b[A\n","Estimating norm scaling factor:  64%|██████▍   | 638/1000 [00:21<00:06, 58.18it/s]\u001b[A\n","Estimating norm scaling factor:  65%|██████▍   | 646/1000 [00:22<00:19, 18.00it/s]\u001b[A\n","Estimating norm scaling factor:  65%|██████▌   | 654/1000 [00:22<00:14, 23.31it/s]\u001b[A\n","Estimating norm scaling factor:  66%|██████▌   | 662/1000 [00:23<00:11, 29.34it/s]\u001b[A\n","Estimating norm scaling factor:  67%|██████▋   | 669/1000 [00:23<00:11, 28.09it/s]\u001b[A\n","Estimating norm scaling factor:  68%|██████▊   | 677/1000 [00:23<00:09, 34.73it/s]\u001b[A\n","Estimating norm scaling factor:  68%|██████▊   | 685/1000 [00:23<00:07, 41.44it/s]\u001b[A\n","Estimating norm scaling factor:  69%|██████▉   | 693/1000 [00:23<00:06, 47.87it/s]\u001b[A\n","Estimating norm scaling factor:  70%|███████   | 701/1000 [00:23<00:05, 53.45it/s]\u001b[A\n","Estimating norm scaling factor:  71%|███████   | 708/1000 [00:24<00:16, 17.26it/s]\u001b[A\n","Estimating norm scaling factor:  72%|███████▏  | 716/1000 [00:24<00:12, 22.63it/s]\u001b[A\n","Estimating norm scaling factor:  72%|███████▏  | 724/1000 [00:25<00:09, 28.68it/s]\u001b[A\n","Estimating norm scaling factor:  73%|███████▎  | 732/1000 [00:25<00:07, 35.22it/s]\u001b[A\n","Estimating norm scaling factor:  74%|███████▍  | 740/1000 [00:25<00:06, 41.76it/s]\u001b[A\n","Estimating norm scaling factor:  75%|███████▍  | 748/1000 [00:25<00:05, 47.75it/s]\u001b[A\n","Estimating norm scaling factor:  76%|███████▌  | 756/1000 [00:25<00:04, 53.21it/s]\u001b[A\n","Estimating norm scaling factor:  76%|███████▋  | 764/1000 [00:25<00:04, 57.98it/s]\u001b[A\n","Estimating norm scaling factor:  77%|███████▋  | 772/1000 [00:27<00:19, 11.92it/s]\u001b[A\n","Estimating norm scaling factor:  78%|███████▊  | 780/1000 [00:27<00:13, 15.92it/s]\u001b[A\n","Estimating norm scaling factor:  79%|███████▉  | 788/1000 [00:27<00:10, 20.84it/s]\u001b[A\n","Estimating norm scaling factor:  80%|███████▉  | 796/1000 [00:27<00:07, 26.54it/s]\u001b[A\n","Estimating norm scaling factor:  80%|████████  | 803/1000 [00:28<00:07, 25.55it/s]\u001b[A\n","Estimating norm scaling factor:  81%|████████  | 811/1000 [00:28<00:05, 31.81it/s]\u001b[A\n","Estimating norm scaling factor:  82%|████████▏ | 819/1000 [00:28<00:04, 38.46it/s]\u001b[A\n","Estimating norm scaling factor:  83%|████████▎ | 827/1000 [00:28<00:03, 44.96it/s]\u001b[A\n","Estimating norm scaling factor:  83%|████████▎ | 834/1000 [00:29<00:10, 16.48it/s]\u001b[A\n","Estimating norm scaling factor:  84%|████████▍ | 842/1000 [00:29<00:07, 21.71it/s]\u001b[A\n","Estimating norm scaling factor:  85%|████████▌ | 850/1000 [00:29<00:05, 27.71it/s]\u001b[A\n","Estimating norm scaling factor:  86%|████████▌ | 858/1000 [00:29<00:04, 33.92it/s]\u001b[A\n","Estimating norm scaling factor:  87%|████████▋ | 866/1000 [00:30<00:03, 40.43it/s]\u001b[A\n","Estimating norm scaling factor:  87%|████████▋ | 874/1000 [00:30<00:02, 46.79it/s]\u001b[A\n","Estimating norm scaling factor:  88%|████████▊ | 881/1000 [00:30<00:02, 51.27it/s]\u001b[A\n","Estimating norm scaling factor:  89%|████████▉ | 889/1000 [00:30<00:01, 56.60it/s]\u001b[A\n","Estimating norm scaling factor:  90%|████████▉ | 897/1000 [00:31<00:05, 17.79it/s]\u001b[A\n","Estimating norm scaling factor:  90%|█████████ | 905/1000 [00:31<00:04, 23.12it/s]\u001b[A\n","Estimating norm scaling factor:  91%|█████████▏| 913/1000 [00:31<00:02, 29.16it/s]\u001b[A\n","Estimating norm scaling factor:  92%|█████████▏| 921/1000 [00:31<00:02, 35.71it/s]\u001b[A\n","Estimating norm scaling factor:  93%|█████████▎| 929/1000 [00:32<00:01, 42.21it/s]\u001b[A\n","Estimating norm scaling factor:  94%|█████████▎| 936/1000 [00:32<00:01, 35.79it/s]\u001b[A\n","Estimating norm scaling factor:  94%|█████████▍| 943/1000 [00:32<00:01, 41.40it/s]\u001b[A\n","Estimating norm scaling factor:  95%|█████████▌| 951/1000 [00:32<00:01, 47.95it/s]\u001b[A\n","Estimating norm scaling factor:  96%|█████████▌| 959/1000 [00:32<00:00, 53.62it/s]\u001b[A\n","Estimating norm scaling factor:  97%|█████████▋| 966/1000 [00:33<00:01, 17.16it/s]\u001b[A\n","Estimating norm scaling factor:  97%|█████████▋| 974/1000 [00:33<00:01, 22.59it/s]\u001b[A\n","Estimating norm scaling factor:  98%|█████████▊| 982/1000 [00:33<00:00, 28.76it/s]\u001b[A\n","Estimating norm scaling factor:  99%|█████████▉| 990/1000 [00:34<00:00, 35.30it/s]\u001b[A\n","Estimating norm scaling factor: 100%|██████████| 1000/1000 [00:34<00:00, 29.24it/s]\n","30000| MSE Loss 10.654 | L1 24.729: 100%|██████████| 122880000/122880000 [18:58<00:00, 107923.50it/s]\n"]},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.513 MB of 0.523 MB uploaded\\r'), FloatProgress(value=0.9803935511868165, max=1.0…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae60b6065bca44179f6c87e74035a7a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>▁▅██████████████████████████████████████</td></tr><tr><td>details/current_learning_rate</td><td>████████████████████████████████▇▇▅▅▄▃▂▁</td></tr><tr><td>details/n_training_tokens</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>losses/auxiliary_reconstruction_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/ghost_grad_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/l1_loss</td><td>█▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▁▁▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>losses/mse_loss</td><td>█▃▅▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/overall_loss</td><td>▂▃█▆▆▅▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/CE_loss_score</td><td>▇▃▁▂▃▃▃▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇█████████</td></tr><tr><td>metrics/ce_loss_with_ablation</td><td>▆▃▅▃▇▄▄▅▅▅▆▆▄▆▃█▇▅▃▂█▂▃▇▁▃▃▂▆▅▄▅▂▆▄▅▅▅▃▅</td></tr><tr><td>metrics/ce_loss_with_sae</td><td>▂▆█▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▂▁▂▁▂▁▁▁▁▁▁▁</td></tr><tr><td>metrics/ce_loss_without_sae</td><td>▂▅▅▃▄▃▄▆▃▄▅▃▃▄▄▂▄▆▆▆▃▆▃▄▂▄▁▃▇▃▇▅█▄▆▅▃▄▆▅</td></tr><tr><td>metrics/explained_variance</td><td>▁▆▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇███████████████████████</td></tr><tr><td>metrics/explained_variance_std</td><td>▆▆███▇▆▆▆▅▅▄▄▄▃▃▃▃▃▂▃▂▃▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▂▁</td></tr><tr><td>metrics/l0</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/l2_norm</td><td>█▃▁▂▄▄▄▅▅▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇████▇▇████████</td></tr><tr><td>metrics/l2_norm_in</td><td>▄█▃▄▄▄▄█▄▂▄▅▆▇▅▅▆▃▅▇▇▆▇▄▇▄▆▆▅▄▂▅▃▄▅▆▆▅▅▁</td></tr><tr><td>metrics/l2_ratio</td><td>█▃▁▂▃▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>█▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>sparsity/below_1e-5</td><td>▁▁▁▃▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████</td></tr><tr><td>sparsity/below_1e-6</td><td>▁▁▁▁▂▃▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████</td></tr><tr><td>sparsity/dead_features</td><td>▁▁▁▁▁▁▁▁▂▃▃▆▆▅▆▅▇▅▆▇▇▇▇▇▇▇▇▇▇▇█████▇████</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▆▆▆▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>5</td></tr><tr><td>details/current_learning_rate</td><td>0.0</td></tr><tr><td>details/n_training_tokens</td><td>122880000</td></tr><tr><td>losses/auxiliary_reconstruction_loss</td><td>0.0</td></tr><tr><td>losses/ghost_grad_loss</td><td>0.0</td></tr><tr><td>losses/l1_loss</td><td>4.94573</td></tr><tr><td>losses/mse_loss</td><td>10.65376</td></tr><tr><td>losses/overall_loss</td><td>35.38239</td></tr><tr><td>metrics/CE_loss_score</td><td>0.57907</td></tr><tr><td>metrics/ce_loss_with_ablation</td><td>12.49227</td></tr><tr><td>metrics/ce_loss_with_sae</td><td>6.60316</td></tr><tr><td>metrics/ce_loss_without_sae</td><td>2.32225</td></tr><tr><td>metrics/explained_variance</td><td>0.8221</td></tr><tr><td>metrics/explained_variance_std</td><td>0.11008</td></tr><tr><td>metrics/l0</td><td>10.54639</td></tr><tr><td>metrics/l2_norm</td><td>0.51343</td></tr><tr><td>metrics/l2_norm_in</td><td>7.9532</td></tr><tr><td>metrics/l2_ratio</td><td>0.06445</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>-2.36709</td></tr><tr><td>sparsity/below_1e-5</td><td>12</td></tr><tr><td>sparsity/below_1e-6</td><td>12</td></tr><tr><td>sparsity/dead_features</td><td>12</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>175.7041</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">1024-L1-5-LR-5e-05-Tokens-1.229e+08</strong> at: <a href='https://wandb.ai/wlg100/tiny-stories-1M_MLP0_sae/runs/svodk83r' target=\"_blank\">https://wandb.ai/wlg100/tiny-stories-1M_MLP0_sae/runs/svodk83r</a><br/> View project at: <a href='https://wandb.ai/wlg100/tiny-stories-1M_MLP0_sae' target=\"_blank\">https://wandb.ai/wlg100/tiny-stories-1M_MLP0_sae</a><br/>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20240709_195137-svodk83r/logs</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."]},"metadata":{}}],"source":["total_training_steps = 30_000  # probably we should do more\n","batch_size = 4096\n","total_training_tokens = total_training_steps * batch_size\n","\n","lr_warm_up_steps = 0\n","lr_decay_steps = total_training_steps // 5  # 20% of training\n","l1_warm_up_steps = total_training_steps // 20  # 5% of training\n","\n","cfg = LanguageModelSAERunnerConfig(\n","    # Data Generating Function (Model + Training Distibuion)\n","    model_name=\"tiny-stories-1M\",  # our model (more options here: https://neelnanda-io.github.io/TransformerLens/generated/model_properties_table.html)\n","    hook_name=\"blocks.0.hook_mlp_out\",  # A valid hook point (see more details here: https://neelnanda-io.github.io/TransformerLens/generated/demos/Main_Demo.html#Hook-Points)\n","    hook_layer=0,  # Only one layer in the model.\n","    d_in=64,  # the width of the mlp output.\n","    dataset_path=\"apollo-research/roneneldan-TinyStories-tokenizer-gpt2\",  # this is a tokenized language dataset on Huggingface for the Tiny Stories corpus.\n","    is_dataset_tokenized=True,\n","    streaming=True,  # we could pre-download the token dataset if it was small.\n","    # SAE Parameters\n","    mse_loss_normalization=None,  # We won't normalize the mse loss,\n","    expansion_factor=16,  # the width of the SAE. Larger will result in better stats but slower training.\n","    b_dec_init_method=\"zeros\",  # The geometric median can be used to initialize the decoder weights.\n","    apply_b_dec_to_input=False,  # We won't apply the decoder weights to the input.\n","    normalize_sae_decoder=False,\n","    scale_sparsity_penalty_by_decoder_norm=True,\n","    decoder_heuristic_init=True,\n","    init_encoder_as_decoder_transpose=True,\n","    normalize_activations=\"expected_average_only_in\",\n","    # Training Parameters\n","    lr=5e-5,  # lower the better, we'll go fairly high to speed up the tutorial.\n","    adam_beta1=0.9,  # adam params (default, but once upon a time we experimented with these.)\n","    adam_beta2=0.999,\n","    lr_scheduler_name=\"constant\",  # constant learning rate with warmup. Could be better schedules out there.\n","    lr_warm_up_steps=lr_warm_up_steps,  # this can help avoid too many dead features initially.\n","    lr_decay_steps=lr_decay_steps,  # this will help us avoid overfitting.\n","    l1_coefficient=5,  # will control how sparse the feature activations are\n","    l1_warm_up_steps=l1_warm_up_steps,  # this can help avoid too many dead features initially.\n","    lp_norm=1.0,  # the L1 penalty (and not a Lp for p < 1)\n","    train_batch_size_tokens=batch_size,\n","    context_size=512,  # will control the lenght of the prompts we feed to the model. Larger is better but slower. so for the tutorial we'll use a short one.\n","    # Activation Store Parameters\n","    n_batches_in_buffer=64,  # controls how many activations we store / shuffle.\n","    training_tokens=total_training_tokens,  # 100 million tokens is quite a few, but we want to see good stats. Get a coffee, come back.\n","    store_batch_size_prompts=16,\n","    # Resampling protocol\n","    use_ghost_grads=False,  # we don't use ghost grads anymore.\n","    feature_sampling_window=1000,  # this controls our reporting of feature sparsity stats\n","    dead_feature_window=1000,  # would effect resampling or ghost grads if we were using it.\n","    dead_feature_threshold=1e-4,  # would effect resampling or ghost grads if we were using it.\n","    # WANDB\n","    log_to_wandb=True,  # always use wandb unless you are just testing code.\n","    wandb_project=\"tiny-stories-1M_MLP0_sae\",\n","    wandb_log_frequency=30,\n","    eval_every_n_wandb_logs=20,\n","    # Misc\n","    device=device,\n","    seed=42,\n","    n_checkpoints=0,\n","    checkpoint_path=\"checkpoints\",\n","    dtype=\"float32\"\n",")\n","# look at the next cell to see some instruction for what to do while this is running.\n","sparse_autoencoder = SAETrainingRunner(cfg).run()"]},{"cell_type":"markdown","source":["## save"],"metadata":{"id":"trabeLxABN6o"}},{"cell_type":"code","source":["# Save the trained sparse autoencoder model\n","save_path = 'tiny-stories-1M_MLP0_sae.pth'\n","torch.save(sparse_autoencoder.state_dict(), save_path)\n","print(f'Model saved to {save_path}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PJuT3FEn_ku3","executionInfo":{"status":"ok","timestamp":1720555855898,"user_tz":-60,"elapsed":42,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"88c89e0e-c016-4a3a-cfe4-d583280da614"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model saved to tiny-stories-1M_MLP0_sae.pth\n"]}]},{"cell_type":"code","source":["from google.colab import files\n","files.download(save_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"JFtsDykf_11w","executionInfo":{"status":"ok","timestamp":1720555855899,"user_tz":-60,"elapsed":37,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"74d52b62-a472-44e8-b98b-9a0ae0513cc7"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_cd032c29-7111-47e7-8597-a639b6861b8a\", \"tiny-stories-1M_MLP0_sae.pth\", 531096)"]},"metadata":{}}]},{"cell_type":"code","source":["# faster\n","from google.colab import drive\n","import shutil\n","\n","drive.mount('/content/drive')\n","drive_save_path = '/content/drive/MyDrive/tiny-stories-1M_MLP0_sae.pth'\n","shutil.copy(save_path, drive_save_path)\n","print(f'Model copied to {drive_save_path}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CcHmkXkU_rnX","executionInfo":{"status":"ok","timestamp":1720556467061,"user_tz":-60,"elapsed":11726,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"72e14a28-f6a8-4075-ceb4-84c45c06fc7b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Model copied to /content/drive/MyDrive/tiny-stories-1M_MLP0_sae.pth\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyOE649vh9fpnnL0RP7YBRLo"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"28498b5b3f8a47a3a0dac902bf5d64d9":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_7e7ff04181934dc4aadd66dbbeff9e9d","IPY_MODEL_a73bd1833fa2449d8356cbe3ddc32642"],"layout":"IPY_MODEL_d56497be3d77453798f326b301c1c081"}},"7e7ff04181934dc4aadd66dbbeff9e9d":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bf7a5d1158149a186bf09fabeb4a459","placeholder":"​","style":"IPY_MODEL_aae2595001054f6fa644a1dd5343dc83","value":"0.017 MB of 0.017 MB uploaded\r"}},"a73bd1833fa2449d8356cbe3ddc32642":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2c813a7f0a4458aa43b50e078ba48c0","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ba6eba4c00e04376a891dbb42d147e83","value":1}},"d56497be3d77453798f326b301c1c081":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2bf7a5d1158149a186bf09fabeb4a459":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aae2595001054f6fa644a1dd5343dc83":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2c813a7f0a4458aa43b50e078ba48c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba6eba4c00e04376a891dbb42d147e83":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ae60b6065bca44179f6c87e74035a7a9":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_92d394ce5f3546f080106dbfb0943ed8","IPY_MODEL_1d8219a03b8640b684a67cc27a24e51c"],"layout":"IPY_MODEL_9a8904beef23454aa3166fed62d72066"}},"92d394ce5f3546f080106dbfb0943ed8":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2f8ddce6417450b90829c5e4092b87e","placeholder":"​","style":"IPY_MODEL_775a18713d7e431488829721fbdb0dea","value":"0.533 MB of 0.533 MB uploaded\r"}},"1d8219a03b8640b684a67cc27a24e51c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_c44d48162916417597bdab965a4ed74f","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aa2ebb44480442439dc92518fa75dbdc","value":1}},"9a8904beef23454aa3166fed62d72066":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2f8ddce6417450b90829c5e4092b87e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"775a18713d7e431488829721fbdb0dea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c44d48162916417597bdab965a4ed74f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa2ebb44480442439dc92518fa75dbdc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}