{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyNyFRLkbvmxMqg+1wVp1GNK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"fd8c8aee14c14bfe81a8e7e63f45f036":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a0ab8420ba3a45fd84769f420bc83c25","IPY_MODEL_31d54585be534d5aae98b23f3a1c1445","IPY_MODEL_3067f34bbef8414797f08cf4c7eaf7fe"],"layout":"IPY_MODEL_e3b434ed31d048fb967f6a6eaeb7d77e"}},"a0ab8420ba3a45fd84769f420bc83c25":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32f80082f792427db352372d329c161b","placeholder":"​","style":"IPY_MODEL_d77dbfd26a2b49d6a303e7ac7f24ccc9","value":"config.json: 100%"}},"31d54585be534d5aae98b23f3a1c1445":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a00c1d9f7d714638af328ecfd798b54a","max":689,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4fa95e2850534c869e6314db3bbda6e3","value":689}},"3067f34bbef8414797f08cf4c7eaf7fe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f25c756c8cc4996b0449cce4017bbe2","placeholder":"​","style":"IPY_MODEL_875c778027a846d8baa0551bae16c7b2","value":" 689/689 [00:00&lt;00:00, 51.9kB/s]"}},"e3b434ed31d048fb967f6a6eaeb7d77e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32f80082f792427db352372d329c161b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d77dbfd26a2b49d6a303e7ac7f24ccc9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a00c1d9f7d714638af328ecfd798b54a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4fa95e2850534c869e6314db3bbda6e3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6f25c756c8cc4996b0449cce4017bbe2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"875c778027a846d8baa0551bae16c7b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd3e8f08fdd14e818ea7886ac429f1c0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_05db5a20747a4e4fa4b4a558c40c296c","IPY_MODEL_e7027e0ba0394bad8f2c058983baf79c","IPY_MODEL_6d2430eda17a4962865e17840dae1b8d"],"layout":"IPY_MODEL_d1797f95c320490e8f80136d6c73be92"}},"05db5a20747a4e4fa4b4a558c40c296c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_10f8f4d59663471db6d54d733875e42f","placeholder":"​","style":"IPY_MODEL_663cb7421c194aaaad31afa7d52b2b35","value":"model.safetensors: 100%"}},"e7027e0ba0394bad8f2c058983baf79c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_315f6b91fc6c4b6aa78debd3db2ac396","max":6431829964,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fcdcc4a4d7874e319bc0e6e27a0a17eb","value":6431829964}},"6d2430eda17a4962865e17840dae1b8d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fdad160be10435e9d41d785342ab7bf","placeholder":"​","style":"IPY_MODEL_80b399dfa20c4eee9020c8e3fe8f6c4d","value":" 6.43G/6.43G [01:41&lt;00:00, 56.3MB/s]"}},"d1797f95c320490e8f80136d6c73be92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10f8f4d59663471db6d54d733875e42f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"663cb7421c194aaaad31afa7d52b2b35":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"315f6b91fc6c4b6aa78debd3db2ac396":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcdcc4a4d7874e319bc0e6e27a0a17eb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8fdad160be10435e9d41d785342ab7bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80b399dfa20c4eee9020c8e3fe8f6c4d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9a9a726fd8c042c28299c2c967bf81b3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_94e5908efa144e3391a55a1e5842a356","IPY_MODEL_da2ebb57048e4eee9f9663c6f39d873f","IPY_MODEL_df6b8494e6ba412dae3e2ff88e606114"],"layout":"IPY_MODEL_cb8d8dec12b440bcafdd054f63608d3d"}},"94e5908efa144e3391a55a1e5842a356":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16f71f49aff944f0baf0ef289a07f601","placeholder":"​","style":"IPY_MODEL_7bd62e5f6d544cb989436d9ab9943b9e","value":"generation_config.json: 100%"}},"da2ebb57048e4eee9f9663c6f39d873f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f96c379f5f74b88bb8dd9feba89090e","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_71dc4559ff96437d80a150febbc0e70f","value":124}},"df6b8494e6ba412dae3e2ff88e606114":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c955b5f696d34959ad3c55025eb655f2","placeholder":"​","style":"IPY_MODEL_d5f0c97cb5ac4f8fb9a1b9f890a22956","value":" 124/124 [00:00&lt;00:00, 10.2kB/s]"}},"cb8d8dec12b440bcafdd054f63608d3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16f71f49aff944f0baf0ef289a07f601":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bd62e5f6d544cb989436d9ab9943b9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f96c379f5f74b88bb8dd9feba89090e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71dc4559ff96437d80a150febbc0e70f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c955b5f696d34959ad3c55025eb655f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5f0c97cb5ac4f8fb9a1b9f890a22956":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb7dc651a0394c6684079d8436046124":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2e53cf72b4404f79b417968656e711f6","IPY_MODEL_bdd375c294f14d469d7056af561580bb","IPY_MODEL_3fb89da45f894ed3ba46d7c6bd64dce2"],"layout":"IPY_MODEL_13c29098045b40de9ad78cf134055267"}},"2e53cf72b4404f79b417968656e711f6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_695b735a9c2e45f8ae5723f33be6c3d2","placeholder":"​","style":"IPY_MODEL_3d97aa8849344b46b87754f8cf464529","value":"tokenizer_config.json: 100%"}},"bdd375c294f14d469d7056af561580bb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b67d31ef17404f4a9b8c66c9adf2d06c","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_31fed7df234d40a288795655d24660a4","value":26}},"3fb89da45f894ed3ba46d7c6bd64dce2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df031b2707c641dc9ad799fd8a8b131e","placeholder":"​","style":"IPY_MODEL_4a8baf5305034c8da3f32e699d25840e","value":" 26.0/26.0 [00:00&lt;00:00, 2.09kB/s]"}},"13c29098045b40de9ad78cf134055267":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"695b735a9c2e45f8ae5723f33be6c3d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d97aa8849344b46b87754f8cf464529":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b67d31ef17404f4a9b8c66c9adf2d06c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31fed7df234d40a288795655d24660a4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"df031b2707c641dc9ad799fd8a8b131e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a8baf5305034c8da3f32e699d25840e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68d5ce039d5c497a977555358a75d3a9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e782b61428df4e1ebfef092947a05fa1","IPY_MODEL_643839a45bb94820a687229d04500860","IPY_MODEL_6813ecf57c444bcea1776f16f423db12"],"layout":"IPY_MODEL_b2f4bc5cfd2349678352f4a165a8e685"}},"e782b61428df4e1ebfef092947a05fa1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a131315c8fc7433ebbc133303a3942ee","placeholder":"​","style":"IPY_MODEL_c2b83276f73d4005aa181e5478e74fa0","value":"vocab.json: 100%"}},"643839a45bb94820a687229d04500860":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9901f0812f34bb193c19b4ae34f119f","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b0832e5f30154db4a9f01d048cc80918","value":1042301}},"6813ecf57c444bcea1776f16f423db12":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2481011423041f8a3f288e304bfc8b7","placeholder":"​","style":"IPY_MODEL_6d813f28bb9448879311c991a8c7b392","value":" 1.04M/1.04M [00:00&lt;00:00, 14.6MB/s]"}},"b2f4bc5cfd2349678352f4a165a8e685":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a131315c8fc7433ebbc133303a3942ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2b83276f73d4005aa181e5478e74fa0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9901f0812f34bb193c19b4ae34f119f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0832e5f30154db4a9f01d048cc80918":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e2481011423041f8a3f288e304bfc8b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d813f28bb9448879311c991a8c7b392":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c4646fec8e304e8d9c7b50829c9dff86":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e094d8a9c8294aa1bbe676a2069ccddd","IPY_MODEL_72ee348e3e954f2194b94799c1d87a63","IPY_MODEL_43c204c271ae4a3692161a08c9795676"],"layout":"IPY_MODEL_98b30f67cf7b4a6786d847f316d13ede"}},"e094d8a9c8294aa1bbe676a2069ccddd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4835d9cc4360465dbc8e314acec23be0","placeholder":"​","style":"IPY_MODEL_c551a4d7a1154d8db89eb129521fb67a","value":"merges.txt: 100%"}},"72ee348e3e954f2194b94799c1d87a63":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed0a7d06d0884f5992c3cdb38cfca1a3","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5b05a51d17484c29b8aacc8377ec1487","value":456318}},"43c204c271ae4a3692161a08c9795676":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5ed3a13d357420485547d17d7d117b6","placeholder":"​","style":"IPY_MODEL_753e6b791798464590abed0ea118c035","value":" 456k/456k [00:00&lt;00:00, 20.9MB/s]"}},"98b30f67cf7b4a6786d847f316d13ede":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4835d9cc4360465dbc8e314acec23be0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c551a4d7a1154d8db89eb129521fb67a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed0a7d06d0884f5992c3cdb38cfca1a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b05a51d17484c29b8aacc8377ec1487":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c5ed3a13d357420485547d17d7d117b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"753e6b791798464590abed0ea118c035":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0a42e69944074977b0e2fae0ec78a3a2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_be634bb1453e4090be4cbd6edfa15606","IPY_MODEL_7f4afa221f754a6b9b45297cea943934","IPY_MODEL_e1806dec366448468f68656ef98d67ac"],"layout":"IPY_MODEL_d1dad4a7faa74408bfabee545d204a16"}},"be634bb1453e4090be4cbd6edfa15606":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1282133ef6104e85bfcb947dc2a308f8","placeholder":"​","style":"IPY_MODEL_cb26a55ba42f4f2ab28090f770d7c2f5","value":"tokenizer.json: 100%"}},"7f4afa221f754a6b9b45297cea943934":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_61fd3fa5fba347018aba509351dcd202","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_111972af670043ebbc841f5b6886b777","value":1355256}},"e1806dec366448468f68656ef98d67ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9cd71ead6854f2f889a6b665100cd65","placeholder":"​","style":"IPY_MODEL_448b9a17c471414f98596bf6df26725b","value":" 1.36M/1.36M [00:00&lt;00:00, 35.4MB/s]"}},"d1dad4a7faa74408bfabee545d204a16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1282133ef6104e85bfcb947dc2a308f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb26a55ba42f4f2ab28090f770d7c2f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"61fd3fa5fba347018aba509351dcd202":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"111972af670043ebbc841f5b6886b777":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a9cd71ead6854f2f889a6b665100cd65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"448b9a17c471414f98596bf6df26725b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"33e511e94c5040ae9c1f334ea29780e4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_645484cfd9444a2fb1f4d1478b34ab99","IPY_MODEL_1dfe1985b837455f81e81e4c1da2f142","IPY_MODEL_f1fcfa955cc1417aa1048c0f2d3d54cc"],"layout":"IPY_MODEL_99ccee4e76444373855f04a077ff6898"}},"645484cfd9444a2fb1f4d1478b34ab99":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d40b8b0d1a56402faf2695f3b748d0de","placeholder":"​","style":"IPY_MODEL_4852232ed334439c9478702b878d85df","value":"100%"}},"1dfe1985b837455f81e81e4c1da2f142":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f50f2fb30c044956bc4e51c7c89ca1ef","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_816e4a65f9ac433dbcafac2b84dca0a9","value":50}},"f1fcfa955cc1417aa1048c0f2d3d54cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8e081d258db482e9bf2c6ff100deb35","placeholder":"​","style":"IPY_MODEL_f11950488fe74a6689f262b24a6ed7d7","value":" 50/50 [00:05&lt;00:00,  9.88it/s]"}},"99ccee4e76444373855f04a077ff6898":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d40b8b0d1a56402faf2695f3b748d0de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4852232ed334439c9478702b878d85df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f50f2fb30c044956bc4e51c7c89ca1ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"816e4a65f9ac433dbcafac2b84dca0a9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c8e081d258db482e9bf2c6ff100deb35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f11950488fe74a6689f262b24a6ed7d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"shAFb9-lOVHu"},"source":["## Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"LeRi_tw2dhae","executionInfo":{"status":"ok","timestamp":1715693022584,"user_tz":240,"elapsed":782325,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["%%capture\n","try:\n","    import google.colab # type: ignore\n","    from google.colab import output\n","    %pip install sae-lens==1.3.0 transformer-lens==1.17.0 circuitsvis==1.43.2\n","except:\n","    from IPython import get_ipython # type: ignore\n","    ipython = get_ipython(); assert ipython is not None\n","    ipython.run_line_magic(\"load_ext\", \"autoreload\")\n","    ipython.run_line_magic(\"autoreload\", \"2\")"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"uy-b3CcSOVHu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715693027385,"user_tz":240,"elapsed":4821,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"4d899098-3a0c-4e50-891f-3fe8869a3fe9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"source":["import torch\n","import os\n","\n","from sae_lens.training.config import LanguageModelSAERunnerConfig\n","from sae_lens.training.lm_runner import language_model_sae_runner\n","\n","if torch.cuda.is_available():\n","    device = \"cuda\"\n","elif torch.backends.mps.is_available():\n","    device = \"mps\"\n","else:\n","    device = \"cpu\"\n","\n","print(\"Using device:\", device)\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""]},{"cell_type":"markdown","metadata":{"id":"oe2nlqf-OVHv"},"source":["# Model Selection and Evaluation\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"hFz6JUMuOVHv","colab":{"base_uri":"https://localhost:8080/","height":422,"referenced_widgets":["fd8c8aee14c14bfe81a8e7e63f45f036","a0ab8420ba3a45fd84769f420bc83c25","31d54585be534d5aae98b23f3a1c1445","3067f34bbef8414797f08cf4c7eaf7fe","e3b434ed31d048fb967f6a6eaeb7d77e","32f80082f792427db352372d329c161b","d77dbfd26a2b49d6a303e7ac7f24ccc9","a00c1d9f7d714638af328ecfd798b54a","4fa95e2850534c869e6314db3bbda6e3","6f25c756c8cc4996b0449cce4017bbe2","875c778027a846d8baa0551bae16c7b2","fd3e8f08fdd14e818ea7886ac429f1c0","05db5a20747a4e4fa4b4a558c40c296c","e7027e0ba0394bad8f2c058983baf79c","6d2430eda17a4962865e17840dae1b8d","d1797f95c320490e8f80136d6c73be92","10f8f4d59663471db6d54d733875e42f","663cb7421c194aaaad31afa7d52b2b35","315f6b91fc6c4b6aa78debd3db2ac396","fcdcc4a4d7874e319bc0e6e27a0a17eb","8fdad160be10435e9d41d785342ab7bf","80b399dfa20c4eee9020c8e3fe8f6c4d","9a9a726fd8c042c28299c2c967bf81b3","94e5908efa144e3391a55a1e5842a356","da2ebb57048e4eee9f9663c6f39d873f","df6b8494e6ba412dae3e2ff88e606114","cb8d8dec12b440bcafdd054f63608d3d","16f71f49aff944f0baf0ef289a07f601","7bd62e5f6d544cb989436d9ab9943b9e","9f96c379f5f74b88bb8dd9feba89090e","71dc4559ff96437d80a150febbc0e70f","c955b5f696d34959ad3c55025eb655f2","d5f0c97cb5ac4f8fb9a1b9f890a22956","fb7dc651a0394c6684079d8436046124","2e53cf72b4404f79b417968656e711f6","bdd375c294f14d469d7056af561580bb","3fb89da45f894ed3ba46d7c6bd64dce2","13c29098045b40de9ad78cf134055267","695b735a9c2e45f8ae5723f33be6c3d2","3d97aa8849344b46b87754f8cf464529","b67d31ef17404f4a9b8c66c9adf2d06c","31fed7df234d40a288795655d24660a4","df031b2707c641dc9ad799fd8a8b131e","4a8baf5305034c8da3f32e699d25840e","68d5ce039d5c497a977555358a75d3a9","e782b61428df4e1ebfef092947a05fa1","643839a45bb94820a687229d04500860","6813ecf57c444bcea1776f16f423db12","b2f4bc5cfd2349678352f4a165a8e685","a131315c8fc7433ebbc133303a3942ee","c2b83276f73d4005aa181e5478e74fa0","c9901f0812f34bb193c19b4ae34f119f","b0832e5f30154db4a9f01d048cc80918","e2481011423041f8a3f288e304bfc8b7","6d813f28bb9448879311c991a8c7b392","c4646fec8e304e8d9c7b50829c9dff86","e094d8a9c8294aa1bbe676a2069ccddd","72ee348e3e954f2194b94799c1d87a63","43c204c271ae4a3692161a08c9795676","98b30f67cf7b4a6786d847f316d13ede","4835d9cc4360465dbc8e314acec23be0","c551a4d7a1154d8db89eb129521fb67a","ed0a7d06d0884f5992c3cdb38cfca1a3","5b05a51d17484c29b8aacc8377ec1487","c5ed3a13d357420485547d17d7d117b6","753e6b791798464590abed0ea118c035","0a42e69944074977b0e2fae0ec78a3a2","be634bb1453e4090be4cbd6edfa15606","7f4afa221f754a6b9b45297cea943934","e1806dec366448468f68656ef98d67ac","d1dad4a7faa74408bfabee545d204a16","1282133ef6104e85bfcb947dc2a308f8","cb26a55ba42f4f2ab28090f770d7c2f5","61fd3fa5fba347018aba509351dcd202","111972af670043ebbc841f5b6886b777","a9cd71ead6854f2f889a6b665100cd65","448b9a17c471414f98596bf6df26725b"]},"executionInfo":{"status":"ok","timestamp":1715693138624,"user_tz":240,"elapsed":111272,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a400d2a3-a3cb-4204-a6fb-8742cb2ba568"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/689 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd8c8aee14c14bfe81a8e7e63f45f036"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/6.43G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd3e8f08fdd14e818ea7886ac429f1c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a9a726fd8c042c28299c2c967bf81b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb7dc651a0394c6684079d8436046124"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68d5ce039d5c497a977555358a75d3a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4646fec8e304e8d9c7b50829c9dff86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a42e69944074977b0e2fae0ec78a3a2"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Loaded pretrained model gpt2-xl into HookedTransformer\n"]}],"source":["from transformer_lens import HookedTransformer\n","\n","model = HookedTransformer.from_pretrained(\n","    \"gpt2-xl\"\n",")  # This will wrap huggingface models and has lots of nice utilities."]},{"cell_type":"markdown","metadata":{"id":"aUiXrjdUOVHv"},"source":["### Getting a vibe for a model using `model.generate`"]},{"cell_type":"markdown","metadata":{"id":"ZZfKT5aDOVHv"},"source":["Let's start by generating some stories using the model."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"G4ad4Zz1OVHv","colab":{"base_uri":"https://localhost:8080/","height":126},"executionInfo":{"status":"ok","timestamp":1715693148718,"user_tz":240,"elapsed":10193,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"758a56ea-6fc9-4e04-deb5-8dd690e9d4c1"},"outputs":[{"output_type":"display_data","data":{"text/plain":["\"You messed up because you're not the kind of person who should want to eat the same food as everyone else. Maybe everyone has preferences, maybe you're nothing special, but here's the thing: Most people have tastes, based on their body sense of taste and one's preferences\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\"You messed up because you're not a liberal. How would your friends trust you if you said that? His debate with Steinbug and the Morton episode are the only major occurrences that are dismissed as not happening because he disagrees with a huge group.\\n\\n[quote]As such\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}}],"source":["# here we use generate to get 10 completeions with temperature 1. Feel free to play with the prompt to make it more interesting.\n","for i in range(2):\n","    display(\n","        model.generate(\n","            # \"I think you're\",\n","            \"You messed up because you're\",\n","            stop_at_eos=False,  # avoids a bug on MPS\n","            temperature=1,\n","            verbose=False,\n","            max_new_tokens=50,\n","        )\n","    )"]},{"cell_type":"markdown","metadata":{"id":"RDKr8o1xOVHv"},"source":["One thing we notice is that the model seems to be able to repeat [X] consistently. To better understand the models ability to remember [X], let's extract a prompt where the next character is determined and use the \"test_prompt\" utility from TransformerLens to check the ranking of the token for [X]."]},{"cell_type":"markdown","metadata":{"id":"KsfJX-YpOVHv"},"source":["### Spot checking model abilities with `transformer_lens.utils.test_prompt`"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"TpmPoj7uOVHv","colab":{"base_uri":"https://localhost:8080/","height":280},"executionInfo":{"status":"ok","timestamp":1715693148956,"user_tz":240,"elapsed":255,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"6dc41470-59a6-408f-94ca-7abecabd27a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenized prompt: ['<|endoftext|>', 'I', ' think', ' you', \"'re\"]\n","Tokenized answer: [' angry']\n"]},{"output_type":"display_data","data":{"text/plain":["Performance on answer token:\n","\u001b[1mRank: \u001b[0m\u001b[1;36m248\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m9.03\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.03\u001b[0m\u001b[1m% Token: | angry|\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n","<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">248</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.03</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.03</span><span style=\"font-weight: bold\">% Token: | angry|</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Top 0th token. Logit: 15.02 Prob: 10.41% Token: | right|\n","Top 1th token. Logit: 14.38 Prob:  5.48% Token: | missing|\n","Top 2th token. Logit: 14.27 Prob:  4.89% Token: | being|\n","Top 3th token. Logit: 13.88 Prob:  3.32% Token: | going|\n","Top 4th token. Logit: 13.76 Prob:  2.94% Token: | a|\n","Top 5th token. Logit: 13.47 Prob:  2.20% Token: | making|\n","Top 6th token. Logit: 13.46 Prob:  2.18% Token: | getting|\n","Top 7th token. Logit: 13.42 Prob:  2.09% Token: | talking|\n","Top 8th token. Logit: 13.41 Prob:  2.07% Token: | looking|\n","Top 9th token. Logit: 13.39 Prob:  2.03% Token: | on|\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' angry'\u001b[0m, \u001b[1;36m248\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' angry'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">248</span><span style=\"font-weight: bold\">)]</span>\n","</pre>\n"]},"metadata":{}}],"source":["from transformer_lens.utils import test_prompt\n","\n","# Test the model with a prompt\n","test_prompt(\n","    \"I think you're\",\n","    \" angry\",\n","    model,\n","    prepend_space_to_answer=False,\n",")"]},{"cell_type":"markdown","metadata":{"id":"jGzOvReDOVHv"},"source":["In the output above, we see that the model assigns ~ % probability to [X] being the next token."]},{"cell_type":"markdown","metadata":{"id":"QH8YOZOzOVHv"},"source":["### Exploring Model Capabilities with Log Probs"]},{"cell_type":"markdown","metadata":{"id":"50mqTBihOVHw"},"source":["Look at token log probs for ALL tokens in a prompt. Hover to get the top5 tokens by log probability. Darker tokens are tokens where the model assigned a higher probability to the actual next token.\n","\n","Given prompt \"A B C D\", this predicts the rank of predicting \"C\" given \"A B\". The actual prompt has \"A B C\", but if only \"A B\" was given, how \"much\" does the model expect C? [improve this explanation]"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Tic0RCUpOVHw","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1715693149467,"user_tz":240,"elapsed":531,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"fe4b741c-abba-4d01-f24c-07bef75fa480"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<circuitsvis.utils.render.RenderedHTML at 0x7fc764c272e0>"],"text/html":["<div id=\"circuits-vis-4e9fce4d-a17a\" style=\"margin: 15px 0;\"/>\n","    <script crossorigin type=\"module\">\n","    import { render, TokenLogProbs } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n","    render(\n","      \"circuits-vis-4e9fce4d-a17a\",\n","      TokenLogProbs,\n","      {\"prompt\": [\"<|endoftext|>\", \"Hi\", \",\", \" how\", \" are\", \" you\", \" doing\", \" this\", \"?\", \" I\", \"'m\", \" really\", \" enjoying\", \" your\", \" posts\"], \"topKLogProbs\": [[-2.6872425079345703, -3.715317726135254, -3.7391061782836914, -4.057321548461914, -4.083163261413574, -4.277179718017578, -4.56345272064209, -4.786035537719727, -4.840024948120117, -4.921682357788086], [-1.5797330141067505, -2.027867317199707, -2.518280029296875, -2.590961456298828, -2.6814584732055664, -2.930814743041992, -3.703841209411621, -3.7082290649414062, -3.964371681213379, -4.156004905700684], [-1.2318705320358276, -1.7359265089035034, -2.5717782974243164, -2.994002342224121, -3.4413251876831055, -3.494873046875, -3.7443418502807617, -4.275408744812012, -4.586957931518555, -4.770859718322754], [-0.24571247398853302, -2.6420347690582275, -3.656780481338501, -4.192373275756836, -4.237569808959961, -4.753711700439453, -4.913618087768555, -4.970931053161621, -4.990654945373535, -5.3073530197143555], [-0.03641727939248085, -4.4173665046691895, -4.958733081817627, -5.668175220489502, -6.122833728790283, -6.753963947296143, -6.75415563583374, -6.940831661224365, -7.264197826385498, -7.270103931427002], [-0.6300495266914368, -1.803013563156128, -2.566391706466675, -2.714130163192749, -3.3134095668792725, -3.869537115097046, -4.360833168029785, -4.72672176361084, -5.252769470214844, -5.295635223388672], [-0.36235496401786804, -2.0277154445648193, -3.162118673324585, -3.9841878414154053, -4.014175891876221, -4.03933572769165, -4.709605693817139, -5.5270676612854, -5.783412456512451, -5.950422763824463], [-1.6068084239959717, -1.6255261898040771, -2.246575117111206, -2.420941114425659, -2.4848086833953857, -2.5086209774017334, -3.891991376876831, -4.138782501220703, -4.2538299560546875, -4.264670372009277], [-1.6876351833343506, -1.691267728805542, -3.0004794597625732, -3.5912444591522217, -3.6452834606170654, -3.8094260692596436, -3.9082038402557373, -4.138927459716797, -4.2039079666137695, -4.211038589477539], [-0.9844256639480591, -1.781178593635559, -2.76583194732666, -3.050565719604492, -3.126866340637207, -3.3353052139282227, -3.823701858520508, -3.837080955505371, -4.730781555175781, -4.876978874206543], [-3.284498453140259, -3.4799654483795166, -3.5058062076568604, -3.5515472888946533, -3.736788034439087, -3.7611420154571533, -3.951920747756958, -4.018680572509766, -4.040225982666016, -4.1057281494140625], [-1.4299159049987793, -1.8895297050476074, -1.982043743133545, -2.109611988067627, -3.2732672691345215, -3.4283337593078613, -3.7002005577087402, -4.0049262046813965, -4.085874080657959, -4.503758907318115], [-1.6405433416366577, -1.6505874395370483, -2.1066107749938965, -2.702155590057373, -3.4549689292907715, -3.4871678352355957, -3.685403347015381, -3.914625644683838, -4.134899616241455, -4.439239978790283], [-2.2108352184295654, -2.5059049129486084, -2.595972776412964, -3.2893331050872803, -3.7323920726776123, -3.972808599472046, -4.045782089233398, -4.075493812561035, -4.11903190612793, -4.294276237487793]], \"topKTokens\": [[\"The\", \"A\", \"\\\"\", \"I\", \"In\", \"This\", \"It\", \"As\", \"We\", \"If\"], [\",\", \" everyone\", \" there\", \" all\", \"!\", \" guys\", \".\", \" Everyone\", \" All\", \" everybody\"], [\" I\", \"\\n\", \" my\", \"\\n\\n\", \" everyone\", \" this\", \" we\", \" and\", \"I\", \" i\"], [\" are\", \"'s\", \" is\", \" you\", \" can\", \" about\", \" may\", \"'re\", \" do\", \" ya\"], [\" you\", \" ya\", \" things\", \" the\", \" we\", \" your\", \" u\", \" all\", \" ye\", \" y\"], [\"?\", \" doing\", \" all\", \" today\", \" guys\", \",\", \" this\", \"!\", \" ?\", \".\"], [\"?\", \" today\", \",\", \".\", \"!\", \" this\", \" ?\", \" guys\", \" now\", \" tonight\"], [\" morning\", \" evening\", \" week\", \" afternoon\", \" fine\", \" weekend\", \" summer\", \" year\", \" month\", \" time\"], [\"\\n\", \" I\", \" It\", \" We\", \" This\", \" My\", \" If\", \" Well\", \" Welcome\", \" Today\"], [\"'m\", \" am\", \" hope\", \"'ve\", \" have\", \" know\", \" was\", \" just\", \" see\", \" thought\"], [\" a\", \" here\", \" glad\", \" so\", \" writing\", \" back\", \" doing\", \" very\", \" trying\", \" not\"], [\" excited\", \" sorry\", \" happy\", \" glad\", \" looking\", \" enjoying\", \" pleased\", \" busy\", \",\", \" good\"], [\" this\", \" the\", \" your\", \" my\", \" it\", \" reading\", \" working\", \" writing\", \" watching\", \" our\"], [\" blog\", \" work\", \" site\", \" website\", \" new\", \" book\", \" podcast\", \" story\", \" show\", \" article\"]], \"correctTokenRank\": [147, 0, 39, 0, 0, 1, 5, 68, 1, 0, 15, 5, 2, 21], \"correctTokenLogProb\": [-6.979203224182129, -1.5797330141067505, -6.518105506896973, -0.24571247398853302, -0.03641727939248085, -1.803013563156128, -4.03933572769165, -7.823346138000488, -1.691267728805542, -0.9844256639480591, -4.393807411193848, -3.4283337593078613, -2.1066107749938965, -4.952796936035156]}\n","    )\n","    </script>"]},"metadata":{},"execution_count":6}],"source":["import circuitsvis as cv  # optional dep, install with pip install circuitsvis\n","\n","# Let's make a longer prompt and see the log probabilities of the tokens\n","example_prompt = \"\"\"Hi, how are you doing this? I'm really enjoying your posts\"\"\"\n","logits, cache = model.run_with_cache(example_prompt)\n","cv.logits.token_log_probs(\n","    model.to_tokens(example_prompt),\n","    model(example_prompt)[0].log_softmax(dim=-1),\n","    model.to_string,\n",")\n","# hover on the output to see the result."]},{"cell_type":"markdown","metadata":{"id":"lhGIl3YbOVHw"},"source":["Let's combine `model.generate` and the token log probs visualization to see the log probs on text generated by the model. Note that we can play with the temperature and this should sample less likely trajectories according to the model.\n","\n","Some things to explore:\n","- Which tokens does the model assign high probability to? Can you see how the model should know which word comes next?\n","- What happens if you increase / decrease the temperature?\n","- Do the rankings of tokens seem sensible to you? What about where the model doesn't assign a high probability to the token which came next?"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Nikp2ASlOVHw","colab":{"base_uri":"https://localhost:8080/","height":517,"referenced_widgets":["33e511e94c5040ae9c1f334ea29780e4","645484cfd9444a2fb1f4d1478b34ab99","1dfe1985b837455f81e81e4c1da2f142","f1fcfa955cc1417aa1048c0f2d3d54cc","99ccee4e76444373855f04a077ff6898","d40b8b0d1a56402faf2695f3b748d0de","4852232ed334439c9478702b878d85df","f50f2fb30c044956bc4e51c7c89ca1ef","816e4a65f9ac433dbcafac2b84dca0a9","c8e081d258db482e9bf2c6ff100deb35","f11950488fe74a6689f262b24a6ed7d7"]},"executionInfo":{"status":"ok","timestamp":1715693155648,"user_tz":240,"elapsed":6231,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b943bd2a-4dd5-440d-9cb2-261b7f4998a3"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33e511e94c5040ae9c1f334ea29780e4"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["<circuitsvis.utils.render.RenderedHTML at 0x7fc764c25960>"],"text/html":["<div id=\"circuits-vis-3534b200-81ef\" style=\"margin: 15px 0;\"/>\n","    <script crossorigin type=\"module\">\n","    import { render, TokenLogProbs } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n","    render(\n","      \"circuits-vis-3534b200-81ef\",\n","      TokenLogProbs,\n","      {\"prompt\": [\"<|endoftext|>\", \"You\", \" messed\", \" up\", \" because\", \" you\", \"'re\", \" just\", \" wasting\", \" my\", \" time\", \" that\", \" I\", \" spend\", \" here\", \" on\", \" the\", \" internet\", \".\", \" I\", \" post\", \" here\", \" because\", \" there\", \" is\", \" no\", \" other\", \" place\", \" that\", \" has\", \" the\", \" information\", \" on\", \" plug\", \"ging\", \" extracted\", \" Linux\", \" hot\", \"keys\", \",\", \" and\", \" how\", \" to\", \" install\", \" them\", \",\", \" for\", \" complete\", \" beginners\", \".\", \"\\n\", \"\\n\", \"As\", \" a\", \" Valve\", \"-\", \"develop\"], \"topKLogProbs\": [[-2.6872377395629883, -3.7153148651123047, -3.739107131958008, -4.057324409484863, -4.083160400390625, -4.277179718017578, -4.563450813293457, -4.786036491394043, -4.840023040771484, -4.921683311462402], [-1.7873629331588745, -2.5576038360595703, -2.62857723236084, -2.747570037841797, -2.8047752380371094, -2.813754081726074, -2.89150333404541, -3.041299819946289, -3.2347869873046875, -3.2431373596191406], [-0.3385504186153412, -1.4747122526168823, -4.356453895568848, -4.5300397872924805, -5.285601615905762, -5.693315505981445, -5.95765495300293, -6.163137435913086, -6.167057037353516, -6.388240814208984], [-1.2483701705932617, -1.8593559265136719, -2.7399988174438477, -3.0622034072875977, -3.0980682373046875, -3.120511054992676, -3.4289941787719727, -3.972315788269043, -4.008922576904297, -4.034462928771973], [-0.3124949634075165, -2.8272788524627686, -3.258756399154663, -3.9420039653778076, -4.086424350738525, -4.121204853057861, -4.995398998260498, -4.998521327972412, -5.29218053817749, -5.350015163421631], [-1.9465878009796143, -2.0086777210235596, -2.2450506687164307, -2.5195229053497314, -3.013073205947876, -3.7174274921417236, -3.804032564163208, -3.8170406818389893, -3.981431245803833, -4.274041175842285], [-1.6439428329467773, -2.0617876052856445, -3.06442928314209, -3.274247169494629, -3.7173662185668945, -3.9257287979125977, -3.9751367568969727, -4.105877876281738, -4.119577407836914, -4.472037315368652], [-0.921607494354248, -1.8873772621154785, -2.466928005218506, -3.5722804069519043, -3.6331124305725098, -3.9077982902526855, -4.117407321929932, -4.456628322601318, -4.476785182952881, -4.691674709320068], [-1.0795444250106812, -1.1336559057235718, -2.736794948577881, -3.598926067352295, -3.7729554176330566, -3.7903218269348145, -3.918461322784424, -4.4559645652771, -4.465014934539795, -4.631821155548096], [-0.04180612042546272, -5.460902214050293, -5.527530670166016, -5.663122177124023, -5.856823921203613, -6.4283952713012695, -6.49362850189209, -6.890608787536621, -6.923501968383789, -6.964380264282227], [-0.7531687021255493, -2.2162976264953613, -2.2972092628479004, -2.752869129180908, -2.990156650543213, -4.11101770401001, -4.577372074127197, -4.6872172355651855, -5.062592029571533, -5.291989803314209], [-1.3234443664550781, -1.3594646453857422, -1.6434297561645508, -3.2329673767089844, -3.638627052307129, -3.953213691711426, -4.193935394287109, -4.841888427734375, -4.845793724060059, -5.0138959884643555], [-1.262650728225708, -2.4213860034942627, -2.7109596729278564, -2.720308542251587, -3.0570414066314697, -3.167104959487915, -3.2302143573760986, -3.4895851612091064, -3.657965898513794, -3.733471155166626], [-1.6398905515670776, -2.4347219467163086, -2.8572683334350586, -3.1273117065429688, -3.4274063110351562, -3.540764808654785, -3.5643205642700195, -3.570209503173828, -3.8076934814453125, -3.959749221801758], [-1.3334286212921143, -2.509995698928833, -2.534960985183716, -3.2441866397857666, -3.468059778213501, -3.6021597385406494, -3.626267671585083, -3.636245012283325, -4.001908302307129, -4.332515716552734], [-1.3980964422225952, -1.6789602041244507, -2.7862038612365723, -3.296867847442627, -3.3924508094787598, -3.4671874046325684, -3.6174025535583496, -4.5184712409973145, -4.657507419586182, -4.956288814544678], [-1.350534439086914, -2.3793230056762695, -2.3886566162109375, -2.4361190795898438, -2.7180910110473633, -3.1786155700683594, -3.472381591796875, -3.6605520248413086, -3.7172136306762695, -4.669682502746582], [-0.8830428123474121, -2.364236354827881, -3.3410725593566895, -3.5645546913146973, -3.63942289352417, -3.709242343902588, -3.829679012298584, -4.184787273406982, -4.254645824432373, -4.3191962242126465], [-1.3516273498535156, -2.015216827392578, -2.142458915710449, -3.446441650390625, -3.991588592529297, -4.004199981689453, -4.184653282165527, -4.23237419128418, -4.25045108795166, -4.263393402099609], [-1.5683047771453857, -1.7596766948699951, -2.9080770015716553, -3.2435901165008545, -3.2798945903778076, -3.4431846141815186, -3.5381762981414795, -3.60835337638855, -3.9252402782440186, -4.274442672729492], [-2.7578299045562744, -2.919811487197876, -2.9668333530426025, -2.9717724323272705, -3.030496835708618, -3.3695995807647705, -3.414252519607544, -3.5095064640045166, -3.6239168643951416, -3.6559011936187744], [-1.2332345247268677, -1.656337857246399, -2.2422237396240234, -3.136155128479004, -3.545577049255371, -3.7412214279174805, -3.8327770233154297, -3.845823287963867, -3.9771013259887695, -4.1422929763793945], [-0.38728561997413635, -2.7622551918029785, -3.2361693382263184, -3.919482707977295, -3.919914722442627, -3.974287509918213, -4.244575023651123, -4.359414577484131, -4.641359806060791, -4.889770030975342], [-1.1283198595046997, -1.1422072649002075, -1.323710560798645, -4.109244346618652, -4.56938362121582, -4.777830123901367, -5.037957191467285, -5.325641632080078, -5.508688926696777, -5.792355537414551], [-1.252116322517395, -1.990519642829895, -2.56075382232666, -2.6131410598754883, -2.864686965942383, -3.522345542907715, -3.534769058227539, -4.071459770202637, -4.373747825622559, -4.379420280456543], [-1.026310920715332, -2.3633651733398438, -2.7927627563476562, -2.897425651550293, -3.464357376098633, -3.8340063095092773, -4.159969329833984, -4.444277763366699, -4.554081916809082, -4.594724655151367], [-0.2910175025463104, -3.43233585357666, -3.91512393951416, -3.976006507873535, -4.100503921508789, -4.668107032775879, -4.718191146850586, -5.391921043395996, -5.667838096618652, -5.862022399902344], [-1.727895736694336, -1.7788143157958984, -1.7953872680664062, -2.009693145751953, -2.5562820434570312, -2.6785354614257812, -2.9205188751220703, -3.6708879470825195, -3.87274169921875, -4.048243522644043], [-0.9205985069274902, -2.819882869720459, -2.8615078926086426, -3.210951328277588, -3.6143555641174316, -3.721245288848877, -4.0320563316345215, -4.291462421417236, -4.302110195159912, -4.313584804534912], [-1.622652292251587, -2.526624917984009, -2.8409817218780518, -3.0372021198272705, -3.120124101638794, -3.174532175064087, -3.354987382888794, -3.779917001724243, -3.843773126602173, -3.9547674655914307], [-1.986222267150879, -2.5126953125, -2.607208251953125, -2.773731231689453, -2.9960556030273438, -4.0864715576171875, -4.204458236694336, -4.249730110168457, -4.333721160888672, -4.338554382324219], [-1.1135029792785645, -1.3422646522521973, -1.8512825965881348, -2.6950526237487793, -3.447730541229248, -3.8455443382263184, -4.207173824310303, -4.328980922698975, -4.350255489349365, -4.8850274085998535], [-1.394246220588684, -1.8833266496658325, -2.854252815246582, -3.576766014099121, -3.670363426208496, -4.347029685974121, -4.454331398010254, -4.51339054107666, -4.701651573181152, -4.70760440826416], [-0.9590882658958435, -1.8568506240844727, -2.5919723510742188, -3.2034482955932617, -4.417336463928223, -4.500179290771484, -4.550695419311523, -5.040962219238281, -5.11849308013916, -5.167899131774902], [-1.5687907934188843, -2.2036261558532715, -2.737572193145752, -2.8060879707336426, -3.108837604522705, -3.275625705718994, -3.7921433448791504, -4.117537021636963, -4.175857067108154, -4.403918743133545], [-2.70615553855896, -3.071871519088745, -3.1406590938568115, -3.9502780437469482, -4.694087028503418, -4.827594757080078, -4.93949031829834, -4.948513031005859, -4.981009483337402, -5.006372451782227], [-1.920484185218811, -2.3133702278137207, -3.1585545539855957, -3.3750624656677246, -3.600233554840088, -3.617583751678467, -3.6942057609558105, -3.70881986618042, -4.138638973236084, -4.176811695098877], [-1.1338260173797607, -1.6588904857635498, -1.858259916305542, -2.3742759227752686, -3.3390262126922607, -3.455674886703491, -3.6831376552581787, -4.238338470458984, -4.855152130126953, -4.914057731628418], [-1.5230778455734253, -1.5459622144699097, -2.423466682434082, -2.660959243774414, -2.729076385498047, -2.7668752670288086, -3.3466453552246094, -3.757685661315918, -3.7686872482299805, -3.9094038009643555], [-2.113145112991333, -2.4717161655426025, -3.207768678665161, -3.4130642414093018, -3.526369333267212, -3.8513386249542236, -3.965944528579712, -3.9845497608184814, -4.353995323181152, -4.458330154418945], [-2.083892583847046, -2.7765891551971436, -2.912672758102417, -3.3213775157928467, -3.3411881923675537, -3.7169501781463623, -3.765791654586792, -3.8197877407073975, -3.9324662685394287, -4.09780216217041], [-0.14378899335861206, -3.4018638134002686, -3.5187299251556396, -3.97733473777771, -5.0900654792785645, -5.470003604888916, -5.7597174644470215, -6.1493239402771, -6.174264430999756, -6.184741497039795], [-1.819155216217041, -1.8888754844665527, -2.8561367988586426, -2.958143711090088, -3.5152525901794434, -3.7442259788513184, -3.771458148956299, -3.8218541145324707, -4.478399753570557, -4.500624179840088], [-0.7808564901351929, -2.533407688140869, -2.664161205291748, -2.795365810394287, -3.8435282707214355, -3.9884305000305176, -4.362023830413818, -4.37195348739624, -4.577451229095459, -4.7448811531066895], [-0.8205921053886414, -1.9334766864776611, -2.616370439529419, -2.632148027420044, -3.9446499347686768, -3.9720041751861572, -3.9775383472442627, -4.131618499755859, -4.241284370422363, -4.377364158630371], [-1.3805365562438965, -3.0199761390686035, -3.0408005714416504, -3.2132887840270996, -3.2178072929382324, -3.312774181365967, -3.413475513458252, -3.643764019012451, -3.675384998321533, -3.7341551780700684], [-2.341426372528076, -2.5989584922790527, -2.695618152618408, -3.0488944053649902, -3.160017490386963, -3.3154454231262207, -3.581735134124756, -3.7368884086608887, -3.885530948638916, -3.9516310691833496], [-0.16367819905281067, -3.834824562072754, -4.360747337341309, -4.6637725830078125, -4.79936408996582, -5.195262908935547, -5.3585205078125, -5.366971015930176, -5.65538215637207, -5.965303421020508], [-0.5218089818954468, -2.1828160285949707, -2.8807129859924316, -2.986788272857666, -3.1986775398254395, -3.775367259979248, -4.102591037750244, -4.46853494644165, -4.6485419273376465, -4.6547160148620605], [-1.213078260421753, -2.2526252269744873, -2.5438430309295654, -2.8987863063812256, -3.1729400157928467, -3.382768392562866, -3.628155469894409, -3.6428544521331787, -4.11210823059082, -4.179245948791504], [-0.021510634571313858, -5.901027202606201, -6.3786444664001465, -7.007279872894287, -7.514869213104248, -7.69812536239624, -7.741164684295654, -7.811513423919678, -7.836974620819092, -8.089982032775879], [-2.057973623275757, -2.579913854598999, -2.6728713512420654, -3.0653464794158936, -3.2535321712493896, -3.3666322231292725, -3.5014407634735107, -3.9967076778411865, -4.1028947830200195, -4.13233757019043], [-1.733158826828003, -1.789808988571167, -2.11161208152771, -2.98327898979187, -3.192864179611206, -3.317289113998413, -3.428130865097046, -3.5542666912078857, -3.8659427165985107, -3.939899206161499], [-2.846092939376831, -2.9571378231048584, -3.0595338344573975, -3.206174612045288, -3.223449468612671, -3.461479902267456, -3.7312276363372803, -3.946868658065796, -4.040326118469238, -4.1113128662109375], [-1.2660658359527588, -1.9095127582550049, -2.580287218093872, -2.877258539199829, -3.7098419666290283, -3.738386392593384, -3.7847044467926025, -3.8005869388580322, -3.9213736057281494, -3.949228525161743], [-2.609257221221924, -2.706810474395752, -2.8794331550598145, -3.582001209259033, -3.597775936126709, -3.7455086708068848, -3.930236339569092, -4.0100274085998535, -4.142364978790283, -4.181433200836182]], \"topKTokens\": [[\"The\", \"A\", \"\\\"\", \"I\", \"In\", \"This\", \"It\", \"As\", \"We\", \"If\"], [\" can\", \" may\", \" are\", \"'ve\", \" must\", \" have\", \" know\", \"'re\", \" don\", \" might\"], [\" up\", \" with\", \" me\", \" it\", \" this\", \" around\", \" the\", \" your\", \" us\", \" something\"], [\".\", \",\", \"!\", \" your\", \" big\", \" and\", \" the\", \" a\", \" my\", \"\\n\"], [\" you\", \" of\", \" your\", \" I\", \" the\", \" it\", \" this\", \",\", \" there\", \" we\"], [\"'re\", \" were\", \" didn\", \" are\", \" don\", \" have\", \" thought\", \" weren\", \" did\", \" had\"], [\" a\", \" not\", \" an\", \" human\", \" stupid\", \" too\", \" trying\", \" the\", \" in\", \" young\"], [\" not\", \" a\", \" too\", \" like\", \" so\", \" an\", \" that\", \" trying\", \" stupid\", \" plain\"], [\" your\", \" time\", \" my\", \" energy\", \" our\", \" the\", \" everyone\", \" too\", \" money\", \" a\"], [\" time\", \" money\", \" life\", \" fucking\", \" precious\", \" valuable\", \" and\", \" energy\", \" breath\", \" hard\"], [\".\", \",\", \" and\", \"\\n\", \" with\", \"!\", \" by\", \"...\", \" (\", \":\"], [\"'s\", \" I\", \" you\", \" is\", \" way\", \" much\", \" i\", \" doesn\", \" it\", \" would\"], [\" could\", \" can\", \" have\", \"'m\", \" don\", \" should\", \" would\", \"'ve\", \" spent\", \"'d\"], [\" on\", \" reading\", \" to\", \" trying\", \" writing\", \" with\", \" watching\", \" looking\", \" here\", \" in\"], [\".\", \" on\", \",\", \" to\", \"\\n\", \" trying\", \" and\", \" reading\", \" talking\", \" with\"], [\" this\", \" the\", \" reddit\", \" my\", \" your\", \" Reddit\", \" a\", \" /\", \" these\", \" Patreon\"], [\" internet\", \" forums\", \" Internet\", \" site\", \" forum\", \" blog\", \" website\", \" web\", \" net\", \" board\"], [\".\", \",\", \" and\", \" talking\", \"\\n\", \" to\", \" trying\", \"!\", \" writing\", \" for\"], [\"\\n\", \" You\", \" I\", \"\\n\\n\", \" That\", \" If\", \" And\", \" It\", \" So\", \" But\"], [\"'m\", \" don\", \" have\", \"'ve\", \" can\", \" am\", \"'ll\", \" know\", \" will\", \" want\"], [\" a\", \" about\", \" this\", \" things\", \" here\", \" my\", \" to\", \" on\", \" stuff\", \" the\"], [\" because\", \" to\", \" for\", \" so\", \",\", \" about\", \" as\", \" in\", \" and\", \" on\"], [\" I\", \" it\", \" you\", \" there\", \" the\", \" of\", \" this\", \" my\", \" people\", \" that\"], [\"'s\", \" are\", \" is\", \" isn\", \" aren\", \" needs\", \" really\", \" was\", \" seems\", \" has\"], [\" a\", \" no\", \" nothing\", \" something\", \" so\", \" an\", \" some\", \" more\", \" not\", \" one\"], [\" other\", \" one\", \" place\", \" better\", \" way\", \" real\", \" point\", \" alternative\", \" reason\", \" such\"], [\" place\", \" forum\", \" source\", \" way\", \" site\", \" website\", \" community\", \" outlet\", \" resource\", \" discussion\"], [\" I\", \" to\", \" where\", \" for\", \" that\", \" on\", \" like\", \" you\", \" in\", \".\"], [\" I\", \" is\", \" has\", \" will\", \" you\", \"'s\", \" can\", \" gives\", \" allows\", \" deals\"], [\" the\", \" a\", \" as\", \" this\", \" so\", \" anything\", \" been\", \" such\", \" more\", \" what\"], [\" same\", \" information\", \" kind\", \" knowledge\", \" content\", \" type\", \" depth\", \" amount\", \" level\", \" resources\"], [\" I\", \" that\", \" you\", \" and\", \" on\", \",\", \" about\", \".\", \" in\", \" or\"], [\" this\", \" the\", \" how\", \" what\", \" these\", \" it\", \" my\", \" all\", \" a\", \" your\"], [\"ging\", \"-\", \" and\", \"g\", \"boards\", \"board\", \" &\", \"gy\", \" ins\", \" adapters\"], [\" in\", \" your\", \" a\", \" into\", \" and\", \" the\", \" up\", \" things\", \",\", \" it\"], [\" files\", \" audio\", \" data\", \" cables\", \" USB\", \" and\", \" devices\", \" plugs\", \" games\", \" cards\"], [\" kernels\", \" dist\", \" distributions\", \" packages\", \" CDs\", \" systems\", \" kernel\", \" images\", \" USB\", \" binaries\"], [\"plug\", \"fixes\", \"keys\", \"w\", \"-\", \" plug\", \"pl\", \"sp\", \" keys\", \"sw\"], [\" into\", \".\", \" and\", \",\", \" to\", \" in\", \" that\", \" (\", \" on\", \" for\"], [\" and\", \" so\", \" or\", \" which\", \" but\", \" like\", \" as\", \" such\", \" the\", \" including\"], [\" I\", \" how\", \" the\", \" it\", \" you\", \" this\", \" that\", \" also\", \" there\", \" what\"], [\" to\", \" they\", \" you\", \" it\", \" I\", \" do\", \" the\", \" that\", \" and\", \" much\"], [\" do\", \" use\", \" make\", \" get\", \" set\", \" fix\", \" configure\", \" change\", \" setup\", \" install\"], [\" them\", \" it\", \" the\", \" and\", \"/\", \" a\", \" these\", \" those\", \" your\", \",\"], [\".\", \" on\", \" in\", \",\", \" and\", \" into\", \" to\", \" with\", \" for\", \" (\"], [\" and\", \" in\", \" so\", \" as\", \" or\", \" that\", \" how\", \" but\", \" etc\", \" on\"], [\" the\", \" your\", \" those\", \" a\", \" you\", \" people\", \" free\", \" all\", \" example\", \" my\"], [\" beginners\", \" new\", \" and\", \" beginner\", \" no\", \" novice\", \" newcomers\", \" control\", \" freedom\", \" users\"], [\".\", \" like\", \",\", \" to\", \" and\", \" who\", \" that\", \" (\", \" with\", \" or\"], [\"\\n\", \" I\", \"\\n\\n\", \" If\", \" You\", \" This\", \" So\", \"<|endoftext|>\", \" It\", \" The\"], [\"\\n\", \"I\", \"The\", \"This\", \"In\", \"It\", \"So\", \"If\", \"We\", \"You\"], [\"I\", \"If\", \"You\", \"This\", \"Plug\", \"So\", \"The\", \"Here\", \"There\", \"In\"], [\" a\", \" you\", \" I\", \" for\", \" of\", \" an\", \" far\", \" the\", \" always\", \" long\"], [\" beginner\", \" matter\", \" result\", \" bonus\", \" new\", \" Linux\", \" disclaimer\", \" side\", \" complete\", \" reminder\"], [\" employee\", \" developer\", \" Software\", \" fan\", \" user\", \" Developer\", \"-\", \" programmer\", \"/\", \" engineer\"], [\"fan\", \"h\", \"sponsored\", \"dev\", \"approved\", \"develop\", \"supported\", \"f\", \"employed\", \"supp\"]], \"correctTokenRank\": [29, 1043, 0, 42, 0, 0, 10, 173, 2, 0, 58, 1, 10, 8, 1, 1, 0, 0, 2, 132, 4, 0, 3, 2, 1, 0, 0, 4, 2, 0, 1, 4, 4126, 0, 18620, 424, 617, 2, 3, 0, 1, 0, 9, 0, 3, 10, 216, 0, 0, 0, 0, 20, 0, 1849, 6, 5], \"correctTokenLogProb\": [-5.325375556945801, -11.413673400878906, -0.3385504186153412, -6.563363075256348, -0.3124949634075165, -1.9465878009796143, -4.4864091873168945, -8.376123428344727, -2.736794948577881, -0.04180612042546272, -7.346235752105713, -1.3594646453857422, -3.8994791507720947, -3.8076934814453125, -2.509995698928833, -1.6789602041244507, -1.350534439086914, -0.8830428123474121, -2.142458915710449, -7.832322120666504, -3.030496835708618, -1.2332345247268677, -3.919482707977295, -1.323710560798645, -1.990519642829895, -1.026310920715332, -0.2910175025463104, -2.5562820434570312, -2.8615078926086426, -1.622652292251587, -2.5126953125, -3.447730541229248, -11.061235427856445, -0.9590882658958435, -14.501553535461426, -7.978272438049316, -9.686326026916504, -1.858259916305542, -2.660959243774414, -2.113145112991333, -2.7765891551971436, -0.14378899335861206, -4.500624179840088, -0.7808564901351929, -2.632148027420044, -3.751718044281006, -7.9742817878723145, -0.16367819905281067, -0.5218089818954468, -1.213078260421753, -0.021510634571313858, -4.847736358642578, -1.733158826828003, -10.45154094696045, -3.7847044467926025, -3.7455086708068848]}\n","    )\n","    </script>"]},"metadata":{},"execution_count":7}],"source":["example_prompt = model.generate(\n","    \"You messed up because you're\",\n","    stop_at_eos=False,  # avoids a bug on MPS\n","    temperature=1,\n","    verbose=True,\n","    max_new_tokens=50,\n",")\n","logits, cache = model.run_with_cache(example_prompt)\n","cv.logits.token_log_probs(\n","    model.to_tokens(example_prompt),\n","    model(example_prompt)[0].log_softmax(dim=-1),\n","    model.to_string,\n",")"]},{"cell_type":"markdown","metadata":{"id":"er3H1TDoOVHw"},"source":["# Training an SAE\n","\n","Now we're ready to train out SAE. We'll make a runner config, instantiate the runner and the rest is taken care of for us!\n","\n","During training, you use weights and biases to check key metrics which indicate how well we are able to optimize the variables we care about.\n","\n","To get a better sense of which variables to look at, you can read my (Joseph's) post [here](https://www.lesswrong.com/posts/f9EgfLSurAiqRJySD/open-source-sparse-autoencoders-for-all-residual-stream) and especially look at my weights and biases report [here](https://links-cdn.wandb.ai/wandb-public-images/links/jbloom/uue9i416.html).\n","\n","A few tips:\n","- Feel free to reorganize your wandb dashboard to put L0, CE_Loss_score, explained variance and other key metrics in one section at the top.\n","- Make a [run comparer](https://docs.wandb.ai/guides/app/features/panels/run-comparer) when tuning hyperparameters.\n","- You can download the resulting sparse autoencoder / sparsity estimate from wandb and upload them to huggingface if you want to share your SAE with other.\n","    - cfg.json (training config)\n","    - sae_weight.safetensors (model weights)\n","    - sparsity.safetensors (sparsity estimate)"]},{"cell_type":"markdown","metadata":{"id":"jCHtPycOOVHw"},"source":["## MLP Out\n","\n","I've tuned the hyperparameters below for a decent SAE which achieves 86% CE Loss recovered and an L0 of ~85, and runs in about 2 hours on an M3 Max. You can get an SAE that looks better faster if you only consider L0 and CE loss but it will likely have more dense features and more dead features. Here's a link to my output with two runs with two different L1's: https://wandb.ai/jbloom/sae_lens_tutorial ."]},{"cell_type":"markdown","source":["Paste wandb API key below"],"metadata":{"id":"arFFHcl7jXTU"}},{"cell_type":"code","execution_count":8,"metadata":{"id":"oAsZCAdJOVHw","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1715693197419,"user_tz":240,"elapsed":42293,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"acc6a8a7-58ed-43c3-acdd-fe0fa87120de"},"outputs":[{"output_type":"stream","name":"stdout","text":["Warning: We are initializing b_dec to zeros. This is probably not what you want.\n","Run name: 25600-L1-5-LR-5e-05-Tokens-4.096e+06\n","n_tokens_per_buffer (millions): 0.524288\n","Lower bound: n_contexts_per_buffer (millions): 0.002048\n","Total training steps: 1000\n","Total wandb updates: 33\n","n_tokens_per_feature_sampling_window (millions): 1048.576\n","n_tokens_per_dead_feature_window (millions): 1048.576\n","We will reset the sparsity calculation 1 times.\n","Number tokens in sparsity calculation window: 4.10e+06\n","Loaded pretrained model gpt2-xl into HookedTransformer\n","Moving model to device:  cuda\n","Warning: We are initializing b_dec to zeros. This is probably not what you want.\n","Run name: 25600-L1-5-LR-5e-05-Tokens-4.096e+06\n","n_tokens_per_buffer (millions): 0.524288\n","Lower bound: n_contexts_per_buffer (millions): 0.002048\n","Total training steps: 1000\n","Total wandb updates: 33\n","n_tokens_per_feature_sampling_window (millions): 1048.576\n","n_tokens_per_dead_feature_window (millions): 1048.576\n","We will reset the sparsity calculation 1 times.\n","Number tokens in sparsity calculation window: 4.10e+06\n","Warning: We are initializing b_dec to zeros. This is probably not what you want.\n","Run name: 25600-L1-5-LR-5e-05-Tokens-4.096e+06\n","n_tokens_per_buffer (millions): 0.524288\n","Lower bound: n_contexts_per_buffer (millions): 0.002048\n","Total training steps: 1000\n","Total wandb updates: 33\n","n_tokens_per_feature_sampling_window (millions): 1048.576\n","n_tokens_per_dead_feature_window (millions): 1048.576\n","We will reset the sparsity calculation 1 times.\n","Number tokens in sparsity calculation window: 4.10e+06\n"]},{"output_type":"stream","name":"stderr","text":["ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":[" ··········\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.17.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20240514_132636-fonqpfx7</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/wlg100/sae_lens_exploraTest_L10/runs/fonqpfx7' target=\"_blank\">25600-L1-5-LR-5e-05-Tokens-4.096e+06</a></strong> to <a href='https://wandb.ai/wlg100/sae_lens_exploraTest_L10' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/wlg100/sae_lens_exploraTest_L10' target=\"_blank\">https://wandb.ai/wlg100/sae_lens_exploraTest_L10</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/wlg100/sae_lens_exploraTest_L10/runs/fonqpfx7' target=\"_blank\">https://wandb.ai/wlg100/sae_lens_exploraTest_L10/runs/fonqpfx7</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\rTraining SAE:   0%|          | 0/4096000 [00:00<?, ?it/s]"]},{"output_type":"error","ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 39.56 GiB of which 122.81 MiB is free. Process 61437 has 39.44 GiB memory in use. Of the allocated memory 38.82 GiB is allocated by PyTorch, and 131.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-31314a6baad1>\u001b[0m in \u001b[0;36m<cell line: 76>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;31m# look at the next cell to see some instruction for what to do while this is running.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0msparse_autoencoder_dictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlanguage_model_sae_runner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sae_lens/training/lm_runner.py\u001b[0m in \u001b[0;36mlanguage_model_sae_runner\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# train SAE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     sparse_autoencoder = train_sae_on_language_model(\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0msparse_autoencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sae_lens/training/train_sae_on_language_model.py\u001b[0m in \u001b[0;36mtrain_sae_on_language_model\u001b[0;34m(model, sae_group, activation_store, batch_size, n_checkpoints, feature_sampling_window, dead_feature_threshold, use_wandb, wandb_log_frequency)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdeprecated\u001b[0m \u001b[0mUse\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtrain_sae_group_on_language_model\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstead\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mkept\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbackward\u001b[0m \u001b[0mcompatibility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m     return train_sae_group_on_language_model(\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0msae_group\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sae_lens/training/train_sae_on_language_model.py\u001b[0m in \u001b[0;36mtrain_sae_group_on_language_model\u001b[0;34m(model, sae_group, activation_store, batch_size, n_checkpoints, feature_sampling_window, use_wandb, wandb_log_frequency)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mn_training_tokens\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_training_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# Do a training step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mlayer_acts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivation_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mn_training_tokens\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sae_lens/training/activations_store.py\u001b[0m in \u001b[0;36mnext_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0;31m# Try to get the next batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;31m# If the DataLoader is exhausted, create a new one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sae_lens/training/activations_store.py\u001b[0m in \u001b[0;36mdataloader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sae_lens/training/activations_store.py\u001b[0m in \u001b[0;36mget_data_loader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;31m# 1. # create new buffer by mixing stored and new buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         mixing_buffer = torch.cat(\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_batches_in_buffer\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage_buffer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m             \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sae_lens/training/activations_store.py\u001b[0m in \u001b[0;36mget_buffer\u001b[0;34m(self, n_batches_in_buffer)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrefill_batch_idx_start\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrefill_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mrefill_batch_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             \u001b[0mrefill_activations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_activations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefill_batch_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m             new_buffer[\n\u001b[1;32m    346\u001b[0m                 \u001b[0mrefill_batch_idx_start\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mrefill_batch_idx_start\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sae_lens/training/activations_store.py\u001b[0m in \u001b[0;36mget_activations\u001b[0;34m(self, batch_tokens)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mact_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhook_point\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mhook_point_max_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         layerwise_activations = self.model.run_with_cache(\n\u001b[0m\u001b[1;32m    252\u001b[0m             \u001b[0mbatch_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mnames_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mact_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/HookedTransformer.py\u001b[0m in \u001b[0;36mrun_with_cache\u001b[0;34m(self, return_cache_object, remove_batch_dim, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0mactivations\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mHookedRootModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m         \"\"\"\n\u001b[0;32m--> 627\u001b[0;31m         out, cache_dict = super().run_with_cache(\n\u001b[0m\u001b[1;32m    628\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_batch_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mremove_batch_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/hook_points.py\u001b[0m in \u001b[0;36mrun_with_cache\u001b[0;34m(self, names_filter, device, remove_batch_dim, incl_bwd, reset_hooks_end, clear_contexts, pos_slice, *model_args, **model_kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0mclear_contexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclear_contexts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         ):\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mmodel_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mincl_bwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0mmodel_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/HookedTransformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    548\u001b[0m                     )\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m                 residual = block(\n\u001b[0m\u001b[1;32m    551\u001b[0m                     \u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                     \u001b[0;31m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/components.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[0m\n\u001b[1;32m   1583\u001b[0m             \u001b[0;31m# queries, keys and values, independently.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m             \u001b[0;31m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1585\u001b[0;31m             self.attn(\n\u001b[0m\u001b[1;32m   1586\u001b[0m                 \u001b[0mquery_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mshortformer_pos_embed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mshortformer_pos_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/components.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query_input, key_input, value_input, past_kv_cache_entry, additive_attention_mask, attention_mask)\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         attn_scores = self.calculate_attention_scores(\n\u001b[0m\u001b[1;32m    557\u001b[0m             \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         )  # [batch, head_index, query_pos, key_pos]\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/components.py\u001b[0m in \u001b[0;36mcalculate_attention_scores\u001b[0;34m(self, q, k)\u001b[0m\n\u001b[1;32m    746\u001b[0m     ) -> Float[torch.Tensor, \"batch head_index query_pos key_pos\"]:\n\u001b[1;32m    747\u001b[0m         attn_scores = (\n\u001b[0;32m--> 748\u001b[0;31m             einsum(\n\u001b[0m\u001b[1;32m    749\u001b[0m                 \u001b[0;31m\"\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0mquery_pos\u001b[0m \u001b[0mhead_index\u001b[0m \u001b[0md_head\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[0mkey_pos\u001b[0m \u001b[0mhead_index\u001b[0m \u001b[0md_head\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fancy_einsum/__init__.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(equation, *operands)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0mnew_equation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_equation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_equation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fancy_einsum/__init__.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(self, equation, *operands)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;31m# the path for contracting 0 or 1 time(s) is already optimized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;31m# or the user has disabled using opt_einsum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 39.56 GiB of which 122.81 MiB is free. Process 61437 has 39.44 GiB memory in use. Of the allocated memory 38.82 GiB is allocated by PyTorch, and 131.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["# total_training_steps = 30_000  # probably we should do more\n","total_training_steps = 1000  # probably we should do more\n","batch_size = 4096\n","# batch_size = 4\n","total_training_tokens = total_training_steps * batch_size\n","\n","lr_warm_up_steps = 0\n","lr_decay_steps = total_training_steps // 5  # 20% of training\n","l1_warm_up_steps = total_training_steps // 20  # 5% of training\n","\n","cfg = LanguageModelSAERunnerConfig(\n","    # Data Generating Function (Model + Training Distibuion)\n","    model_name=\"gpt2-xl\",  # our model (more options here: https://neelnanda-io.github.io/TransformerLens/generated/model_properties_table.html)\n","    # hook_point=\"blocks.20.hook_mlp_out\",  # A valid hook point (see more details here: https://neelnanda-io.github.io/TransformerLens/generated/demos/Main_Demo.html#Hook-Points)\n","    # hook_point_layer=20,  # Only one layer in the model.\n","    hook_point=\"blocks.9.hook_mlp_out\",  # A valid hook point (see more details here: https://neelnanda-io.github.io/TransformerLens/generated/demos/Main_Demo.html#Hook-Points)\n","    hook_point_layer=9,  # Only one layer in the model.\n","    # d_in=1024,  # the width of the mlp output.\n","    d_in=1600,  # the width of the mlp output.\n","    # dataset_path=\"apollo-research/roneneldan-TinyStories-tokenizer-gpt2\",  # this is a tokenized language dataset on Huggingface for the Tiny Stories corpus.\n","    dataset_path=\"stas/openwebtext-10k\",\n","    is_dataset_tokenized=True,\n","    # streaming=True,  # we could pre-download the token dataset if it was small.\n","\n","    # SAE Parameters\n","    mse_loss_normalization=None,  # We won't normalize the mse loss,\n","    expansion_factor=16,  # the width of the SAE. Larger will result in better stats but slower training.\n","    b_dec_init_method=\"zeros\",  # The geometric median can be used to initialize the decoder weights.\n","    apply_b_dec_to_input=False,  # We won't apply the decoder weights to the input.\n","    normalize_sae_decoder=False,\n","    # scale_sparsity_penalty_by_decoder_norm=True,\n","    # decoder_heuristic_init=True,\n","    # init_encoder_as_decoder_transpose=True,\n","    # normalize_activations=False,\n","\n","    # Training Parameters\n","    lr=5e-5,  # lower the better, we'll go fairly high to speed up the tutorial.\n","    adam_beta1=0.9,  # adam params (default, but once upon a time we experimented with these.)\n","    adam_beta2=0.999,\n","    lr_scheduler_name=\"constant\",  # constant learning rate with warmup. Could be better schedules out there.\n","    lr_warm_up_steps=lr_warm_up_steps,  # this can help avoid too many dead features initially.\n","    lr_decay_steps=lr_decay_steps,  # this will help us avoid overfitting.\n","    l1_coefficient=5,  # will control how sparse the feature activations are\n","    # l1_warm_up_steps=l1_warm_up_steps,  # this can help avoid too many dead features initially.\n","    lp_norm=1.0,  # the L1 penalty (and not a Lp for p < 1)\n","    # train_batch_size_tokens=batch_size,\n","    context_size=256,  # will control the lenght of the prompts we feed to the model. Larger is better but slower. so for the tutorial we'll use a short one.\n","    # Activation Store Parameters\n","    n_batches_in_buffer=64,  # controls how many activations we store / shuffle.\n","    training_tokens=total_training_tokens,  # 100 million tokens is quite a few, but we want to see good stats. Get a coffee, come back.\n","    # store_batch_size_prompts=16,\n","\n","    # Resampling protocol\n","    use_ghost_grads=False,  # we don't use ghost grads anymore.\n","    feature_sampling_window=1000,  # this controls our reporting of feature sparsity stats\n","    dead_feature_window=1000,  # would effect resampling or ghost grads if we were using it.\n","    dead_feature_threshold=1e-4,  # would effect resampling or ghost grads if we were using it.\n","\n","    # WANDB\n","    log_to_wandb=True,  # always use wandb unless you are just testing code.\n","    # log_to_wandb=False,\n","    wandb_project=\"sae_lens_exploraTest_L9\",\n","    # wandb_project=\"sae_lens_tutorial\",\n","    wandb_log_frequency=30,\n","    # eval_every_n_wandb_logs=20,\n","\n","    # Misc\n","    device=device,\n","    seed=42,\n","    n_checkpoints=0,\n","    checkpoint_path=\"checkpoints\",\n","    dtype=torch.float32,\n",")\n","\n","# look at the next cell to see some instruction for what to do while this is running.\n","sparse_autoencoder_dictionary = language_model_sae_runner(cfg)"]},{"cell_type":"markdown","metadata":{"id":"khR_QkAJOVHw"},"source":["# Interpret SAE\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b4sUumxZOVHw","executionInfo":{"status":"aborted","timestamp":1715693197420,"user_tz":240,"elapsed":17,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["import pandas as pd\n","\n","# Let's start by getting the top 10 logits for each feature\n","\n","sparse_autoencoder = next(iter(sparse_autoencoder_dictionary))[1]\n","projection_onto_unembed = sparse_autoencoder.W_dec @ model.W_U\n","\n","\n","# get the top 10 logits.\n","vals, inds = torch.topk(projection_onto_unembed, 10, dim=1)\n","\n","# get 10 random features\n","random_indices = torch.randint(0, projection_onto_unembed.shape[0], (10,))\n","\n","# Show the top 10 logits promoted by those features\n","top_10_logits_df = pd.DataFrame(\n","    [model.to_str_tokens(i) for i in inds[random_indices]],\n","    index=random_indices.tolist(),\n",").T\n","top_10_logits_df"]}]}