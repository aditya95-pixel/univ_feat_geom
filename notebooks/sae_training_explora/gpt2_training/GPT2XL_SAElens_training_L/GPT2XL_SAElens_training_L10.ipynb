{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyP6PECiLklsfO668HqDWpZn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"59a84549db264ac99cbfeadebf935b6a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9f9a8497d1094c85b13374a30b0ec462","IPY_MODEL_30104ed6599f41178e0e96fae1c1c829","IPY_MODEL_4ad21ab78c8d462191f26efc35d7258b"],"layout":"IPY_MODEL_33d655ade2b24d4aa61a18ddf5ec4614"}},"9f9a8497d1094c85b13374a30b0ec462":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_248e52843d5d4198820f0b9d6908817f","placeholder":"​","style":"IPY_MODEL_46b29d1ef2f344ddbf3ec66fd035400b","value":"config.json: 100%"}},"30104ed6599f41178e0e96fae1c1c829":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7d6cd9ce15e49a4903f5bd77da501e1","max":689,"min":0,"orientation":"horizontal","style":"IPY_MODEL_19c4d05d74ec471fbaee74d24e0bbe8e","value":689}},"4ad21ab78c8d462191f26efc35d7258b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f27411fdb60b48f4ae27638f7b92d76f","placeholder":"​","style":"IPY_MODEL_3f91ef3fabb24a0d923a68757208fb7c","value":" 689/689 [00:00&lt;00:00, 54.0kB/s]"}},"33d655ade2b24d4aa61a18ddf5ec4614":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"248e52843d5d4198820f0b9d6908817f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46b29d1ef2f344ddbf3ec66fd035400b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b7d6cd9ce15e49a4903f5bd77da501e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19c4d05d74ec471fbaee74d24e0bbe8e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f27411fdb60b48f4ae27638f7b92d76f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f91ef3fabb24a0d923a68757208fb7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc36d37d898a44669b6dca624bcb3688":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b45e9d14c4e14503a1d41c42c30df00a","IPY_MODEL_b76078e813394f1ab31d1a7a16ce1d0f","IPY_MODEL_ae0551db548342d1933b5bae3547dc5c"],"layout":"IPY_MODEL_b67319d8ce3c495d8bc0b6eceb98d894"}},"b45e9d14c4e14503a1d41c42c30df00a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2327ceeb5dc49b4b254fe08ea4fb1ff","placeholder":"​","style":"IPY_MODEL_d869c2324dbe40f28982bfc40a17c2c7","value":"model.safetensors: 100%"}},"b76078e813394f1ab31d1a7a16ce1d0f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_deadd275ae324490be56f0107dcfd0c4","max":6431829964,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5a03179709464c20beb017232fd206bd","value":6431829964}},"ae0551db548342d1933b5bae3547dc5c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e703e24912d54e9098aaf1f1ed5ebcff","placeholder":"​","style":"IPY_MODEL_f899dc41c4144788ae69db47f95efdfc","value":" 6.43G/6.43G [00:32&lt;00:00, 197MB/s]"}},"b67319d8ce3c495d8bc0b6eceb98d894":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2327ceeb5dc49b4b254fe08ea4fb1ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d869c2324dbe40f28982bfc40a17c2c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"deadd275ae324490be56f0107dcfd0c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a03179709464c20beb017232fd206bd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e703e24912d54e9098aaf1f1ed5ebcff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f899dc41c4144788ae69db47f95efdfc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7dd55aeb846243368138a950ddc4b11c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fa78d5ae2e4746c4948f5489a9098af4","IPY_MODEL_c93411ad85054f1b89ccd4b903465de6","IPY_MODEL_ef49d11f836643a9a256417ded208c23"],"layout":"IPY_MODEL_239d24eadfd8455ba3a817b953b35469"}},"fa78d5ae2e4746c4948f5489a9098af4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_61173e67631c4d15923f783b4e681cc2","placeholder":"​","style":"IPY_MODEL_26bef72af570486bb0444b051663e0e7","value":"generation_config.json: 100%"}},"c93411ad85054f1b89ccd4b903465de6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_14785e251800478d8f0a9e1dcaa29fbc","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fcd50b29affe4a9594a6861280a0e2b7","value":124}},"ef49d11f836643a9a256417ded208c23":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db5e605e5ff348a4a215ff5da9bacf12","placeholder":"​","style":"IPY_MODEL_4cce3db2caf54b73b74005be3f7a6ac2","value":" 124/124 [00:00&lt;00:00, 10.4kB/s]"}},"239d24eadfd8455ba3a817b953b35469":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61173e67631c4d15923f783b4e681cc2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26bef72af570486bb0444b051663e0e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"14785e251800478d8f0a9e1dcaa29fbc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcd50b29affe4a9594a6861280a0e2b7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"db5e605e5ff348a4a215ff5da9bacf12":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cce3db2caf54b73b74005be3f7a6ac2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"310d07dfae614333bcd4c1072ab8c9b4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f9b3400def1948e7935d2322f92dac50","IPY_MODEL_cbb75df98faa4abdb55459b1b1ea72ea","IPY_MODEL_8ae5ea8f911f4f90a6993fe61811ab42"],"layout":"IPY_MODEL_fd67289b7cf34f34927ecaf506fd6be8"}},"f9b3400def1948e7935d2322f92dac50":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2367dc628693435ba9e9f2cdc16f193c","placeholder":"​","style":"IPY_MODEL_158a80da367a4cb2a2dfecafc698646c","value":"tokenizer_config.json: 100%"}},"cbb75df98faa4abdb55459b1b1ea72ea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb36328e3c0f4586ab0ba92b341bc1de","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_303be6a1aef34f0bb878491503135832","value":26}},"8ae5ea8f911f4f90a6993fe61811ab42":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a27f475690b14ef9826a07fdec3d2746","placeholder":"​","style":"IPY_MODEL_1ca555580f1d42f6853eb3f7eff746d8","value":" 26.0/26.0 [00:00&lt;00:00, 2.21kB/s]"}},"fd67289b7cf34f34927ecaf506fd6be8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2367dc628693435ba9e9f2cdc16f193c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"158a80da367a4cb2a2dfecafc698646c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb36328e3c0f4586ab0ba92b341bc1de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"303be6a1aef34f0bb878491503135832":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a27f475690b14ef9826a07fdec3d2746":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ca555580f1d42f6853eb3f7eff746d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"84acc4d9ab2045aab85ae7718f0e304a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c1d5ae1ba9804152ad144694b03f8af6","IPY_MODEL_b2fcf64840a94520a22c69f1a85c608d","IPY_MODEL_ce817172231a4557a55b1e778d934080"],"layout":"IPY_MODEL_b35b637170644680994731409e27869f"}},"c1d5ae1ba9804152ad144694b03f8af6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_632b546a39a84339948c9a6468e7a080","placeholder":"​","style":"IPY_MODEL_61ac5a00608d4aa786774b6bc74f4242","value":"vocab.json: 100%"}},"b2fcf64840a94520a22c69f1a85c608d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0e924f8a3ed41809d807b5de73fc633","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6a5df76c170841adacf3d9079b512776","value":1042301}},"ce817172231a4557a55b1e778d934080":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_40012ca9b43e492aa8cb78cce1bf657e","placeholder":"​","style":"IPY_MODEL_5e7f6e2acde74b7b89867a6e5205868d","value":" 1.04M/1.04M [00:00&lt;00:00, 10.3MB/s]"}},"b35b637170644680994731409e27869f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"632b546a39a84339948c9a6468e7a080":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61ac5a00608d4aa786774b6bc74f4242":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b0e924f8a3ed41809d807b5de73fc633":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a5df76c170841adacf3d9079b512776":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"40012ca9b43e492aa8cb78cce1bf657e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e7f6e2acde74b7b89867a6e5205868d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a3390eab43b4982bb8b5856eaedbff4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4d20fcfbacaa48b2b763d884f92ef6f4","IPY_MODEL_3b6555e9210445089ef27769a5303526","IPY_MODEL_7750745706784723a01ed0e137f9771b"],"layout":"IPY_MODEL_28b7ab25d1504320bf46aaa250aad540"}},"4d20fcfbacaa48b2b763d884f92ef6f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f57ee2996f7746ccb1880914b383162b","placeholder":"​","style":"IPY_MODEL_ab61d1f156154f0e869324eb6571ab39","value":"merges.txt: 100%"}},"3b6555e9210445089ef27769a5303526":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_30da32a5bb354ba099cf75fb3b81b815","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_880c79fffe434556b5b964746959e6fc","value":456318}},"7750745706784723a01ed0e137f9771b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f52473b337654224a12e98cb71e6c48a","placeholder":"​","style":"IPY_MODEL_a71a6f5a1ef94099af4728ca059d9aab","value":" 456k/456k [00:00&lt;00:00, 32.0MB/s]"}},"28b7ab25d1504320bf46aaa250aad540":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f57ee2996f7746ccb1880914b383162b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab61d1f156154f0e869324eb6571ab39":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"30da32a5bb354ba099cf75fb3b81b815":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"880c79fffe434556b5b964746959e6fc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f52473b337654224a12e98cb71e6c48a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a71a6f5a1ef94099af4728ca059d9aab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7686ab7efa7c4b4c9217113d33d49207":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c64720282bb24e07a667577e0a78276c","IPY_MODEL_3022464a1b7c423eb0c6758910f4251f","IPY_MODEL_d7b8d24ad7394764b8d84573872ccf95"],"layout":"IPY_MODEL_4945637d586e4c52bb4bc6fe48fd1e66"}},"c64720282bb24e07a667577e0a78276c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db17c784cb8f40958ac5a58f44b772d7","placeholder":"​","style":"IPY_MODEL_30bcfb4d8e6c482aa637de0269ce0fab","value":"tokenizer.json: 100%"}},"3022464a1b7c423eb0c6758910f4251f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_08aa325706234a09af44d42a82ee7755","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_073affe856804bb5a62fe77b8f2624ec","value":1355256}},"d7b8d24ad7394764b8d84573872ccf95":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dfdcde5467414b1aa5e36a21566614f5","placeholder":"​","style":"IPY_MODEL_c7cba8bdea9d4bc3a4846970646f610a","value":" 1.36M/1.36M [00:00&lt;00:00, 39.3MB/s]"}},"4945637d586e4c52bb4bc6fe48fd1e66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db17c784cb8f40958ac5a58f44b772d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30bcfb4d8e6c482aa637de0269ce0fab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"08aa325706234a09af44d42a82ee7755":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"073affe856804bb5a62fe77b8f2624ec":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dfdcde5467414b1aa5e36a21566614f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7cba8bdea9d4bc3a4846970646f610a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b95a599191f1413a9c566a5268b49114":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6d88bc25f6b64b36b84b46da22495b35","IPY_MODEL_6d0f00d5ff85465a9e5b19d6eaea0472","IPY_MODEL_a656f6893a3348a39c4ee82e6c8d9aea"],"layout":"IPY_MODEL_386a568a944946f9be9f85eb1103ee2b"}},"6d88bc25f6b64b36b84b46da22495b35":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d261172a8c064210a3ebc0c88dbd20f3","placeholder":"​","style":"IPY_MODEL_3d6db5c3c14946fd820a11004ecaf6f4","value":"100%"}},"6d0f00d5ff85465a9e5b19d6eaea0472":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_950374d1c36e47238167869e21f02623","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eb8314510878432f9f99e93321004b60","value":50}},"a656f6893a3348a39c4ee82e6c8d9aea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_709adf395fd944cd8b57be04f9b65b8f","placeholder":"​","style":"IPY_MODEL_7ce7b3ce02924a089e4386e24d6137f9","value":" 50/50 [00:05&lt;00:00,  9.35it/s]"}},"386a568a944946f9be9f85eb1103ee2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d261172a8c064210a3ebc0c88dbd20f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d6db5c3c14946fd820a11004ecaf6f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"950374d1c36e47238167869e21f02623":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb8314510878432f9f99e93321004b60":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"709adf395fd944cd8b57be04f9b65b8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ce7b3ce02924a089e4386e24d6137f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"shAFb9-lOVHu"},"source":["## Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"LeRi_tw2dhae","executionInfo":{"status":"ok","timestamp":1715652601638,"user_tz":240,"elapsed":412952,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["%%capture\n","try:\n","    import google.colab # type: ignore\n","    from google.colab import output\n","    %pip install sae-lens==1.3.0 transformer-lens==1.17.0 circuitsvis==1.43.2\n","except:\n","    from IPython import get_ipython # type: ignore\n","    ipython = get_ipython(); assert ipython is not None\n","    ipython.run_line_magic(\"load_ext\", \"autoreload\")\n","    ipython.run_line_magic(\"autoreload\", \"2\")"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"uy-b3CcSOVHu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715652606940,"user_tz":240,"elapsed":5347,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"334662c0-9ce4-4fdc-fecd-c2e312b9c1ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"source":["import torch\n","import os\n","\n","from sae_lens.training.config import LanguageModelSAERunnerConfig\n","from sae_lens.training.lm_runner import language_model_sae_runner\n","\n","if torch.cuda.is_available():\n","    device = \"cuda\"\n","elif torch.backends.mps.is_available():\n","    device = \"mps\"\n","else:\n","    device = \"cpu\"\n","\n","print(\"Using device:\", device)\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""]},{"cell_type":"markdown","metadata":{"id":"oe2nlqf-OVHv"},"source":["# Model Selection and Evaluation\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"hFz6JUMuOVHv","colab":{"base_uri":"https://localhost:8080/","height":422,"referenced_widgets":["59a84549db264ac99cbfeadebf935b6a","9f9a8497d1094c85b13374a30b0ec462","30104ed6599f41178e0e96fae1c1c829","4ad21ab78c8d462191f26efc35d7258b","33d655ade2b24d4aa61a18ddf5ec4614","248e52843d5d4198820f0b9d6908817f","46b29d1ef2f344ddbf3ec66fd035400b","b7d6cd9ce15e49a4903f5bd77da501e1","19c4d05d74ec471fbaee74d24e0bbe8e","f27411fdb60b48f4ae27638f7b92d76f","3f91ef3fabb24a0d923a68757208fb7c","bc36d37d898a44669b6dca624bcb3688","b45e9d14c4e14503a1d41c42c30df00a","b76078e813394f1ab31d1a7a16ce1d0f","ae0551db548342d1933b5bae3547dc5c","b67319d8ce3c495d8bc0b6eceb98d894","e2327ceeb5dc49b4b254fe08ea4fb1ff","d869c2324dbe40f28982bfc40a17c2c7","deadd275ae324490be56f0107dcfd0c4","5a03179709464c20beb017232fd206bd","e703e24912d54e9098aaf1f1ed5ebcff","f899dc41c4144788ae69db47f95efdfc","7dd55aeb846243368138a950ddc4b11c","fa78d5ae2e4746c4948f5489a9098af4","c93411ad85054f1b89ccd4b903465de6","ef49d11f836643a9a256417ded208c23","239d24eadfd8455ba3a817b953b35469","61173e67631c4d15923f783b4e681cc2","26bef72af570486bb0444b051663e0e7","14785e251800478d8f0a9e1dcaa29fbc","fcd50b29affe4a9594a6861280a0e2b7","db5e605e5ff348a4a215ff5da9bacf12","4cce3db2caf54b73b74005be3f7a6ac2","310d07dfae614333bcd4c1072ab8c9b4","f9b3400def1948e7935d2322f92dac50","cbb75df98faa4abdb55459b1b1ea72ea","8ae5ea8f911f4f90a6993fe61811ab42","fd67289b7cf34f34927ecaf506fd6be8","2367dc628693435ba9e9f2cdc16f193c","158a80da367a4cb2a2dfecafc698646c","bb36328e3c0f4586ab0ba92b341bc1de","303be6a1aef34f0bb878491503135832","a27f475690b14ef9826a07fdec3d2746","1ca555580f1d42f6853eb3f7eff746d8","84acc4d9ab2045aab85ae7718f0e304a","c1d5ae1ba9804152ad144694b03f8af6","b2fcf64840a94520a22c69f1a85c608d","ce817172231a4557a55b1e778d934080","b35b637170644680994731409e27869f","632b546a39a84339948c9a6468e7a080","61ac5a00608d4aa786774b6bc74f4242","b0e924f8a3ed41809d807b5de73fc633","6a5df76c170841adacf3d9079b512776","40012ca9b43e492aa8cb78cce1bf657e","5e7f6e2acde74b7b89867a6e5205868d","7a3390eab43b4982bb8b5856eaedbff4","4d20fcfbacaa48b2b763d884f92ef6f4","3b6555e9210445089ef27769a5303526","7750745706784723a01ed0e137f9771b","28b7ab25d1504320bf46aaa250aad540","f57ee2996f7746ccb1880914b383162b","ab61d1f156154f0e869324eb6571ab39","30da32a5bb354ba099cf75fb3b81b815","880c79fffe434556b5b964746959e6fc","f52473b337654224a12e98cb71e6c48a","a71a6f5a1ef94099af4728ca059d9aab","7686ab7efa7c4b4c9217113d33d49207","c64720282bb24e07a667577e0a78276c","3022464a1b7c423eb0c6758910f4251f","d7b8d24ad7394764b8d84573872ccf95","4945637d586e4c52bb4bc6fe48fd1e66","db17c784cb8f40958ac5a58f44b772d7","30bcfb4d8e6c482aa637de0269ce0fab","08aa325706234a09af44d42a82ee7755","073affe856804bb5a62fe77b8f2624ec","dfdcde5467414b1aa5e36a21566614f5","c7cba8bdea9d4bc3a4846970646f610a"]},"executionInfo":{"status":"ok","timestamp":1715652648950,"user_tz":240,"elapsed":42055,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0f1c269f-945b-4b70-9bdc-0e33097c777e"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/689 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59a84549db264ac99cbfeadebf935b6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/6.43G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc36d37d898a44669b6dca624bcb3688"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7dd55aeb846243368138a950ddc4b11c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"310d07dfae614333bcd4c1072ab8c9b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84acc4d9ab2045aab85ae7718f0e304a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a3390eab43b4982bb8b5856eaedbff4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7686ab7efa7c4b4c9217113d33d49207"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Loaded pretrained model gpt2-xl into HookedTransformer\n"]}],"source":["from transformer_lens import HookedTransformer\n","\n","model = HookedTransformer.from_pretrained(\n","    \"gpt2-xl\"\n",")  # This will wrap huggingface models and has lots of nice utilities."]},{"cell_type":"markdown","metadata":{"id":"aUiXrjdUOVHv"},"source":["### Getting a vibe for a model using `model.generate`"]},{"cell_type":"markdown","metadata":{"id":"ZZfKT5aDOVHv"},"source":["Let's start by generating some stories using the model."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"G4ad4Zz1OVHv","colab":{"base_uri":"https://localhost:8080/","height":126},"executionInfo":{"status":"ok","timestamp":1715652659862,"user_tz":240,"elapsed":10961,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b86181a9-204b-4335-be70-83f982dea77e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["'You messed up because you\\'re dumb. You shouldn\\'t have outsourced your shitty four-man desktop team to some other nation. You shouldn\\'t have said dubious things like, \"Abstaining is not blackmail.\" Your shitty outfit for this special event has stupid sounds...'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\"You messed up because you're going to leave your device on when you walk away from it, no matter what stupid fad came out of town. That's why you need a backup.\\n\\nGet Backup\\n\\nA little bit like OP but instead of getting more devices he\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}}],"source":["# here we use generate to get 10 completeions with temperature 1. Feel free to play with the prompt to make it more interesting.\n","for i in range(2):\n","    display(\n","        model.generate(\n","            # \"I think you're\",\n","            \"You messed up because you're\",\n","            stop_at_eos=False,  # avoids a bug on MPS\n","            temperature=1,\n","            verbose=False,\n","            max_new_tokens=50,\n","        )\n","    )"]},{"cell_type":"markdown","metadata":{"id":"RDKr8o1xOVHv"},"source":["One thing we notice is that the model seems to be able to repeat [X] consistently. To better understand the models ability to remember [X], let's extract a prompt where the next character is determined and use the \"test_prompt\" utility from TransformerLens to check the ranking of the token for [X]."]},{"cell_type":"markdown","metadata":{"id":"KsfJX-YpOVHv"},"source":["### Spot checking model abilities with `transformer_lens.utils.test_prompt`"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"TpmPoj7uOVHv","colab":{"base_uri":"https://localhost:8080/","height":280},"executionInfo":{"status":"ok","timestamp":1715652660119,"user_tz":240,"elapsed":274,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"994dc81a-5fc9-4cfe-cd9f-1853c1d36a5d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenized prompt: ['<|endoftext|>', 'I', ' think', ' you', \"'re\"]\n","Tokenized answer: [' angry']\n"]},{"output_type":"display_data","data":{"text/plain":["Performance on answer token:\n","\u001b[1mRank: \u001b[0m\u001b[1;36m248\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m9.03\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.03\u001b[0m\u001b[1m% Token: | angry|\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n","<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">248</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.03</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.03</span><span style=\"font-weight: bold\">% Token: | angry|</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Top 0th token. Logit: 15.02 Prob: 10.41% Token: | right|\n","Top 1th token. Logit: 14.38 Prob:  5.48% Token: | missing|\n","Top 2th token. Logit: 14.27 Prob:  4.89% Token: | being|\n","Top 3th token. Logit: 13.88 Prob:  3.32% Token: | going|\n","Top 4th token. Logit: 13.76 Prob:  2.94% Token: | a|\n","Top 5th token. Logit: 13.47 Prob:  2.20% Token: | making|\n","Top 6th token. Logit: 13.46 Prob:  2.18% Token: | getting|\n","Top 7th token. Logit: 13.42 Prob:  2.09% Token: | talking|\n","Top 8th token. Logit: 13.41 Prob:  2.07% Token: | looking|\n","Top 9th token. Logit: 13.39 Prob:  2.03% Token: | on|\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' angry'\u001b[0m, \u001b[1;36m248\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' angry'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">248</span><span style=\"font-weight: bold\">)]</span>\n","</pre>\n"]},"metadata":{}}],"source":["from transformer_lens.utils import test_prompt\n","\n","# Test the model with a prompt\n","test_prompt(\n","    \"I think you're\",\n","    \" angry\",\n","    model,\n","    prepend_space_to_answer=False,\n",")"]},{"cell_type":"markdown","metadata":{"id":"jGzOvReDOVHv"},"source":["In the output above, we see that the model assigns ~ % probability to [X] being the next token."]},{"cell_type":"markdown","metadata":{"id":"QH8YOZOzOVHv"},"source":["### Exploring Model Capabilities with Log Probs"]},{"cell_type":"markdown","metadata":{"id":"50mqTBihOVHw"},"source":["Look at token log probs for ALL tokens in a prompt. Hover to get the top5 tokens by log probability. Darker tokens are tokens where the model assigned a higher probability to the actual next token.\n","\n","Given prompt \"A B C D\", this predicts the rank of predicting \"C\" given \"A B\". The actual prompt has \"A B C\", but if only \"A B\" was given, how \"much\" does the model expect C? [improve this explanation]"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Tic0RCUpOVHw","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1715652660880,"user_tz":240,"elapsed":800,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"89e82b44-330f-4bc0-b8bb-661e51cd54f1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<circuitsvis.utils.render.RenderedHTML at 0x7ec2f0d3b970>"],"text/html":["<div id=\"circuits-vis-47dbfba7-5751\" style=\"margin: 15px 0;\"/>\n","    <script crossorigin type=\"module\">\n","    import { render, TokenLogProbs } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n","    render(\n","      \"circuits-vis-47dbfba7-5751\",\n","      TokenLogProbs,\n","      {\"prompt\": [\"<|endoftext|>\", \"Hi\", \",\", \" how\", \" are\", \" you\", \" doing\", \" this\", \"?\", \" I\", \"'m\", \" really\", \" enjoying\", \" your\", \" posts\"], \"topKLogProbs\": [[-2.6872425079345703, -3.715317726135254, -3.7391061782836914, -4.057321548461914, -4.083163261413574, -4.277179718017578, -4.56345272064209, -4.786035537719727, -4.840024948120117, -4.921682357788086], [-1.5797330141067505, -2.027867317199707, -2.518280029296875, -2.590961456298828, -2.6814584732055664, -2.930814743041992, -3.703841209411621, -3.7082290649414062, -3.964371681213379, -4.156004905700684], [-1.2318705320358276, -1.7359265089035034, -2.5717782974243164, -2.994002342224121, -3.4413251876831055, -3.494873046875, -3.7443418502807617, -4.275408744812012, -4.586957931518555, -4.770859718322754], [-0.24571247398853302, -2.6420347690582275, -3.656780481338501, -4.192373275756836, -4.237569808959961, -4.753711700439453, -4.913618087768555, -4.970931053161621, -4.990654945373535, -5.3073530197143555], [-0.03641727939248085, -4.4173665046691895, -4.958733081817627, -5.668175220489502, -6.122833728790283, -6.753963947296143, -6.75415563583374, -6.940831661224365, -7.264197826385498, -7.270103931427002], [-0.6300495266914368, -1.803013563156128, -2.566391706466675, -2.714130163192749, -3.3134095668792725, -3.869537115097046, -4.360833168029785, -4.72672176361084, -5.252769470214844, -5.295635223388672], [-0.36235496401786804, -2.0277154445648193, -3.162118673324585, -3.9841878414154053, -4.014175891876221, -4.03933572769165, -4.709605693817139, -5.5270676612854, -5.783412456512451, -5.950422763824463], [-1.6068084239959717, -1.6255261898040771, -2.246575117111206, -2.420941114425659, -2.4848086833953857, -2.5086209774017334, -3.891991376876831, -4.138782501220703, -4.2538299560546875, -4.264670372009277], [-1.6876351833343506, -1.691267728805542, -3.0004794597625732, -3.5912444591522217, -3.6452834606170654, -3.8094260692596436, -3.9082038402557373, -4.138927459716797, -4.2039079666137695, -4.211038589477539], [-0.9844256639480591, -1.781178593635559, -2.76583194732666, -3.050565719604492, -3.126866340637207, -3.3353052139282227, -3.823701858520508, -3.837080955505371, -4.730781555175781, -4.876978874206543], [-3.284498453140259, -3.4799654483795166, -3.5058062076568604, -3.5515472888946533, -3.736788034439087, -3.7611420154571533, -3.951920747756958, -4.018680572509766, -4.040225982666016, -4.1057281494140625], [-1.4299159049987793, -1.8895297050476074, -1.982043743133545, -2.109611988067627, -3.2732672691345215, -3.4283337593078613, -3.7002005577087402, -4.0049262046813965, -4.085874080657959, -4.503758907318115], [-1.6405433416366577, -1.6505874395370483, -2.1066107749938965, -2.702155590057373, -3.4549689292907715, -3.4871678352355957, -3.685403347015381, -3.914625644683838, -4.134899616241455, -4.439239978790283], [-2.2108352184295654, -2.5059049129486084, -2.595972776412964, -3.2893331050872803, -3.7323920726776123, -3.972808599472046, -4.045782089233398, -4.075493812561035, -4.11903190612793, -4.294276237487793]], \"topKTokens\": [[\"The\", \"A\", \"\\\"\", \"I\", \"In\", \"This\", \"It\", \"As\", \"We\", \"If\"], [\",\", \" everyone\", \" there\", \" all\", \"!\", \" guys\", \".\", \" Everyone\", \" All\", \" everybody\"], [\" I\", \"\\n\", \" my\", \"\\n\\n\", \" everyone\", \" this\", \" we\", \" and\", \"I\", \" i\"], [\" are\", \"'s\", \" is\", \" you\", \" can\", \" about\", \" may\", \"'re\", \" do\", \" ya\"], [\" you\", \" ya\", \" things\", \" the\", \" we\", \" your\", \" u\", \" all\", \" ye\", \" y\"], [\"?\", \" doing\", \" all\", \" today\", \" guys\", \",\", \" this\", \"!\", \" ?\", \".\"], [\"?\", \" today\", \",\", \".\", \"!\", \" this\", \" ?\", \" guys\", \" now\", \" tonight\"], [\" morning\", \" evening\", \" week\", \" afternoon\", \" fine\", \" weekend\", \" summer\", \" year\", \" month\", \" time\"], [\"\\n\", \" I\", \" It\", \" We\", \" This\", \" My\", \" If\", \" Well\", \" Welcome\", \" Today\"], [\"'m\", \" am\", \" hope\", \"'ve\", \" have\", \" know\", \" was\", \" just\", \" see\", \" thought\"], [\" a\", \" here\", \" glad\", \" so\", \" writing\", \" back\", \" doing\", \" very\", \" trying\", \" not\"], [\" excited\", \" sorry\", \" happy\", \" glad\", \" looking\", \" enjoying\", \" pleased\", \" busy\", \",\", \" good\"], [\" this\", \" the\", \" your\", \" my\", \" it\", \" reading\", \" working\", \" writing\", \" watching\", \" our\"], [\" blog\", \" work\", \" site\", \" website\", \" new\", \" book\", \" podcast\", \" story\", \" show\", \" article\"]], \"correctTokenRank\": [147, 0, 39, 0, 0, 1, 5, 68, 1, 0, 15, 5, 2, 21], \"correctTokenLogProb\": [-6.979203224182129, -1.5797330141067505, -6.518105506896973, -0.24571247398853302, -0.03641727939248085, -1.803013563156128, -4.03933572769165, -7.823346138000488, -1.691267728805542, -0.9844256639480591, -4.393807411193848, -3.4283337593078613, -2.1066107749938965, -4.952796936035156]}\n","    )\n","    </script>"]},"metadata":{},"execution_count":6}],"source":["import circuitsvis as cv  # optional dep, install with pip install circuitsvis\n","\n","# Let's make a longer prompt and see the log probabilities of the tokens\n","example_prompt = \"\"\"Hi, how are you doing this? I'm really enjoying your posts\"\"\"\n","logits, cache = model.run_with_cache(example_prompt)\n","cv.logits.token_log_probs(\n","    model.to_tokens(example_prompt),\n","    model(example_prompt)[0].log_softmax(dim=-1),\n","    model.to_string,\n",")\n","# hover on the output to see the result."]},{"cell_type":"markdown","metadata":{"id":"lhGIl3YbOVHw"},"source":["Let's combine `model.generate` and the token log probs visualization to see the log probs on text generated by the model. Note that we can play with the temperature and this should sample less likely trajectories according to the model.\n","\n","Some things to explore:\n","- Which tokens does the model assign high probability to? Can you see how the model should know which word comes next?\n","- What happens if you increase / decrease the temperature?\n","- Do the rankings of tokens seem sensible to you? What about where the model doesn't assign a high probability to the token which came next?"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Nikp2ASlOVHw","colab":{"base_uri":"https://localhost:8080/","height":473,"referenced_widgets":["b95a599191f1413a9c566a5268b49114","6d88bc25f6b64b36b84b46da22495b35","6d0f00d5ff85465a9e5b19d6eaea0472","a656f6893a3348a39c4ee82e6c8d9aea","386a568a944946f9be9f85eb1103ee2b","d261172a8c064210a3ebc0c88dbd20f3","3d6db5c3c14946fd820a11004ecaf6f4","950374d1c36e47238167869e21f02623","eb8314510878432f9f99e93321004b60","709adf395fd944cd8b57be04f9b65b8f","7ce7b3ce02924a089e4386e24d6137f9"]},"executionInfo":{"status":"ok","timestamp":1715652666751,"user_tz":240,"elapsed":5929,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9f1aabe1-557b-469a-d8a0-d88ddf45c8bf"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b95a599191f1413a9c566a5268b49114"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["<circuitsvis.utils.render.RenderedHTML at 0x7ec2f0d3beb0>"],"text/html":["<div id=\"circuits-vis-0275434f-678e\" style=\"margin: 15px 0;\"/>\n","    <script crossorigin type=\"module\">\n","    import { render, TokenLogProbs } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n","    render(\n","      \"circuits-vis-0275434f-678e\",\n","      TokenLogProbs,\n","      {\"prompt\": [\"<|endoftext|>\", \"You\", \" messed\", \" up\", \" because\", \" you\", \"'re\", \" smarter\", \" than\", \" woman\", \".\", \" It\", \"'s\", \" your\", \" fault\", \" and\", \" not\", \" anyone\", \" else\", \"'s\", \".\", \" It\", \"'s\", \" not\", \" really\", \" your\", \" fault\", \",\", \" and\", \" it\", \" wouldn\", \"'t\", \" change\", \" the\", \" world\", \".\", \" Every\", \" time\", \" you\", \" messed\", \" up\", \",\", \" the\", \" universe\", \" is\", \" judging\", \" you\", \".\", \" All\", \" it\", \" takes\", \" is\", \" that\", \" one\", \" warning\", \" to\", \" understand\"], \"topKLogProbs\": [[-2.6872377395629883, -3.7153148651123047, -3.739107131958008, -4.057324409484863, -4.083160400390625, -4.277179718017578, -4.563450813293457, -4.786036491394043, -4.840023040771484, -4.921683311462402], [-1.7873629331588745, -2.5576038360595703, -2.62857723236084, -2.747570037841797, -2.8047752380371094, -2.813754081726074, -2.89150333404541, -3.041299819946289, -3.2347869873046875, -3.2431373596191406], [-0.3385504186153412, -1.4747122526168823, -4.356453895568848, -4.5300397872924805, -5.285601615905762, -5.693315505981445, -5.95765495300293, -6.163137435913086, -6.167057037353516, -6.388240814208984], [-1.2483701705932617, -1.8593559265136719, -2.7399988174438477, -3.0622034072875977, -3.0980682373046875, -3.120511054992676, -3.4289941787719727, -3.972315788269043, -4.008922576904297, -4.034462928771973], [-0.3124949634075165, -2.8272788524627686, -3.258756399154663, -3.9420039653778076, -4.086424350738525, -4.121204853057861, -4.995398998260498, -4.998521327972412, -5.29218053817749, -5.350015163421631], [-1.9465878009796143, -2.0086777210235596, -2.2450506687164307, -2.5195229053497314, -3.013073205947876, -3.7174274921417236, -3.804032564163208, -3.8170406818389893, -3.981431245803833, -4.274041175842285], [-1.6439428329467773, -2.0617876052856445, -3.06442928314209, -3.274247169494629, -3.7173662185668945, -3.9257287979125977, -3.9751367568969727, -4.105877876281738, -4.119577407836914, -4.472037315368652], [-0.04606708139181137, -4.196393013000488, -4.529524803161621, -5.006147384643555, -5.996447563171387, -6.436841011047363, -6.9185380935668945, -7.072373390197754, -7.339280128479004, -7.6870527267456055], [-1.6748024225234985, -2.0820908546447754, -2.147940158843994, -2.2820515632629395, -2.576378345489502, -3.073673725128174, -3.478315830230713, -3.816636562347412, -4.018491268157959, -4.313180446624756], [-1.0003598928451538, -1.8411115407943726, -2.301504611968994, -2.7880406379699707, -4.158644199371338, -4.373183727264404, -4.458206653594971, -4.526139736175537, -4.561875820159912, -4.578070163726807], [-1.1202008724212646, -1.9496686458587646, -3.426447629928589, -3.587388753890991, -3.947046995162964, -4.018028259277344, -4.124672889709473, -4.1922101974487305, -4.355189323425293, -4.373735427856445], [-0.312645822763443, -2.7774038314819336, -3.288386344909668, -3.896028518676758, -4.19365119934082, -4.847673416137695, -4.9271955490112305, -5.162570953369141, -5.198504447937012, -5.23637580871582], [-1.6533215045928955, -2.293677568435669, -2.9661333560943604, -3.244584321975708, -3.3141062259674072, -3.38468861579895, -3.7495968341827393, -3.897732973098755, -3.993440866470337, -3.998692750930786], [-0.38094788789749146, -3.4591786861419678, -3.593104124069214, -3.921964406967163, -4.193019866943359, -4.570215225219727, -4.8250274658203125, -4.9058837890625, -5.153110504150391, -5.230053901672363], [-0.9316851496696472, -1.9559962749481201, -2.250168561935425, -2.716146230697632, -3.0491750240325928, -3.0742404460906982, -3.285796880722046, -3.5805823802948, -4.39933443069458, -4.640421390533447], [-0.6653165817260742, -2.5885725021362305, -2.976785659790039, -3.116654396057129, -3.429544448852539, -3.5363569259643555, -3.8240537643432617, -3.915782928466797, -4.308647155761719, -4.344058036804199], [-0.7510876059532166, -2.0752930641174316, -2.157100200653076, -2.7671761512756348, -3.5481886863708496, -3.793006420135498, -3.9844536781311035, -4.0429863929748535, -4.811869144439697, -4.851980686187744], [-0.08349882066249847, -2.9886481761932373, -3.6650893688201904, -7.122180938720703, -7.741913795471191, -7.931269645690918, -8.317815780639648, -8.42709732055664, -8.869088172912598, -9.25538158416748], [-0.05572082847356796, -3.3790507316589355, -4.934432506561279, -6.147035121917725, -6.190094470977783, -7.119253635406494, -7.629085063934326, -7.731582164764404, -7.734867572784424, -7.848449230194092], [-0.14683672785758972, -3.2144217491149902, -4.128047466278076, -4.88478422164917, -4.930837154388428, -4.967372417449951, -5.039885997772217, -5.603392124176025, -5.7718024253845215, -5.813185214996338], [-1.212402105331421, -1.858701467514038, -3.1893155574798584, -3.4814698696136475, -3.5993764400482178, -3.854029417037964, -4.014348030090332, -4.116510391235352, -4.258149147033691, -4.335015296936035], [-0.24133343994617462, -3.1481595039367676, -3.4994397163391113, -3.687443256378174, -4.470109462738037, -4.644785404205322, -4.963501453399658, -5.152108669281006, -5.4195685386657715, -5.4740118980407715], [-1.4637937545776367, -1.5540332794189453, -2.8823537826538086, -3.460421562194824, -3.4865598678588867, -3.811891555786133, -4.145814895629883, -4.152935028076172, -4.284430503845215, -4.536275863647461], [-1.3070189952850342, -2.5952413082122803, -2.9149720668792725, -3.081014394760132, -3.188927412033081, -3.211928129196167, -3.3681581020355225, -3.4318854808807373, -3.5723960399627686, -3.7599246501922607], [-1.328056812286377, -1.9659981727600098, -2.170356273651123, -2.6149048805236816, -3.873288631439209, -4.012035846710205, -4.066727161407471, -4.189849376678467, -4.251514911651611, -4.2718377113342285], [-0.1366763859987259, -3.544320583343506, -4.0824198722839355, -4.357441425323486, -4.878283977508545, -4.983786106109619, -5.0128302574157715, -5.916850566864014, -6.1894145011901855, -6.309070110321045], [-1.0907052755355835, -1.5324395895004272, -2.5509982109069824, -2.810025691986084, -3.0415244102478027, -3.629051685333252, -3.733985424041748, -4.095590114593506, -4.100677967071533, -4.1257853507995605], [-1.5175706148147583, -2.1391372680664062, -2.224257469177246, -2.238276481628418, -3.0176620483398438, -3.3216705322265625, -3.4576826095581055, -3.7473506927490234, -3.86508846282959, -4.157022476196289], [-1.3360153436660767, -1.4338489770889282, -2.8370680809020996, -3.265939235687256, -3.6772828102111816, -3.7774014472961426, -3.8733649253845215, -3.975435733795166, -4.00460958480835, -4.089139461517334], [-0.3695628345012665, -2.7054545879364014, -3.485956907272339, -3.6732242107391357, -3.8451640605926514, -4.147236347198486, -4.176285266876221, -4.421087741851807, -4.454979419708252, -4.9549479484558105], [-0.0003906917118001729, -10.523294448852539, -10.76349925994873, -10.768661499023438, -11.181041717529297, -11.392008781433105, -11.471559524536133, -11.519556999206543, -11.653182029724121, -11.825031280517578], [-1.240295171737671, -1.6151235103607178, -1.8051660060882568, -2.8010785579681396, -2.832427740097046, -3.2204606533050537, -3.5416314601898193, -3.90427565574646, -4.124162673950195, -4.14124870300293], [-1.086228609085083, -1.7919933795928955, -1.9289276599884033, -3.0102970600128174, -3.0156357288360596, -3.5686867237091064, -3.7348101139068604, -3.794490098953247, -4.372488975524902, -4.382580757141113], [-0.6160085201263428, -1.8990933895111084, -2.664898633956909, -2.7043635845184326, -3.7212941646575928, -4.7989397048950195, -4.96723747253418, -5.056146621704102, -5.084616661071777, -5.299350738525391], [-1.132806420326233, -1.2947155237197876, -2.011228084564209, -2.862576961517334, -3.508330821990967, -4.335696697235107, -4.389806270599365, -4.5628533363342285, -4.571339130401611, -4.854177951812744], [-1.227129340171814, -2.1913857460021973, -2.4180874824523926, -3.4855923652648926, -3.518972873687744, -3.546329975128174, -3.755852222442627, -4.069075107574463, -4.188633441925049, -4.249156475067139], [-1.5440318584442139, -1.6473634243011475, -2.313256025314331, -2.7788712978363037, -3.0337655544281006, -3.6815497875213623, -3.753041982650757, -4.302148818969727, -4.468022346496582, -4.729621887207031], [-0.5674152374267578, -2.0837135314941406, -2.3634719848632812, -3.067892074584961, -3.629365921020508, -4.396341323852539, -4.405631065368652, -4.4503679275512695, -4.68658447265625, -4.851125717163086], [-2.8845818042755127, -2.9852707386016846, -3.143686532974243, -3.251939058303833, -3.298609972000122, -3.487502336502075, -3.5430614948272705, -3.602487802505493, -3.626549005508423, -3.6571295261383057], [-0.08805869519710541, -3.103557825088501, -4.2891693115234375, -4.618829727172852, -5.958245277404785, -6.018021583557129, -6.173548698425293, -6.814091682434082, -6.897365570068359, -7.236418724060059], [-0.5136847496032715, -2.67067289352417, -3.025979518890381, -3.3758368492126465, -3.380676746368408, -3.5014615058898926, -4.082306385040283, -4.214242458343506, -4.6457695960998535, -4.74507474899292], [-0.7772031426429749, -1.515108585357666, -3.851832866668701, -3.8824944496154785, -3.949431896209717, -3.984433650970459, -4.166487216949463, -4.374400615692139, -4.4118475914001465, -4.483489513397217], [-1.26543128490448, -2.373638153076172, -3.364659309387207, -3.740847587585449, -3.757704734802246, -3.825942039489746, -3.8595962524414062, -3.9508304595947266, -4.143975257873535, -4.182182312011719], [-1.9019118547439575, -1.945761799812317, -2.5893545150756836, -3.0262889862060547, -3.397500991821289, -3.600177764892578, -3.941685676574707, -4.163762092590332, -4.230831146240234, -4.41359806060791], [-2.647153854370117, -2.8792848587036133, -3.0467090606689453, -3.303948402404785, -3.470478057861328, -3.5138683319091797, -3.5451231002807617, -3.61971378326416, -3.880990982055664, -4.339103698730469], [-0.06817684322595596, -3.4936814308166504, -5.321277141571045, -5.435182094573975, -5.632069110870361, -6.2480692863464355, -6.4134087562561035, -6.637826442718506, -6.676916599273682, -6.704470157623291], [-1.117750644683838, -1.884148120880127, -1.983126163482666, -2.0394539833068848, -3.5953211784362793, -3.807565212249756, -3.9591526985168457, -4.106536388397217, -4.466503620147705, -4.507761478424072], [-1.89222252368927, -1.9129706621170044, -1.9610320329666138, -3.048542022705078, -3.189249038696289, -3.409104347229004, -3.564824104309082, -3.576620101928711, -3.7259960174560547, -4.193662643432617], [-1.4937188625335693, -1.5502889156341553, -1.8976304531097412, -2.4965789318084717, -3.116119146347046, -3.228919744491577, -3.413774251937866, -3.4149529933929443, -3.914849042892456, -4.123842239379883], [-1.216251015663147, -1.9344955682754517, -2.303679943084717, -2.629363536834717, -2.914212703704834, -3.144538402557373, -3.3175177574157715, -3.6057066917419434, -3.8465209007263184, -3.8539977073669434], [-0.1336718201637268, -2.493624687194824, -3.773543357849121, -5.36946964263916, -5.382174491882324, -6.779354095458984, -7.12185001373291, -7.4577531814575195, -7.540814399719238, -7.5581207275390625], [-0.6156583428382874, -1.7479443550109863, -2.8423733711242676, -3.8761143684387207, -3.9084811210632324, -4.318283557891846, -4.732576847076416, -4.775766849517822, -4.779865741729736, -4.831228733062744], [-0.2466285079717636, -3.5678794384002686, -3.760380506515503, -3.86719012260437, -4.467627048492432, -4.700470447540283, -4.779709339141846, -4.811342716217041, -4.893944263458252, -5.60365629196167], [-1.6613343954086304, -2.7098631858825684, -2.8393454551696777, -2.9283547401428223, -2.928591251373291, -3.039313793182373, -3.2855582237243652, -3.39802885055542, -3.4100165367126465, -4.069971561431885], [-1.747610330581665, -2.3479197025299072, -2.490391969680786, -2.7351438999176025, -3.47697377204895, -3.578237771987915, -3.617802858352661, -3.6447298526763916, -3.8620874881744385, -4.140390396118164], [-2.534503698348999, -2.6612279415130615, -2.9949004650115967, -3.160114049911499, -3.3608815670013428, -3.459028959274292, -3.6633927822113037, -3.6658780574798584, -3.7923295497894287, -3.8289878368377686]], \"topKTokens\": [[\"The\", \"A\", \"\\\"\", \"I\", \"In\", \"This\", \"It\", \"As\", \"We\", \"If\"], [\" can\", \" may\", \" are\", \"'ve\", \" must\", \" have\", \" know\", \"'re\", \" don\", \" might\"], [\" up\", \" with\", \" me\", \" it\", \" this\", \" around\", \" the\", \" your\", \" us\", \" something\"], [\".\", \",\", \"!\", \" your\", \" big\", \" and\", \" the\", \" a\", \" my\", \"\\n\"], [\" you\", \" of\", \" your\", \" I\", \" the\", \" it\", \" this\", \",\", \" there\", \" we\"], [\"'re\", \" were\", \" didn\", \" are\", \" don\", \" have\", \" thought\", \" weren\", \" did\", \" had\"], [\" a\", \" not\", \" an\", \" human\", \" stupid\", \" too\", \" trying\", \" the\", \" in\", \" young\"], [\" than\", \" and\", \",\", \".\", \" or\", \" then\", \" that\", \"\\n\", \"/\", \" (\"], [\" you\", \" me\", \" your\", \" the\", \" everyone\", \" I\", \" us\", \" God\", \" a\", \" other\"], [\".\", \",\", \"\\n\", \" and\", \"hood\", \" who\", \" in\", \" #\", \" you\", \"!\"], [\"\\n\", \" You\", \" I\", \" That\", \" It\", \"\\n\\n\", \" And\", \" \\u2014\", \" Women\", \" If\"], [\"'s\", \" doesn\", \" is\", \" was\", \" happens\", \" isn\", \" sucks\", \" has\", \" wasn\", \" makes\"], [\" not\", \" a\", \" okay\", \" your\", \" that\", \" the\", \" just\", \" true\", \" called\", \" simple\"], [\" fault\", \" job\", \" own\", \" responsibility\", \" problem\", \" turn\", \" choice\", \" brain\", \" nature\", \" fucking\"], [\".\", \",\", \" for\", \" that\", \" you\", \" and\", \" because\", \" she\", \"!\", \" if\"], [\" you\", \" it\", \" she\", \" your\", \" not\", \" I\", \" no\", \" there\", \" that\", \" if\"], [\" hers\", \" theirs\", \" her\", \" the\", \" that\", \" their\", \" a\", \" anyone\", \" woman\", \" because\"], [\" else\", \" el\", \"'s\", \" EL\", \" in\", \" but\", \" who\", \" or\", \" other\", \",\"], [\"'s\", \".\", \"'.\", \".'\", \",\", \"s\", \" who\", \"\\n\", \"',\", \"'\"], [\".\", \",\", \"\\n\", \" (\", \" or\", \"!\", \" because\", \" and\", \".\\\"\", \" \\u2014\"], [\"\\n\", \" You\", \" It\", \" If\", \" I\", \" Women\", \" And\", \" That\", \"\\n\\n\", \" Don\"], [\"'s\", \" doesn\", \" was\", \" is\", \" wasn\", \" isn\", \" happens\", \" will\", \" can\", \" sucks\"], [\" not\", \" your\", \" a\", \" okay\", \" the\", \" just\", \" because\", \" all\", \" also\", \" never\"], [\" your\", \" a\", \" her\", \" about\", \" their\", \" that\", \" like\", \" even\", \" the\", \" fair\"], [\" your\", \" a\", \" about\", \" that\", \" her\", \" even\", \" the\", \" fair\", \" up\", \" their\"], [\" fault\", \" problem\", \" job\", \" place\", \" responsibility\", \" business\", \" choice\", \" decision\", \" body\", \" issue\"], [\".\", \",\", \" because\", \" that\", \" at\", \" but\", \" and\", \" you\", \" though\", \" if\"], [\" but\", \" you\", \" it\", \" because\", \" and\", \" either\", \" though\", \" really\", \" so\", \" just\"], [\" you\", \" it\", \" if\", \" I\", \" that\", \" not\", \" the\", \" no\", \" there\", \" even\"], [\"'s\", \" doesn\", \" isn\", \" shouldn\", \" is\", \" won\", \" never\", \" will\", \" can\", \" should\"], [\"'t\", \"\\n\", \"\\u00b4\", \"'\", \"`\", \"\\ufffd\", \" the\", \".\", \"'s\", \",\"], [\" be\", \" have\", \" matter\", \" really\", \" even\", \" change\", \" make\", \" happen\", \" hurt\", \" help\"], [\" anything\", \" the\", \" if\", \" things\", \" a\", \" your\", \".\", \" what\", \",\", \" even\"], [\" fact\", \" world\", \" outcome\", \" situation\", \" way\", \" facts\", \" reality\", \" past\", \" truth\", \" circumstances\"], [\".\", \" if\", \",\", \" anyway\", \" for\", \" in\", \" to\", \" or\", \" because\", \" but\"], [\"\\n\", \" You\", \" It\", \" If\", \" But\", \" Women\", \" I\", \" And\", \" The\", \" That\"], [\" time\", \" woman\", \" single\", \" man\", \" day\", \" person\", \" girl\", \" guy\", \" one\", \" human\"], [\" you\", \" a\", \" I\", \" someone\", \" we\", \".\", \" she\", \" women\", \",\", \" there\"], [\" try\", \" get\", \"'re\", \" say\", \" make\", \" screw\", \" see\", \" think\", \" do\", \" have\"], [\" up\", \" something\", \" it\", \" with\", \" this\", \" things\", \" that\", \" around\", \"-\", \" a\"], [\",\", \" you\", \" and\", \" because\", \" it\", \" in\", \" or\", \" with\", \" a\", \" as\"], [\" you\", \" it\", \" I\", \" the\", \" your\", \" someone\", \" there\", \" women\", \" every\", \" that\"], [\" world\", \" woman\", \" only\", \" universe\", \" person\", \" girl\", \" next\", \" whole\", \" women\", \" blame\"], [\" was\", \" is\", \" would\", \" made\", \" will\", \" just\", \" punished\", \" has\", \" had\", \" didn\"], [\" going\", \" just\", \" like\", \" telling\", \" still\", \" a\", \" punishing\", \" trying\", \" saying\", \" not\"], [\" you\", \" your\", \" and\", \" it\", \" the\", \" how\", \".\", \",\", \" YOU\", \" on\"], [\".\", \",\", \" for\", \" and\", \" because\", \" on\", \" as\", \" harshly\", \" by\", \" to\"], [\"\\n\", \" You\", \" It\", \" Every\", \" And\", \" If\", \" But\", \" That\", \" The\", \" So\"], [\" you\", \" the\", \" of\", \" women\", \" your\", \" that\", \" those\", \" it\", \" this\", \" because\"], [\" takes\", \" would\", \" does\", \"'s\", \" needs\", \" wants\", \" says\", \" is\", \" really\", \" has\"], [\" is\", \" to\", \" for\", \",\", \" are\", \" in\", \" now\", \" it\", \" from\", \" a\"], [\" one\", \" a\", \" for\", \" the\", \" to\", \" just\", \" some\", \" that\", \" an\", \" you\"], [\" one\", \" single\", \" little\", \" tiny\", \" first\", \" once\", \" moment\", \" small\", \" you\", \" stupid\"], [\" time\", \" mistake\", \" little\", \" stupid\", \" bad\", \" wrong\", \" thing\", \" moment\", \" tiny\", \" person\"], [\" sign\", \",\", \" shot\", \".\", \" light\", \" from\", \" word\", \" and\", \" that\", \" to\"], [\" change\", \" make\", \" realize\", \" be\", \" the\", \" get\", \" you\", \" stop\", \" say\", \" know\"]], \"correctTokenRank\": [29, 1043, 0, 42, 0, 0, 163, 0, 349, 0, 4, 0, 3, 0, 5, 4, 7, 0, 0, 0, 2, 0, 0, 18, 0, 0, 1, 4, 1, 25, 0, 5, 1, 1, 0, 78, 0, 0, 133, 0, 0, 3, 3, 1, 59, 0, 0, 29, 7, 0, 0, 7, 0, 743, 9, 22], \"correctTokenLogProb\": [-5.325375556945801, -11.413673400878906, -0.3385504186153412, -6.563363075256348, -0.3124949634075165, -1.9465878009796143, -7.457328796386719, -0.04606708139181137, -9.645880699157715, -1.0003598928451538, -3.947046995162964, -0.312645822763443, -3.244584321975708, -0.38094788789749146, -3.0742404460906982, -3.429544448852539, -4.0429863929748535, -0.08349882066249847, -0.05572082847356796, -0.14683672785758972, -3.1893155574798584, -0.24133343994617462, -1.4637937545776367, -4.7629899978637695, -1.328056812286377, -0.1366763859987259, -1.5324395895004272, -3.0176620483398438, -1.4338489770889282, -6.230407238006592, -0.0003906917118001729, -3.2204606533050537, -1.7919933795928955, -1.8990933895111084, -1.132806420326233, -6.8832173347473145, -1.5440318584442139, -0.5674152374267578, -6.9587907791137695, -0.08805869519710541, -0.5136847496032715, -3.8824944496154785, -3.740847587585449, -1.945761799812317, -6.044591903686523, -0.06817684322595596, -1.117750644683838, -5.565461158752441, -3.4149529933929443, -1.216251015663147, -0.1336718201637268, -4.775766849517822, -0.2466285079717636, -9.800475120544434, -4.140390396118164, -4.700630187988281]}\n","    )\n","    </script>"]},"metadata":{},"execution_count":7}],"source":["example_prompt = model.generate(\n","    \"You messed up because you're\",\n","    stop_at_eos=False,  # avoids a bug on MPS\n","    temperature=1,\n","    verbose=True,\n","    max_new_tokens=50,\n",")\n","logits, cache = model.run_with_cache(example_prompt)\n","cv.logits.token_log_probs(\n","    model.to_tokens(example_prompt),\n","    model(example_prompt)[0].log_softmax(dim=-1),\n","    model.to_string,\n",")"]},{"cell_type":"markdown","metadata":{"id":"er3H1TDoOVHw"},"source":["# Training an SAE\n","\n","Now we're ready to train out SAE. We'll make a runner config, instantiate the runner and the rest is taken care of for us!\n","\n","During training, you use weights and biases to check key metrics which indicate how well we are able to optimize the variables we care about.\n","\n","To get a better sense of which variables to look at, you can read my (Joseph's) post [here](https://www.lesswrong.com/posts/f9EgfLSurAiqRJySD/open-source-sparse-autoencoders-for-all-residual-stream) and especially look at my weights and biases report [here](https://links-cdn.wandb.ai/wandb-public-images/links/jbloom/uue9i416.html).\n","\n","A few tips:\n","- Feel free to reorganize your wandb dashboard to put L0, CE_Loss_score, explained variance and other key metrics in one section at the top.\n","- Make a [run comparer](https://docs.wandb.ai/guides/app/features/panels/run-comparer) when tuning hyperparameters.\n","- You can download the resulting sparse autoencoder / sparsity estimate from wandb and upload them to huggingface if you want to share your SAE with other.\n","    - cfg.json (training config)\n","    - sae_weight.safetensors (model weights)\n","    - sparsity.safetensors (sparsity estimate)"]},{"cell_type":"markdown","metadata":{"id":"jCHtPycOOVHw"},"source":["## MLP Out\n","\n","I've tuned the hyperparameters below for a decent SAE which achieves 86% CE Loss recovered and an L0 of ~85, and runs in about 2 hours on an M3 Max. You can get an SAE that looks better faster if you only consider L0 and CE loss but it will likely have more dense features and more dead features. Here's a link to my output with two runs with two different L1's: https://wandb.ai/jbloom/sae_lens_tutorial ."]},{"cell_type":"markdown","source":["Paste wandb API key below"],"metadata":{"id":"arFFHcl7jXTU"}},{"cell_type":"code","execution_count":8,"metadata":{"id":"oAsZCAdJOVHw","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1715652711071,"user_tz":240,"elapsed":44388,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"93e79ff2-d4ff-4fd6-e357-e554e25e02b1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Warning: We are initializing b_dec to zeros. This is probably not what you want.\n","Run name: 25600-L1-5-LR-5e-05-Tokens-4.096e+06\n","n_tokens_per_buffer (millions): 0.524288\n","Lower bound: n_contexts_per_buffer (millions): 0.002048\n","Total training steps: 1000\n","Total wandb updates: 33\n","n_tokens_per_feature_sampling_window (millions): 1048.576\n","n_tokens_per_dead_feature_window (millions): 1048.576\n","We will reset the sparsity calculation 1 times.\n","Number tokens in sparsity calculation window: 4.10e+06\n","Loaded pretrained model gpt2-xl into HookedTransformer\n","Moving model to device:  cuda\n","Warning: We are initializing b_dec to zeros. This is probably not what you want.\n","Run name: 25600-L1-5-LR-5e-05-Tokens-4.096e+06\n","n_tokens_per_buffer (millions): 0.524288\n","Lower bound: n_contexts_per_buffer (millions): 0.002048\n","Total training steps: 1000\n","Total wandb updates: 33\n","n_tokens_per_feature_sampling_window (millions): 1048.576\n","n_tokens_per_dead_feature_window (millions): 1048.576\n","We will reset the sparsity calculation 1 times.\n","Number tokens in sparsity calculation window: 4.10e+06\n","Warning: We are initializing b_dec to zeros. This is probably not what you want.\n","Run name: 25600-L1-5-LR-5e-05-Tokens-4.096e+06\n","n_tokens_per_buffer (millions): 0.524288\n","Lower bound: n_contexts_per_buffer (millions): 0.002048\n","Total training steps: 1000\n","Total wandb updates: 33\n","n_tokens_per_feature_sampling_window (millions): 1048.576\n","n_tokens_per_dead_feature_window (millions): 1048.576\n","We will reset the sparsity calculation 1 times.\n","Number tokens in sparsity calculation window: 4.10e+06\n"]},{"output_type":"stream","name":"stderr","text":["ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":[" ··········\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.17.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20240514_021149-o0f7crgl</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/wlg100/sae_lens_exploraTest_L1/runs/o0f7crgl' target=\"_blank\">25600-L1-5-LR-5e-05-Tokens-4.096e+06</a></strong> to <a href='https://wandb.ai/wlg100/sae_lens_exploraTest_L1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/wlg100/sae_lens_exploraTest_L1' target=\"_blank\">https://wandb.ai/wlg100/sae_lens_exploraTest_L1</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/wlg100/sae_lens_exploraTest_L1/runs/o0f7crgl' target=\"_blank\">https://wandb.ai/wlg100/sae_lens_exploraTest_L1/runs/o0f7crgl</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\rTraining SAE:   0%|          | 0/4096000 [00:00<?, ?it/s]"]},{"output_type":"error","ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 39.56 GiB of which 122.81 MiB is free. Process 11468 has 39.44 GiB memory in use. Of the allocated memory 38.82 GiB is allocated by PyTorch, and 131.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-3ab33e669926>\u001b[0m in \u001b[0;36m<cell line: 76>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;31m# look at the next cell to see some instruction for what to do while this is running.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0msparse_autoencoder_dictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlanguage_model_sae_runner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sae_lens/training/lm_runner.py\u001b[0m in \u001b[0;36mlanguage_model_sae_runner\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# train SAE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     sparse_autoencoder = train_sae_on_language_model(\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0msparse_autoencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sae_lens/training/train_sae_on_language_model.py\u001b[0m in \u001b[0;36mtrain_sae_on_language_model\u001b[0;34m(model, sae_group, activation_store, batch_size, n_checkpoints, feature_sampling_window, dead_feature_threshold, use_wandb, wandb_log_frequency)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdeprecated\u001b[0m \u001b[0mUse\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtrain_sae_group_on_language_model\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstead\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mkept\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbackward\u001b[0m \u001b[0mcompatibility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m     return train_sae_group_on_language_model(\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0msae_group\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sae_lens/training/train_sae_on_language_model.py\u001b[0m in \u001b[0;36mtrain_sae_group_on_language_model\u001b[0;34m(model, sae_group, activation_store, batch_size, n_checkpoints, feature_sampling_window, use_wandb, wandb_log_frequency)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mn_training_tokens\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_training_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# Do a training step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mlayer_acts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivation_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mn_training_tokens\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sae_lens/training/activations_store.py\u001b[0m in \u001b[0;36mnext_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0;31m# Try to get the next batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;31m# If the DataLoader is exhausted, create a new one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sae_lens/training/activations_store.py\u001b[0m in \u001b[0;36mdataloader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sae_lens/training/activations_store.py\u001b[0m in \u001b[0;36mget_data_loader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;31m# 1. # create new buffer by mixing stored and new buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         mixing_buffer = torch.cat(\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_batches_in_buffer\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage_buffer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m             \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sae_lens/training/activations_store.py\u001b[0m in \u001b[0;36mget_buffer\u001b[0;34m(self, n_batches_in_buffer)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrefill_batch_idx_start\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrefill_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mrefill_batch_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             \u001b[0mrefill_activations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_activations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefill_batch_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m             new_buffer[\n\u001b[1;32m    346\u001b[0m                 \u001b[0mrefill_batch_idx_start\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mrefill_batch_idx_start\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sae_lens/training/activations_store.py\u001b[0m in \u001b[0;36mget_activations\u001b[0;34m(self, batch_tokens)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mact_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhook_point\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mhook_point_max_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         layerwise_activations = self.model.run_with_cache(\n\u001b[0m\u001b[1;32m    252\u001b[0m             \u001b[0mbatch_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mnames_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mact_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/HookedTransformer.py\u001b[0m in \u001b[0;36mrun_with_cache\u001b[0;34m(self, return_cache_object, remove_batch_dim, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0mactivations\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mHookedRootModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m         \"\"\"\n\u001b[0;32m--> 627\u001b[0;31m         out, cache_dict = super().run_with_cache(\n\u001b[0m\u001b[1;32m    628\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_batch_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mremove_batch_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/hook_points.py\u001b[0m in \u001b[0;36mrun_with_cache\u001b[0;34m(self, names_filter, device, remove_batch_dim, incl_bwd, reset_hooks_end, clear_contexts, pos_slice, *model_args, **model_kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0mclear_contexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclear_contexts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         ):\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mmodel_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mincl_bwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0mmodel_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/HookedTransformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    548\u001b[0m                     )\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m                 residual = block(\n\u001b[0m\u001b[1;32m    551\u001b[0m                     \u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                     \u001b[0;31m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/components.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[0m\n\u001b[1;32m   1583\u001b[0m             \u001b[0;31m# queries, keys and values, independently.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m             \u001b[0;31m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1585\u001b[0;31m             self.attn(\n\u001b[0m\u001b[1;32m   1586\u001b[0m                 \u001b[0mquery_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mshortformer_pos_embed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mshortformer_pos_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/components.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query_input, key_input, value_input, past_kv_cache_entry, additive_attention_mask, attention_mask)\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         attn_scores = self.calculate_attention_scores(\n\u001b[0m\u001b[1;32m    557\u001b[0m             \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         )  # [batch, head_index, query_pos, key_pos]\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/components.py\u001b[0m in \u001b[0;36mcalculate_attention_scores\u001b[0;34m(self, q, k)\u001b[0m\n\u001b[1;32m    746\u001b[0m     ) -> Float[torch.Tensor, \"batch head_index query_pos key_pos\"]:\n\u001b[1;32m    747\u001b[0m         attn_scores = (\n\u001b[0;32m--> 748\u001b[0;31m             einsum(\n\u001b[0m\u001b[1;32m    749\u001b[0m                 \u001b[0;31m\"\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0mquery_pos\u001b[0m \u001b[0mhead_index\u001b[0m \u001b[0md_head\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[0mkey_pos\u001b[0m \u001b[0mhead_index\u001b[0m \u001b[0md_head\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fancy_einsum/__init__.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(equation, *operands)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0mnew_equation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_equation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_equation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fancy_einsum/__init__.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(self, equation, *operands)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;31m# the path for contracting 0 or 1 time(s) is already optimized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;31m# or the user has disabled using opt_einsum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 39.56 GiB of which 122.81 MiB is free. Process 11468 has 39.44 GiB memory in use. Of the allocated memory 38.82 GiB is allocated by PyTorch, and 131.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["# total_training_steps = 30_000  # probably we should do more\n","total_training_steps = 1000  # probably we should do more\n","batch_size = 4096\n","# batch_size = 4\n","total_training_tokens = total_training_steps * batch_size\n","\n","lr_warm_up_steps = 0\n","lr_decay_steps = total_training_steps // 5  # 20% of training\n","l1_warm_up_steps = total_training_steps // 20  # 5% of training\n","\n","cfg = LanguageModelSAERunnerConfig(\n","    # Data Generating Function (Model + Training Distibuion)\n","    model_name=\"gpt2-xl\",  # our model (more options here: https://neelnanda-io.github.io/TransformerLens/generated/model_properties_table.html)\n","    # hook_point=\"blocks.20.hook_mlp_out\",  # A valid hook point (see more details here: https://neelnanda-io.github.io/TransformerLens/generated/demos/Main_Demo.html#Hook-Points)\n","    # hook_point_layer=20,  # Only one layer in the model.\n","    hook_point=\"blocks.10.hook_mlp_out\",  # A valid hook point (see more details here: https://neelnanda-io.github.io/TransformerLens/generated/demos/Main_Demo.html#Hook-Points)\n","    hook_point_layer=10,  # Only one layer in the model.\n","    # d_in=1024,  # the width of the mlp output.\n","    d_in=1600,  # the width of the mlp output.\n","    # dataset_path=\"apollo-research/roneneldan-TinyStories-tokenizer-gpt2\",  # this is a tokenized language dataset on Huggingface for the Tiny Stories corpus.\n","    dataset_path=\"stas/openwebtext-10k\",\n","    is_dataset_tokenized=True,\n","    # streaming=True,  # we could pre-download the token dataset if it was small.\n","\n","    # SAE Parameters\n","    mse_loss_normalization=None,  # We won't normalize the mse loss,\n","    expansion_factor=16,  # the width of the SAE. Larger will result in better stats but slower training.\n","    b_dec_init_method=\"zeros\",  # The geometric median can be used to initialize the decoder weights.\n","    apply_b_dec_to_input=False,  # We won't apply the decoder weights to the input.\n","    normalize_sae_decoder=False,\n","    # scale_sparsity_penalty_by_decoder_norm=True,\n","    # decoder_heuristic_init=True,\n","    # init_encoder_as_decoder_transpose=True,\n","    # normalize_activations=False,\n","\n","    # Training Parameters\n","    lr=5e-5,  # lower the better, we'll go fairly high to speed up the tutorial.\n","    adam_beta1=0.9,  # adam params (default, but once upon a time we experimented with these.)\n","    adam_beta2=0.999,\n","    lr_scheduler_name=\"constant\",  # constant learning rate with warmup. Could be better schedules out there.\n","    lr_warm_up_steps=lr_warm_up_steps,  # this can help avoid too many dead features initially.\n","    lr_decay_steps=lr_decay_steps,  # this will help us avoid overfitting.\n","    l1_coefficient=5,  # will control how sparse the feature activations are\n","    # l1_warm_up_steps=l1_warm_up_steps,  # this can help avoid too many dead features initially.\n","    lp_norm=1.0,  # the L1 penalty (and not a Lp for p < 1)\n","    # train_batch_size_tokens=batch_size,\n","    context_size=256,  # will control the lenght of the prompts we feed to the model. Larger is better but slower. so for the tutorial we'll use a short one.\n","    # Activation Store Parameters\n","    n_batches_in_buffer=64,  # controls how many activations we store / shuffle.\n","    training_tokens=total_training_tokens,  # 100 million tokens is quite a few, but we want to see good stats. Get a coffee, come back.\n","    # store_batch_size_prompts=16,\n","\n","    # Resampling protocol\n","    use_ghost_grads=False,  # we don't use ghost grads anymore.\n","    feature_sampling_window=1000,  # this controls our reporting of feature sparsity stats\n","    dead_feature_window=1000,  # would effect resampling or ghost grads if we were using it.\n","    dead_feature_threshold=1e-4,  # would effect resampling or ghost grads if we were using it.\n","\n","    # WANDB\n","    log_to_wandb=True,  # always use wandb unless you are just testing code.\n","    # log_to_wandb=False,\n","    wandb_project=\"sae_lens_exploraTest_L10\",\n","    # wandb_project=\"sae_lens_tutorial\",\n","    wandb_log_frequency=30,\n","    # eval_every_n_wandb_logs=20,\n","\n","    # Misc\n","    device=device,\n","    seed=42,\n","    n_checkpoints=0,\n","    checkpoint_path=\"checkpoints\",\n","    dtype=torch.float32,\n",")\n","\n","# look at the next cell to see some instruction for what to do while this is running.\n","sparse_autoencoder_dictionary = language_model_sae_runner(cfg)"]},{"cell_type":"markdown","metadata":{"id":"khR_QkAJOVHw"},"source":["# Interpret SAE\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b4sUumxZOVHw","executionInfo":{"status":"aborted","timestamp":1715652711072,"user_tz":240,"elapsed":9,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["import pandas as pd\n","\n","# Let's start by getting the top 10 logits for each feature\n","\n","sparse_autoencoder = next(iter(sparse_autoencoder_dictionary))[1]\n","projection_onto_unembed = sparse_autoencoder.W_dec @ model.W_U\n","\n","\n","# get the top 10 logits.\n","vals, inds = torch.topk(projection_onto_unembed, 10, dim=1)\n","\n","# get 10 random features\n","random_indices = torch.randint(0, projection_onto_unembed.shape[0], (10,))\n","\n","# Show the top 10 logits promoted by those features\n","top_10_logits_df = pd.DataFrame(\n","    [model.to_str_tokens(i) for i in inds[random_indices]],\n","    index=random_indices.tolist(),\n",").T\n","top_10_logits_df"]}]}