{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"L4","collapsed_sections":["-WMqbetGrf4e","2LxnTmFDpb2z","oD7tg7OUIoPh","7wRx4SMDHVl4","9TqjxZYsFviC"],"machine_shape":"hm","authorship_tag":"ABX9TyMn/NUoL1Hgm0ji6h/P0kWu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"6c714b7494e04e5a8e9e7e5aed59b06e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a0cb4b0c07ac49d3981776093fe13bec","IPY_MODEL_048f6d583e3744e29fcefb74c9ab378a","IPY_MODEL_6fb3e0ee47de49f3a9fb1377d002a1c9"],"layout":"IPY_MODEL_97fddb273490463b8d40cc417d5e7e1b"}},"a0cb4b0c07ac49d3981776093fe13bec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_35a7ec07c4864503818599a9addf9bec","placeholder":"​","style":"IPY_MODEL_bcc3df093de1421697e176687129f4e0","value":"config.json: 100%"}},"048f6d583e3744e29fcefb74c9ab378a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc799cb00be1442b85653ad9b1d16857","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4f79f235f43d4bbcbc9684fa756af4fd","value":665}},"6fb3e0ee47de49f3a9fb1377d002a1c9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b24bf531d096488db149fbacef718ac7","placeholder":"​","style":"IPY_MODEL_4e287ecbf8da438bad41ca6437e93d33","value":" 665/665 [00:00&lt;00:00, 62.4kB/s]"}},"97fddb273490463b8d40cc417d5e7e1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35a7ec07c4864503818599a9addf9bec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcc3df093de1421697e176687129f4e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc799cb00be1442b85653ad9b1d16857":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f79f235f43d4bbcbc9684fa756af4fd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b24bf531d096488db149fbacef718ac7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e287ecbf8da438bad41ca6437e93d33":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"535727d826ab444b8d6671a0277f4d79":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7dced8113e4f46c4adb8fde69d89c592","IPY_MODEL_4e2793b8ed4a483c8fd2e00ffe3bf3f4","IPY_MODEL_5fa5dde0cee141c4875306d3bf0b24a9"],"layout":"IPY_MODEL_38691521dbb04803bedc0852872028cd"}},"7dced8113e4f46c4adb8fde69d89c592":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_405e1fcff6204ec0898a7b5939f38032","placeholder":"​","style":"IPY_MODEL_9d9f34de290a4dd18df6b81852b29215","value":"model.safetensors: 100%"}},"4e2793b8ed4a483c8fd2e00ffe3bf3f4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2eeb84f103fe40fdad4df74a985365c1","max":548105171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b45954f4bccd4ab6bdeeb15e53b7a935","value":548105171}},"5fa5dde0cee141c4875306d3bf0b24a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_28ee2f2b9b124c5b8dd669e84bf3af91","placeholder":"​","style":"IPY_MODEL_ecabd75433fc4523a7fbbd16c119c73f","value":" 548M/548M [00:01&lt;00:00, 282MB/s]"}},"38691521dbb04803bedc0852872028cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"405e1fcff6204ec0898a7b5939f38032":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d9f34de290a4dd18df6b81852b29215":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2eeb84f103fe40fdad4df74a985365c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b45954f4bccd4ab6bdeeb15e53b7a935":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"28ee2f2b9b124c5b8dd669e84bf3af91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ecabd75433fc4523a7fbbd16c119c73f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b2160e5f02414b569d0d8efc8c0988c6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dd0bc67682714ef6b6f77bf161db5dc3","IPY_MODEL_97463a8efbd840a4ba191834afa9b35b","IPY_MODEL_dec4664d7f0b4e5ab517fe15c264d9fd"],"layout":"IPY_MODEL_d164b209ff0a40e5b30d8a4ecdb2d972"}},"dd0bc67682714ef6b6f77bf161db5dc3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_541304aeef974bb8bd46f12726e0fd1f","placeholder":"​","style":"IPY_MODEL_902839c872e547bc8cac47124e8e76a9","value":"generation_config.json: 100%"}},"97463a8efbd840a4ba191834afa9b35b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3fd692d4fc9e4ec6ac648c175c7e1b5c","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e47ef65fa84a459aaab8d4e8b62d158f","value":124}},"dec4664d7f0b4e5ab517fe15c264d9fd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c228ffb5314449f094e39f4ff3f6610e","placeholder":"​","style":"IPY_MODEL_10fb34c61297433896b85e80041680b8","value":" 124/124 [00:00&lt;00:00, 9.46kB/s]"}},"d164b209ff0a40e5b30d8a4ecdb2d972":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"541304aeef974bb8bd46f12726e0fd1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"902839c872e547bc8cac47124e8e76a9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3fd692d4fc9e4ec6ac648c175c7e1b5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e47ef65fa84a459aaab8d4e8b62d158f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c228ffb5314449f094e39f4ff3f6610e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10fb34c61297433896b85e80041680b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9568c3f353724f309e75eb8b4dbac062":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_857caa5a17df40acb1e9dd98bac010ae","IPY_MODEL_1f1a4cf4191e4231bba17fc1809d7c68","IPY_MODEL_86e691771e61477d85f76a2c67df5778"],"layout":"IPY_MODEL_61c38a689f4a41798dd01c6dca30845d"}},"857caa5a17df40acb1e9dd98bac010ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2f8844a962145f88e1746eeb8728fbe","placeholder":"​","style":"IPY_MODEL_c93114f7f0254acdbdbcf747f114852b","value":"tokenizer_config.json: 100%"}},"1f1a4cf4191e4231bba17fc1809d7c68":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f636ece970141319c673413c5552951","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_21c6097c7d714911acacc8ced424e09f","value":26}},"86e691771e61477d85f76a2c67df5778":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c50e01f510448a093bda60197aa466f","placeholder":"​","style":"IPY_MODEL_f324df6479854609be9b8dc43e6c859a","value":" 26.0/26.0 [00:00&lt;00:00, 2.40kB/s]"}},"61c38a689f4a41798dd01c6dca30845d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2f8844a962145f88e1746eeb8728fbe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c93114f7f0254acdbdbcf747f114852b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6f636ece970141319c673413c5552951":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21c6097c7d714911acacc8ced424e09f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8c50e01f510448a093bda60197aa466f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f324df6479854609be9b8dc43e6c859a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7f27fb125b364fc19a5334a7657d03a6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d14ab1e222054670a5890fcb2785afad","IPY_MODEL_d2f0a7441f87434e8f856f654096b4a9","IPY_MODEL_00e6b74a67a84b328de0d8f01bda3ea1"],"layout":"IPY_MODEL_66368d92b7e04f75a1454a8a4a28ef9b"}},"d14ab1e222054670a5890fcb2785afad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b5e15f880ae4f929179a50d5b31d66e","placeholder":"​","style":"IPY_MODEL_06ab6a46c3ee49449556cf6e3c8a5952","value":"vocab.json: 100%"}},"d2f0a7441f87434e8f856f654096b4a9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7b0fba99f5146ab8629d945b79754d8","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4b46ce40d44d438ca8497d7aa8a1a813","value":1042301}},"00e6b74a67a84b328de0d8f01bda3ea1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_24cdbe3b672248e0a5111a3a0651687d","placeholder":"​","style":"IPY_MODEL_28bd7488ad4c454cae2e25efd2f09e29","value":" 1.04M/1.04M [00:00&lt;00:00, 3.98MB/s]"}},"66368d92b7e04f75a1454a8a4a28ef9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b5e15f880ae4f929179a50d5b31d66e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06ab6a46c3ee49449556cf6e3c8a5952":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a7b0fba99f5146ab8629d945b79754d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b46ce40d44d438ca8497d7aa8a1a813":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"24cdbe3b672248e0a5111a3a0651687d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28bd7488ad4c454cae2e25efd2f09e29":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"27b6f8f256084fdfa381e682bf2dbba6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bae5c3a2c48d47d2a321083c5c65e201","IPY_MODEL_4129b16027054ccea710dabcfb72edde","IPY_MODEL_77aee132dc7240a4ae299ddb45236d26"],"layout":"IPY_MODEL_e8005cb75d8848738f7320321b9c9a5c"}},"bae5c3a2c48d47d2a321083c5c65e201":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c5eab81456b4f839b641aa4d84f2f1f","placeholder":"​","style":"IPY_MODEL_9c850f802f194c848a74119fb54b1965","value":"merges.txt: 100%"}},"4129b16027054ccea710dabcfb72edde":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_473e06f336c8487d9be25da18e44c54d","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_942602ab66144012b8c537cfb9ff4023","value":456318}},"77aee132dc7240a4ae299ddb45236d26":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_74a11d7001cb41fa9b4be221223159b5","placeholder":"​","style":"IPY_MODEL_5266c526ce394292823c611ed54c6d06","value":" 456k/456k [00:00&lt;00:00, 2.37MB/s]"}},"e8005cb75d8848738f7320321b9c9a5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c5eab81456b4f839b641aa4d84f2f1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c850f802f194c848a74119fb54b1965":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"473e06f336c8487d9be25da18e44c54d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"942602ab66144012b8c537cfb9ff4023":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"74a11d7001cb41fa9b4be221223159b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5266c526ce394292823c611ed54c6d06":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c688cc44841489492e90509373f1480":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_83ad451d1be946a4ae95fe205a91adea","IPY_MODEL_ac5765c247d34bbf97dd17c195634b73","IPY_MODEL_9f3a515be7a84ec18e3a76079a36f846"],"layout":"IPY_MODEL_937e47a911c0464497263758a313357a"}},"83ad451d1be946a4ae95fe205a91adea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_051c6f538ad747eeacfa84baa6d267c3","placeholder":"​","style":"IPY_MODEL_6e9a16a0a0ad4cbc81129b9a85275b44","value":"tokenizer.json: 100%"}},"ac5765c247d34bbf97dd17c195634b73":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2518a54189a4c809404f9910f7c7354","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1f6a4312015b49b3896ee5c853eae72b","value":1355256}},"9f3a515be7a84ec18e3a76079a36f846":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_38fdc22053c84a909273cf77629790d5","placeholder":"​","style":"IPY_MODEL_a494be3c95eb442184bffa44c45af3a3","value":" 1.36M/1.36M [00:00&lt;00:00, 4.20MB/s]"}},"937e47a911c0464497263758a313357a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"051c6f538ad747eeacfa84baa6d267c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e9a16a0a0ad4cbc81129b9a85275b44":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c2518a54189a4c809404f9910f7c7354":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f6a4312015b49b3896ee5c853eae72b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"38fdc22053c84a909273cf77629790d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a494be3c95eb442184bffa44c45af3a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["This notebook obtains the activations of GPT-2 using data from the Pile and trains an SAE on them. It then takes activation differences of GPT-2 to obtain a steering vector and decomposes this steering vector.\n","\n","The code is not efficient as it is for brainstorming purposes only to get a sense of how to code the more sophisticated experiments in this project.\n","\n","For testing purposes, we start with small datasets and SAEs. Next, we will test this on more data and larger models by finding more efficient ways to deal with out-of-memory issues"],"metadata":{"id":"JZRbtlLMLflI"}},{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"-WMqbetGrf4e"}},{"cell_type":"code","source":["%%capture\n","!pip install transformer_lens\n","!pip install datasets\n","!pip install zstandard"],"metadata":{"id":"hozpKjBenAph"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformer_lens import utils, HookedTransformer, ActivationCache\n","from dataclasses import dataclass\n","import torch as t\n","from torch import nn, Tensor\n","import torch.nn.functional as F\n","from jaxtyping import Float, Int\n","from typing import Optional, Callable, Union, List, Tuple\n","import einops\n","from datasets import load_dataset\n","\n","from tqdm import tqdm\n","from rich.table import Table\n","from rich import print as rprint"],"metadata":{"id":"llAiwjkqwpqp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Load Model"],"metadata":{"id":"2LxnTmFDpb2z"}},{"cell_type":"code","source":["device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")"],"metadata":{"id":"gaLmq0KDockd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = HookedTransformer.from_pretrained(\n","    \"gpt2-small\",\n","    # \"gpt2-xl\",\n","    center_unembed=True,\n","    center_writing_weights=True,\n","    fold_ln=True,\n","    refactor_factored_attn_matrices=True,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":386,"referenced_widgets":["6c714b7494e04e5a8e9e7e5aed59b06e","a0cb4b0c07ac49d3981776093fe13bec","048f6d583e3744e29fcefb74c9ab378a","6fb3e0ee47de49f3a9fb1377d002a1c9","97fddb273490463b8d40cc417d5e7e1b","35a7ec07c4864503818599a9addf9bec","bcc3df093de1421697e176687129f4e0","fc799cb00be1442b85653ad9b1d16857","4f79f235f43d4bbcbc9684fa756af4fd","b24bf531d096488db149fbacef718ac7","4e287ecbf8da438bad41ca6437e93d33","535727d826ab444b8d6671a0277f4d79","7dced8113e4f46c4adb8fde69d89c592","4e2793b8ed4a483c8fd2e00ffe3bf3f4","5fa5dde0cee141c4875306d3bf0b24a9","38691521dbb04803bedc0852872028cd","405e1fcff6204ec0898a7b5939f38032","9d9f34de290a4dd18df6b81852b29215","2eeb84f103fe40fdad4df74a985365c1","b45954f4bccd4ab6bdeeb15e53b7a935","28ee2f2b9b124c5b8dd669e84bf3af91","ecabd75433fc4523a7fbbd16c119c73f","b2160e5f02414b569d0d8efc8c0988c6","dd0bc67682714ef6b6f77bf161db5dc3","97463a8efbd840a4ba191834afa9b35b","dec4664d7f0b4e5ab517fe15c264d9fd","d164b209ff0a40e5b30d8a4ecdb2d972","541304aeef974bb8bd46f12726e0fd1f","902839c872e547bc8cac47124e8e76a9","3fd692d4fc9e4ec6ac648c175c7e1b5c","e47ef65fa84a459aaab8d4e8b62d158f","c228ffb5314449f094e39f4ff3f6610e","10fb34c61297433896b85e80041680b8","9568c3f353724f309e75eb8b4dbac062","857caa5a17df40acb1e9dd98bac010ae","1f1a4cf4191e4231bba17fc1809d7c68","86e691771e61477d85f76a2c67df5778","61c38a689f4a41798dd01c6dca30845d","e2f8844a962145f88e1746eeb8728fbe","c93114f7f0254acdbdbcf747f114852b","6f636ece970141319c673413c5552951","21c6097c7d714911acacc8ced424e09f","8c50e01f510448a093bda60197aa466f","f324df6479854609be9b8dc43e6c859a","7f27fb125b364fc19a5334a7657d03a6","d14ab1e222054670a5890fcb2785afad","d2f0a7441f87434e8f856f654096b4a9","00e6b74a67a84b328de0d8f01bda3ea1","66368d92b7e04f75a1454a8a4a28ef9b","6b5e15f880ae4f929179a50d5b31d66e","06ab6a46c3ee49449556cf6e3c8a5952","a7b0fba99f5146ab8629d945b79754d8","4b46ce40d44d438ca8497d7aa8a1a813","24cdbe3b672248e0a5111a3a0651687d","28bd7488ad4c454cae2e25efd2f09e29","27b6f8f256084fdfa381e682bf2dbba6","bae5c3a2c48d47d2a321083c5c65e201","4129b16027054ccea710dabcfb72edde","77aee132dc7240a4ae299ddb45236d26","e8005cb75d8848738f7320321b9c9a5c","0c5eab81456b4f839b641aa4d84f2f1f","9c850f802f194c848a74119fb54b1965","473e06f336c8487d9be25da18e44c54d","942602ab66144012b8c537cfb9ff4023","74a11d7001cb41fa9b4be221223159b5","5266c526ce394292823c611ed54c6d06","7c688cc44841489492e90509373f1480","83ad451d1be946a4ae95fe205a91adea","ac5765c247d34bbf97dd17c195634b73","9f3a515be7a84ec18e3a76079a36f846","937e47a911c0464497263758a313357a","051c6f538ad747eeacfa84baa6d267c3","6e9a16a0a0ad4cbc81129b9a85275b44","c2518a54189a4c809404f9910f7c7354","1f6a4312015b49b3896ee5c853eae72b","38fdc22053c84a909273cf77629790d5","a494be3c95eb442184bffa44c45af3a3"]},"id":"zjFa1PqDrOto","executionInfo":{"status":"ok","timestamp":1714521883880,"user_tz":240,"elapsed":9067,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3ab9cd34-57a2-4dd9-92dd-2e2ca824f598"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c714b7494e04e5a8e9e7e5aed59b06e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"535727d826ab444b8d6671a0277f4d79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2160e5f02414b569d0d8efc8c0988c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9568c3f353724f309e75eb8b4dbac062"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f27fb125b364fc19a5334a7657d03a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27b6f8f256084fdfa381e682bf2dbba6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c688cc44841489492e90509373f1480"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Loaded pretrained model gpt2-small into HookedTransformer\n"]}]},{"cell_type":"markdown","metadata":{"id":"2MD88v4Zvw-r"},"source":["# Autoencoder Training"]},{"cell_type":"markdown","source":["## Class Setup"],"metadata":{"id":"1jCAYFKmz92O"}},{"cell_type":"code","source":["@dataclass\n","class AutoEncoderConfig:\n","    n_instances: int\n","    n_input_ae: int\n","    n_hidden_ae: int\n","    l1_coeff: float = 0.5\n","    tied_weights: bool = False\n","    weight_normalize_eps: float = 1e-8"],"metadata":{"id":"WjziwoIb4Tvb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def linear_lr(step, steps):\n","    return (1 - (step / steps))\n","\n","def constant_lr(*_):\n","    return 1.0\n","\n","def cosine_decay_lr(step, steps):\n","    return np.cos(0.5 * np.pi * step / (steps - 1))"],"metadata":{"id":"iRNZvnQQ6wwS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AutoEncoder(nn.Module):\n","    W_enc: Float[Tensor, \"n_instances n_input_ae n_hidden_ae\"]\n","    W_dec: Float[Tensor, \"n_instances n_hidden_ae n_input_ae\"]\n","    b_enc: Float[Tensor, \"n_instances n_hidden_ae\"]\n","    b_dec: Float[Tensor, \"n_instances n_input_ae\"]\n","\n","    def __init__(self, cfg: AutoEncoderConfig, h):\n","        super().__init__()\n","        self.cfg = cfg\n","\n","        self.model_h = h\n","\n","        self.W_enc = nn.Parameter(nn.init.xavier_normal_(t.empty((cfg.n_instances, cfg.n_input_ae, cfg.n_hidden_ae))))\n","        if not(cfg.tied_weights):\n","            self.W_dec = nn.Parameter(nn.init.xavier_normal_(t.empty((cfg.n_instances, cfg.n_hidden_ae, cfg.n_input_ae))))\n","\n","        self.b_enc = nn.Parameter(t.zeros(cfg.n_instances, cfg.n_hidden_ae))\n","        self.b_dec = nn.Parameter(t.zeros(cfg.n_instances, cfg.n_input_ae))\n","\n","        self.to(device)\n","\n","    def normalize_and_return_W_dec(self) -> Float[Tensor, \"n_instances n_hidden_ae n_input_ae\"]:\n","        '''\n","        If self.cfg.tied_weights = True, we return the normalized & transposed encoder weights.\n","        If self.cfg.tied_weights = False, we normalize the decoder weights in-place, and return them.\n","\n","        Normalization should be over the `n_input_ae` dimension, i.e. each feature should have a noramlized decoder weight.\n","        '''\n","        if self.cfg.tied_weights:\n","            return self.W_enc.transpose(-1, -2) / (self.W_enc.transpose(-1, -2).norm(dim=1, keepdim=True) + self.cfg.weight_normalize_eps)\n","        else:\n","            self.W_dec.data = self.W_dec.data / (self.W_dec.data.norm(dim=2, keepdim=True) + self.cfg.weight_normalize_eps)\n","            return self.W_dec\n","\n","    def forward(self, h: Float[Tensor, \"batch_size n_instances n_input_ae\"]):\n","\n","        # Compute activations\n","        h_cent = h - self.b_dec\n","        acts = einops.einsum(\n","            h_cent, self.W_enc,\n","            \"batch_size n_instances n_input_ae, n_instances n_input_ae n_hidden_ae -> batch_size n_instances n_hidden_ae\"\n","        )\n","        acts = F.relu(acts + self.b_enc)\n","\n","        # Compute reconstructed input\n","        h_reconstructed = einops.einsum(\n","            acts, self.normalize_and_return_W_dec(),\n","            \"batch_size n_instances n_hidden_ae, n_instances n_hidden_ae n_input_ae -> batch_size n_instances n_input_ae\"\n","        ) + self.b_dec\n","\n","        # Compute loss, return values\n","        l2_loss = (h_reconstructed - h).pow(2).mean(-1) # shape [batch_size n_instances]\n","        l1_loss = acts.abs().sum(-1) # shape [batch_size n_instances]\n","        loss = (self.cfg.l1_coeff * l1_loss + l2_loss).mean(0).sum() # scalar\n","\n","        return l1_loss, l2_loss, loss, acts, h_reconstructed\n","\n","    @t.no_grad()\n","    def resample_neurons(\n","        self,\n","        h: Float[Tensor, \"batch_size n_instances n_input_ae\"],\n","        frac_active_in_window: Float[Tensor, \"window n_instances n_hidden_ae\"],\n","        neuron_resample_scale: float,\n","    ) -> Tuple[List[List[str]], str]:\n","        '''\n","        Resamples neurons that have been dead for `dead_neuron_window` steps, according to `frac_active`.\n","        '''\n","        pass # See below for a solution to this function\n","\n","    def optimize(\n","        self,\n","        # model: Model,\n","        batch_size: int = 1024,\n","        steps: int = 10_000,\n","        log_freq: int = 100,\n","        lr: float = 1e-3,\n","        lr_scale: Callable[[int, int], float] = constant_lr,\n","        neuron_resample_window: Optional[int] = None,\n","        dead_neuron_window: Optional[int] = None,\n","        neuron_resample_scale: float = 0.2,\n","    ):\n","        '''\n","        Optimizes the autoencoder using the given hyperparameters.\n","\n","        This function should take a trained model as input.\n","        '''\n","        if neuron_resample_window is not None:\n","            assert (dead_neuron_window is not None) and (dead_neuron_window < neuron_resample_window)\n","\n","        optimizer = t.optim.Adam(list(self.parameters()), lr=lr)\n","        frac_active_list = []\n","        progress_bar = tqdm(range(steps))\n","\n","        # Create lists to store data we'll eventually be plotting\n","        data_log = {\"W_enc\": [], \"W_dec\": [], \"colors\": [], \"titles\": [], \"frac_active\": []}\n","        colors = None\n","        title = \"no resampling yet\"\n","\n","        for step in progress_bar:\n","\n","            # Resample dead neurons\n","            # if (neuron_resample_window is not None) and ((step + 1) % neuron_resample_window == 0):\n","            #     # Get the fraction of neurons active in the previous window\n","            #     frac_active_in_window = t.stack(frac_active_list[-neuron_resample_window:], dim=0)\n","            #     # Compute batch of hidden activations which we'll use in resampling\n","            #     batch = model.generate_batch(batch_size)\n","            #     h = einops.einsum(\n","            #         batch, model.W,\n","            #         \"batch_size instances features, instances hidden features -> batch_size instances hidden\"\n","            #     )\n","            #     # Resample\n","            #     colors, title = self.resample_neurons(h, frac_active_in_window, neuron_resample_scale)\n","\n","            # Update learning rate\n","            step_lr = lr * lr_scale(step, steps)\n","            for group in optimizer.param_groups:\n","                group['lr'] = step_lr\n","\n","            ### MODIFY THIS to use h,  activations from transformerlens ###\n","            # Get a batch of hidden activations from the model\n","            # with t.inference_mode():\n","                # features = model.generate_batch(batch_size)\n","                # h = einops.einsum(\n","                #     features, model.W,\n","                #     \"... instances features, instances hidden features -> ... instances hidden\"\n","                # )\n","\n","            h = self.model_h\n","\n","            # Optimize\n","            l1_loss, l2_loss, loss, acts, _ = self.forward(h)\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","            # Calculate the mean sparsities over batch dim for each (instance, feature)\n","            frac_active = (acts.abs() > 1e-8).float().mean(0)\n","            frac_active_list.append(frac_active)\n","\n","            # Display progress bar, and append new values for plotting\n","            if step % log_freq == 0 or (step + 1 == steps):\n","                progress_bar.set_postfix(l1_loss=self.cfg.l1_coeff * l1_loss.mean(0).sum().item(), l2_loss=l2_loss.mean(0).sum().item(), lr=step_lr)\n","                data_log[\"W_enc\"].append(self.W_enc.detach().cpu().clone())\n","                data_log[\"W_dec\"].append(self.normalize_and_return_W_dec().detach().cpu().clone())\n","                data_log[\"colors\"].append(colors)\n","                data_log[\"titles\"].append(f\"Step {step}/{steps}: {title}\")\n","                data_log[\"frac_active\"].append(frac_active.detach().cpu().clone())\n","\n","        return data_log"],"metadata":{"id":"4CNZX3tR3j8h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CF4mUxhMvw-s"},"source":["Return a dictionary `data_log` containing data which is useful for visualizing the training process"]},{"cell_type":"markdown","source":["## Load training data"],"metadata":{"id":"TioC1OirumVa"}},{"cell_type":"markdown","source":["Future code will do this more efficient (not passing in batch all at once to get h)"],"metadata":{"id":"DvsIRn9p0ujR"}},{"cell_type":"code","source":["dataset = load_dataset(\"stas/openwebtext-10k\", split='train', streaming=True)\n","# dataset = load_dataset(\"EleutherAI/pile\", split='train', streaming=True)"],"metadata":{"id":"uSxh2sb1uoU4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total_len = 0\n","i = 0\n","for sample in dataset:\n","    total_len += len(sample[\"text\"])\n","    i += 1\n","    # if i == 1000:\n","    #     break\n","print(total_len / i)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sgROQC9rPaQK","executionInfo":{"status":"ok","timestamp":1714521887792,"user_tz":240,"elapsed":2117,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"afebdc8b-9f79-4e62-acaf-6ab4e0be7f47"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4918.0299\n"]}]},{"cell_type":"code","source":["strMaxLen = 100 # 100\n","batchLen = 100 # 1000\n","batch_input = []\n","for sample in dataset:\n","    input_sample = sample[\"text\"][:strMaxLen]\n","    batch_input.append(input_sample)\n","    if len(batch_input) == batchLen:\n","        break\n","print(len(batch_input))\n","# print(input_sample)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ANNUB6U01Dj1","executionInfo":{"status":"ok","timestamp":1714523530696,"user_tz":240,"elapsed":553,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"cadd8cf4-578e-49b7-802c-6f7d7504ca48"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["100\n"]}]},{"cell_type":"markdown","source":["## Get activations to train SAE"],"metadata":{"id":"IhiRijN-5Yfc"}},{"cell_type":"code","source":["layer_name = 'blocks.5.mlp.hook_post'"],"metadata":{"id":"pzX1AFUhde2_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# https://neelnanda-io.github.io/TransformerLens/generated/code/transformer_lens.HookedTransformer.html\n","\n","tokens = model.to_tokens(batch_input)\n","tokens.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ChAYwHG7_Vv_","executionInfo":{"status":"ok","timestamp":1714521888297,"user_tz":240,"elapsed":75,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9d6d8b13-319c-4836-cc9d-f7b7adf6ed08"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([100, 34])"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["Seq Len is number of tokens, not string max len"],"metadata":{"id":"sSy0z7xNASfe"}},{"cell_type":"code","source":["# h_store = t.zeros(model_cache['blocks.5.mlp.hook_post'].shape, device=model.cfg.device)\n","seqLen = tokens.shape[1]\n","h_store = t.zeros((len(batch_input), seqLen, model.cfg.d_mlp), device=model.cfg.device)"],"metadata":{"id":"Ct5KiRoU9Buc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["h_store.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yGm22v0N9KF2","executionInfo":{"status":"ok","timestamp":1714521888297,"user_tz":240,"elapsed":66,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"244d75fc-d80c-42a8-eb5b-584c461f0289"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([100, 34, 3072])"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["Use hook fn to avoid storing all activations"],"metadata":{"id":"HB3UOrNl6kps"}},{"cell_type":"code","source":["def store_h_hook(\n","    pattern: Float[Tensor, \"batch seqlen dmlp\"],\n","    # hook: HookPoint,\n","    hook\n","):\n","    # Store the result.\n","    # h_store = pattern  # this won't work b/c replaces entire thing, so won't be stored\n","    # h_store.append(1) # if h_store = [], this will work\n","    h_store[:] = pattern  # this works b/c changes values, not replaces entire thing"],"metadata":{"id":"cGfVKqfV7Jd6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.run_with_hooks(\n","    tokens,\n","    return_type = None,\n","    fwd_hooks=[\n","        (layer_name, store_h_hook),\n","    ]\n",")"],"metadata":{"id":"d697f26W6U9U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# h_store  # check actvs are stored"],"metadata":{"id":"cmJDHHQBC6a2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Train SAE"],"metadata":{"id":"sICthFXwz8oM"}},{"cell_type":"markdown","source":["### one sample"],"metadata":{"id":"oD7tg7OUIoPh"}},{"cell_type":"code","source":["# input_text = \"I think you're\"\n","# logits, model_cache = model.run_with_cache(input_text, remove_batch_dim=True)\n","# h = model_cache['blocks.5.mlp.hook_post']  # (batch size, seqLen, n_hidden)\n","\n","# # convert to h dim: \"batch_size * seq_len n_instances n_input_ae\"\n","# print(h.shape)\n","# h = h.unsqueeze(1)\n","# print(h.shape)"],"metadata":{"id":"Iacwjw3Dyfvk"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3b_Vf7f7vw-s"},"outputs":[],"source":["# ae_cfg = AutoEncoderConfig(\n","#     n_instances = 1, # 8\n","#     n_input_ae = h.shape[-1],  # model's n_hidden\n","#     n_hidden_ae = 2 * h.shape[-1],  # require n_hidden_ae >= n_features\n","#     l1_coeff = 0.5,\n","# )\n","\n","# autoencoder = AutoEncoder(ae_cfg, h)\n","\n","# data_log = autoencoder.optimize(\n","#     steps = 1000,\n","#     log_freq = 200,\n","# )"]},{"cell_type":"markdown","source":["### on more samples and instances"],"metadata":{"id":"7wRx4SMDHVl4"}},{"cell_type":"code","source":["# # pass multiple inputs\n","# batch_input = [\"deception\", \"anger\"]\n","# logits, model_cache_2 = model.run_with_cache(batch_input, remove_batch_dim=False)\n","# h = model_cache_2['blocks.5.mlp.hook_post']\n","# h.shape  # (batch size, seqLen, n_hidden)\n","\n","# # convert to h dim: \"batch_size * seq_len, n_instances, n_input_ae\"\n","# print(h.shape)\n","# h = h.reshape(6, 3072)\n","# h = h.unsqueeze(1)\n","# print(h.shape)"],"metadata":{"id":"bWjis20HH1qV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ae_cfg = AutoEncoderConfig(\n","#     n_instances = 2, # 8\n","#     n_input_ae = h.shape[-1],  # model's n_hidden\n","#     n_hidden_ae = 2 * h.shape[-1],  # require n_hidden_ae >= n_features. can use R * n_input_ae\n","#     l1_coeff = 0.5,\n","# )\n","\n","# autoencoder = AutoEncoder(ae_cfg, h)\n","\n","# data_log = autoencoder.optimize(\n","#     steps = 1000, # 10_000\n","#     log_freq = 200,\n","# )"],"metadata":{"id":"SbHPZ44xHWz2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### on larger dataset"],"metadata":{"id":"9TqjxZYsFviC"}},{"cell_type":"code","source":["# convert to h dim: \"batch_size * seq_len, n_instances, n_input_ae\"\n","print(h_store.shape)\n","h_store = h_store.reshape(h_store.shape[0] * h_store.shape[1], 3072)\n","h_store = h_store.unsqueeze(1)\n","print(h_store.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714521888719,"user_tz":240,"elapsed":46,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"255c01ed-4918-4403-87cc-2f7a887bc4b3","id":"MoSj7woIF1AP"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([100, 34, 3072])\n","torch.Size([3400, 1, 3072])\n"]}]},{"cell_type":"code","source":["# h_store has \"grad_fn=<UnsqueezeBackward0>)\", so get rid of it\n","h = h_store.detach()  # Detaches values from the computation graph\n","# h"],"metadata":{"id":"IH8qFcpHKjgJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ae_cfg = AutoEncoderConfig(\n","    n_instances = 2, # 8\n","    n_input_ae = h.shape[-1],  # model's n_hidden\n","    n_hidden_ae = 2 * h.shape[-1],  # require n_hidden_ae >= n_features. can use R * n_input_ae\n","    l1_coeff = 0.5,\n",")\n","\n","autoencoder = AutoEncoder(ae_cfg, h)\n","\n","data_log = autoencoder.optimize(\n","    steps = 1000, # 10_000\n","    log_freq = 200,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714522087153,"user_tz":240,"elapsed":198478,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"7696ffae-fff0-44b0-f358-904624bee9e1","id":"V-LlNABTF1AQ"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1000/1000 [03:17<00:00,  5.07it/s, l1_loss=3.96e-7, l2_loss=0.0635, lr=0.001]\n"]}]},{"cell_type":"markdown","source":["## Reconstruction loss"],"metadata":{"id":"vvODjvdrAxXE"}},{"cell_type":"code","source":["# batch_input = [\"deception\", \"anger\"]\n","all_tokens = model.to_tokens(batch_input, prepend_bos=True)\n","all_tokens = all_tokens.to(device)\n","all_tokens.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Op4kCO1fThos","executionInfo":{"status":"ok","timestamp":1714522087154,"user_tz":240,"elapsed":339,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"453c3d83-d3d2-4ffb-c450-98fcd37fb288"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([100, 34])"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["@t.no_grad()\n","def get_reconstruction_loss(\n","    tokens: Int[Tensor, \"batch seq\"],\n","    model: HookedTransformer,\n","    autoencoder: AutoEncoder,\n","    layer_name: str = 'blocks.5.mlp.hook_post',\n",") -> Tuple[float, float]:\n","    '''\n","    Returns the reconstruction loss of each autoencoder instance on the given batch of tokens (i.e.\n","    the L2 loss between the activations and the autoencoder's reconstructions, averaged over all tokens).\n","    '''\n","    batch_size, seq_len = tokens.shape\n","\n","    # layer_name = \"blocks.5.mlp.hook_post\"\n","\n","    logits, cache = model.run_with_cache(tokens, names_filter = [layer_name])\n","    post = cache[layer_name]\n","    assert post.shape == (batch_size, seq_len, model.cfg.d_mlp)\n","\n","    post_reshaped = einops.repeat(post, \"batch seq d_mlp -> (batch seq) instances d_mlp\", instances=2)\n","    # assert post_reshaped.shape == (batch_size * seq_len, 2, model.cfg.d_mlp)\n","\n","    _, l2_loss, _, _, post_reconstructed = autoencoder.forward(post_reshaped)\n","    # assert l2_loss.shape == (batch_size * seq_len, 2) # shape is [datapoints n_instances=2]\n","    # assert post_reconstructed.shape == (batch_size * seq_len, 2, model.cfg.d_mlp) # shape is [datapoints n_instances=2 d_mlp]\n","\n","    # Print out the avg L2 norm of activations\n","    print(\"Avg L2 norm of acts: \", einops.reduce(post_reshaped.pow(2), \"batch inst d_mlp -> inst\", \"mean\").tolist())\n","    # Print out the cosine similarity between original neuron activations & reconstructions (averaged over neurons)\n","    print(\"Avg cos sim of neuron reconstructions: \", t.cosine_similarity(post_reconstructed, post_reshaped, dim=0).mean(-1).tolist())\n","\n","    return l2_loss.mean(0).tolist()\n","\n","\n","reconstruction_loss = get_reconstruction_loss(all_tokens[:10], model, autoencoder, layer_name)\n","print(reconstruction_loss)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AMg-l9vP0TB-","executionInfo":{"status":"ok","timestamp":1714522481716,"user_tz":240,"elapsed":262,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e7922be1-cb1b-4ec8-ba70-80a3fcdb7e68"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Avg L2 norm of acts:  [0.03262889012694359, 0.03262889012694359]\n","Avg cos sim of neuron reconstructions:  [0.06458871066570282, 0.08282989263534546]\n","[0.031933583319187164, 0.03190237656235695]\n"]}]},{"cell_type":"markdown","metadata":{"id":"BdgIFHMcuJu5"},"source":["# Get top samples for a feature"]},{"cell_type":"code","source":["# batch_input = [\"deception\", \"anger\"]\n","all_tokens = model.to_tokens(batch_input, prepend_bos=True)\n","all_tokens = all_tokens.to(device)\n","all_tokens.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RkRGm-yqOKDe","executionInfo":{"status":"ok","timestamp":1714522087314,"user_tz":240,"elapsed":132,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f7e61822-5d66-4d6a-b9a4-7ec75ddde05f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([100, 34])"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0l2gB4IWSqjp","colab":{"base_uri":"https://localhost:8080/","height":177},"executionInfo":{"status":"ok","timestamp":1714522160559,"user_tz":240,"elapsed":510,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c998e76b-af98-44f3-8e01-4879414893f2"},"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[3m            Tokens which most activate feature 0            \u001b[0m\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mSequence                                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mActivation\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n","│ at the time of this\u001b[1;4;38;5;208m writing\u001b[0m in early June)  │ -0.05      │\n","│  a dozen — \"Americans\u001b[1;4;38;5;208m for\u001b[0m Real Good Coffee\" │ -0.10      │\n","│ It's not clear how\u001b[1;4;38;5;208m or\u001b[0m why two men attacked  │ -0.11      │\n","│  the sauce in their carry\u001b[1;4;38;5;208m-\u001b[0mon luggage, e     │ -0.14      │\n","│ �t really give a\u001b[1;4;38;5;208m shit\u001b[0m that most of the      │ -0.14      │\n","└─────────────────────────────────────────────┴────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">            Tokens which most activate feature 0            </span>\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Sequence                                    </span>┃<span style=\"font-weight: bold\"> Activation </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n","│ at the time of this<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> writing</span> in early June)  │ -0.05      │\n","│  a dozen — \"Americans<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> for</span> Real Good Coffee\" │ -0.10      │\n","│ It's not clear how<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> or</span> why two men attacked  │ -0.11      │\n","│  the sauce in their carry<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">-</span>on luggage, e     │ -0.14      │\n","│ �t really give a<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> shit</span> that most of the      │ -0.14      │\n","└─────────────────────────────────────────────┴────────────┘\n","</pre>\n"]},"metadata":{}}],"source":["@t.inference_mode()\n","def highest_activating_tokens(\n","    tokens: Int[Tensor, \"batch seq\"],\n","    model: HookedTransformer,\n","    autoencoder: AutoEncoder,\n","    feature_idx: int,\n","    autoencoder_B: bool = False,\n","    k: int = 10,\n","    layer_name: str = 'blocks.5.mlp.hook_post',\n",") -> Tuple[Int[Tensor, \"k 2\"], Float[Tensor, \"k\"]]:\n","    '''\n","    Returns the indices & values for the highest-activating tokens in the given batch of data.\n","    '''\n","    batch_size, seq_len = tokens.shape\n","    instance_idx = 1 if autoencoder_B else 0\n","\n","    # Get the LLM model's post activations from the clean run\n","    cache = model.run_with_cache(tokens, names_filter=[layer_name])[1]\n","    post = cache[layer_name]\n","    post_reshaped = einops.rearrange(post, \"batch seq d_mlp -> (batch seq) d_mlp\")\n","\n","    # Compute SAE activations (not from a fwd pass, but explicitly, by taking only the feature we want)\n","    # This code is copied from the first part of the 'forward' method of the AutoEncoder class\n","    h_cent = post_reshaped - autoencoder.b_dec[instance_idx]\n","    acts = einops.einsum(\n","        h_cent, autoencoder.W_enc[instance_idx, :, feature_idx],\n","        \"batch_size n_input_ae, n_input_ae -> batch_size\"\n","    )\n","\n","    # Get the top k SAE largest activations for that SAE feature\n","    top_acts_values, top_acts_indices = acts.topk(k)\n","\n","    # Convert the indices into (batch, seq) indices\n","    top_acts_batch = top_acts_indices // seq_len\n","    top_acts_seq = top_acts_indices % seq_len\n","\n","    return t.stack([top_acts_batch, top_acts_seq], dim=-1), top_acts_values\n","\n","\n","def display_top_sequences(top_acts_indices, top_acts_values, tokens):\n","    table = Table(\"Sequence\", \"Activation\", title=\"Tokens which most activate feature \" + str(feature_idx))\n","    # indices is that highest token in (sampNum, pos) pair\n","    for (batch_idx, seq_idx), value in zip(top_acts_indices, top_acts_values):\n","        # Get the sequence as a string (with some padding on either side of our sequence)\n","        seq = \"\"\n","        # around the token's pos as center, loop thru window of 10, or bounds of sequence\n","        for i in range(max(seq_idx-5, 0), min(seq_idx+5, all_tokens.shape[1])):\n","            # the curr token in the loop thru the window of the seq\n","            new_str_token = model.to_single_str_token(tokens[batch_idx, i].item()).replace(\"\\n\", \"\\\\n\")\n","            # Highlight the token with the high activation\n","            if i == seq_idx: new_str_token = f\"[b u dark_orange]{new_str_token}[/]\"\n","            # add all tokens in len-10 window to the row to display\n","            seq += new_str_token\n","        # Print the sequence, and the activation value\n","        table.add_row(seq, f'{value:.2f}')\n","    rprint(table)\n","\n","tokens = all_tokens[:200]\n","feature_idx = 0\n","k = 5 # all_tokens.shape[0]\n","top_acts_indices, top_acts_values = highest_activating_tokens(tokens, model, autoencoder, feature_idx, autoencoder_B=False, k=k, layer_name=layer_name)\n","display_top_sequences(top_acts_indices, top_acts_values, tokens)"]},{"cell_type":"code","source":["autoencoder.W_enc.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MSBquLojO-WL","executionInfo":{"status":"ok","timestamp":1714522164864,"user_tz":240,"elapsed":195,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f532dbb5-d36a-4c96-f784-030a0175d7de"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 3072, 6144])"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["# for feature_idx in range(model.cfg.d_mlp*2):\n","for feature_idx in range(3):\n","    top_acts_indices, top_acts_values = highest_activating_tokens(tokens, model, autoencoder, feature_idx, autoencoder_B=False, k=k, layer_name=layer_name)\n","    display_top_sequences(top_acts_indices, top_acts_values, tokens)\n","\n","for feature_idx in range(model.cfg.d_mlp*2 -3, model.cfg.d_mlp*2):\n","    top_acts_indices, top_acts_values = highest_activating_tokens(tokens, model, autoencoder, feature_idx, autoencoder_B=False, k=k, layer_name=layer_name)\n","    display_top_sequences(top_acts_indices, top_acts_values, tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":977},"id":"DT7tvL3qGpJL","executionInfo":{"status":"ok","timestamp":1714522168835,"user_tz":240,"elapsed":1299,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"acbcda86-0af9-43fe-9283-2f1b440f6997"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[3m            Tokens which most activate feature 0            \u001b[0m\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mSequence                                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mActivation\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n","│ at the time of this\u001b[1;4;38;5;208m writing\u001b[0m in early June)  │ -0.05      │\n","│  a dozen — \"Americans\u001b[1;4;38;5;208m for\u001b[0m Real Good Coffee\" │ -0.10      │\n","│ It's not clear how\u001b[1;4;38;5;208m or\u001b[0m why two men attacked  │ -0.11      │\n","│  the sauce in their carry\u001b[1;4;38;5;208m-\u001b[0mon luggage, e     │ -0.14      │\n","│ �t really give a\u001b[1;4;38;5;208m shit\u001b[0m that most of the      │ -0.14      │\n","└─────────────────────────────────────────────┴────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">            Tokens which most activate feature 0            </span>\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Sequence                                    </span>┃<span style=\"font-weight: bold\"> Activation </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n","│ at the time of this<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> writing</span> in early June)  │ -0.05      │\n","│  a dozen — \"Americans<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> for</span> Real Good Coffee\" │ -0.10      │\n","│ It's not clear how<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> or</span> why two men attacked  │ -0.11      │\n","│  the sauce in their carry<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">-</span>on luggage, e     │ -0.14      │\n","│ �t really give a<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> shit</span> that most of the      │ -0.14      │\n","└─────────────────────────────────────────────┴────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[3m                             Tokens which most activate feature 1                             \u001b[0m\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mSequence                                                                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mActivation\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n","│ It's not clear how\u001b[1;4;38;5;208m or\u001b[0m why two men attacked                                    │ -0.10      │\n","│  of the Johns Hopkins Bl\u001b[1;4;38;5;208mo\u001b[0m<|endoftext|><|endoftext|><|endoftext|><|endoftext|> │ -0.15      │\n","│  a dozen — \"Americans\u001b[1;4;38;5;208m for\u001b[0m Real Good Coffee\"                                   │ -0.16      │\n","│  The world's best make\u001b[1;4;38;5;208m-\u001b[0mup artists reveal their                                │ -0.17      │\n","│  the sauce in their carry\u001b[1;4;38;5;208m-\u001b[0mon luggage, e                                       │ -0.21      │\n","└───────────────────────────────────────────────────────────────────────────────┴────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                             Tokens which most activate feature 1                             </span>\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Sequence                                                                      </span>┃<span style=\"font-weight: bold\"> Activation </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n","│ It's not clear how<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> or</span> why two men attacked                                    │ -0.10      │\n","│  of the Johns Hopkins Bl<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">o</span>&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt; │ -0.15      │\n","│  a dozen — \"Americans<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> for</span> Real Good Coffee\"                                   │ -0.16      │\n","│  The world's best make<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">-</span>up artists reveal their                                │ -0.17      │\n","│  the sauce in their carry<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">-</span>on luggage, e                                       │ -0.21      │\n","└───────────────────────────────────────────────────────────────────────────────┴────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[3m                   Tokens which most activate feature 2                    \u001b[0m\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mSequence                                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mActivation\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n","│ It's not clear how\u001b[1;4;38;5;208m or\u001b[0m why two men attacked                 │ -0.12      │\n","│  a dozen — \"Americans\u001b[1;4;38;5;208m for\u001b[0m Real Good Coffee\"                │ -0.18      │\n","│ at the time of this\u001b[1;4;38;5;208m writing\u001b[0m in early June)                 │ -0.19      │\n","│ �t really give a\u001b[1;4;38;5;208m shit\u001b[0m that most of the                     │ -0.22      │\n","│ <|endoftext|>SHARE THIS ARTICLE Share\u001b[1;4;38;5;208m Tweet\u001b[0m Post Email\\n\\n │ -0.22      │\n","└────────────────────────────────────────────────────────────┴────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                   Tokens which most activate feature 2                    </span>\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Sequence                                                   </span>┃<span style=\"font-weight: bold\"> Activation </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n","│ It's not clear how<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> or</span> why two men attacked                 │ -0.12      │\n","│  a dozen — \"Americans<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> for</span> Real Good Coffee\"                │ -0.18      │\n","│ at the time of this<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> writing</span> in early June)                 │ -0.19      │\n","│ �t really give a<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> shit</span> that most of the                     │ -0.22      │\n","│ &lt;|endoftext|&gt;SHARE THIS ARTICLE Share<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> Tweet</span> Post Email\\n\\n │ -0.22      │\n","└────────────────────────────────────────────────────────────┴────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[3m        Tokens which most activate feature 6141         \u001b[0m\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mSequence                               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mActivation\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n","│ \u001b[1;4;38;5;208m<|endoftext|>\u001b[0mFor today��                │ -0.04      │\n","│ \u001b[1;4;38;5;208m<|endoftext|>\u001b[0mA magazine supplement with │ -0.04      │\n","│ \u001b[1;4;38;5;208m<|endoftext|>\u001b[0mAnarchists in              │ -0.04      │\n","│ \u001b[1;4;38;5;208m<|endoftext|>\u001b[0mNew drunk-driving          │ -0.04      │\n","│ \u001b[1;4;38;5;208m<|endoftext|>\u001b[0mThe 45-year                │ -0.04      │\n","└─────────────────────────────────────────┴────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">        Tokens which most activate feature 6141         </span>\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Sequence                                </span>┃<span style=\"font-weight: bold\"> Activation </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n","│ <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">&lt;|endoftext|&gt;</span>For today��                │ -0.04      │\n","│ <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">&lt;|endoftext|&gt;</span>A magazine supplement with │ -0.04      │\n","│ <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">&lt;|endoftext|&gt;</span>Anarchists in              │ -0.04      │\n","│ <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">&lt;|endoftext|&gt;</span>New drunk-driving          │ -0.04      │\n","│ <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">&lt;|endoftext|&gt;</span>The 45-year                │ -0.04      │\n","└─────────────────────────────────────────┴────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[3m          Tokens which most activate feature 6142           \u001b[0m\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mSequence                                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mActivation\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n","│  a dozen — \"Americans\u001b[1;4;38;5;208m for\u001b[0m Real Good Coffee\" │ -0.05      │\n","│ It's not clear how\u001b[1;4;38;5;208m or\u001b[0m why two men attacked  │ -0.08      │\n","│ at the time of this\u001b[1;4;38;5;208m writing\u001b[0m in early June)  │ -0.11      │\n","│  the sauce in their carry\u001b[1;4;38;5;208m-\u001b[0mon luggage, e     │ -0.12      │\n","│ �t really give a\u001b[1;4;38;5;208m shit\u001b[0m that most of the      │ -0.13      │\n","└─────────────────────────────────────────────┴────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">          Tokens which most activate feature 6142           </span>\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Sequence                                    </span>┃<span style=\"font-weight: bold\"> Activation </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n","│  a dozen — \"Americans<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> for</span> Real Good Coffee\" │ -0.05      │\n","│ It's not clear how<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> or</span> why two men attacked  │ -0.08      │\n","│ at the time of this<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> writing</span> in early June)  │ -0.11      │\n","│  the sauce in their carry<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">-</span>on luggage, e     │ -0.12      │\n","│ �t really give a<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> shit</span> that most of the      │ -0.13      │\n","└─────────────────────────────────────────────┴────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[3m          Tokens which most activate feature 6143           \u001b[0m\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mSequence                                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mActivation\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n","│ at the time of this\u001b[1;4;38;5;208m writing\u001b[0m in early June)  │ -0.04      │\n","│  a dozen — \"Americans\u001b[1;4;38;5;208m for\u001b[0m Real Good Coffee\" │ -0.09      │\n","│ It's not clear how\u001b[1;4;38;5;208m or\u001b[0m why two men attacked  │ -0.10      │\n","│  the sauce in their carry\u001b[1;4;38;5;208m-\u001b[0mon luggage, e     │ -0.13      │\n","│ �t really give a\u001b[1;4;38;5;208m shit\u001b[0m that most of the      │ -0.15      │\n","└─────────────────────────────────────────────┴────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">          Tokens which most activate feature 6143           </span>\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Sequence                                    </span>┃<span style=\"font-weight: bold\"> Activation </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n","│ at the time of this<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> writing</span> in early June)  │ -0.04      │\n","│  a dozen — \"Americans<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> for</span> Real Good Coffee\" │ -0.09      │\n","│ It's not clear how<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> or</span> why two men attacked  │ -0.10      │\n","│  the sauce in their carry<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">-</span>on luggage, e     │ -0.13      │\n","│ �t really give a<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> shit</span> that most of the      │ -0.15      │\n","└─────────────────────────────────────────────┴────────────┘\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":["# Find features that actv highest for sample X"],"metadata":{"id":"MIa9W966RDGv"}},{"cell_type":"code","source":[],"metadata":{"id":"YuXLRF2gXAdR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Test on features from class X"],"metadata":{"id":"L9WXzBk2RHgn"}},{"cell_type":"markdown","source":["# Steering Vector decomposition"],"metadata":{"id":"w2Wt05M-lofM"}},{"cell_type":"code","source":["# do this b/c anger is one token, calm is 2, so this pads anger with 50256\n","batch_input = [\"anger\", \"calm\"]\n","tokens = model.to_tokens(batch_input)\n","tokens"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XuF5CoJOVVir","executionInfo":{"status":"ok","timestamp":1714523147007,"user_tz":240,"elapsed":174,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0d856f00-a5e1-4d43-e6e5-cce1fb0e8cfd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[50256,  2564, 50256],\n","        [50256,  9948,    76]], device='cuda:0')"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","source":["seqLen = tokens.shape[1]\n","h_store = t.zeros((1, seqLen, model.cfg.d_mlp), device=model.cfg.device)\n","\n","model.run_with_hooks(\n","    tokens[0],\n","    return_type = None,\n","    fwd_hooks=[\n","        (layer_name, store_h_hook),\n","    ]\n",")\n","\n","neg_h = t.clone(h_store)"],"metadata":{"id":"1DrKWZPXlpdM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["seqLen = tokens.shape[1]\n","h_store = t.zeros((1, seqLen, model.cfg.d_mlp), device=model.cfg.device)\n","\n","model.run_with_hooks(\n","    tokens[1],\n","    return_type = None,\n","    fwd_hooks=[\n","        (layer_name, store_h_hook),\n","    ]\n",")\n","\n","pos_h = t.clone(h_store)"],"metadata":{"id":"nnfc91dqU6da"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["steer_vec = neg_h - pos_h\n","steer_vec.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_cODPH6aVBcj","executionInfo":{"status":"ok","timestamp":1714523147659,"user_tz":240,"elapsed":43,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e98fb1d4-f980-4cf5-c439-a0b0fbcf7cce"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 3, 3072])"]},"metadata":{},"execution_count":70}]},{"cell_type":"code","source":["# get LLM activs for steering vec\n","post_reshaped = einops.repeat(steer_vec, \"batch seq d_mlp -> (batch seq) instances d_mlp\", instances=2)\n","post_reshaped.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OW6bPnhcfyCZ","executionInfo":{"status":"ok","timestamp":1714523147660,"user_tz":240,"elapsed":42,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"8e756e60-60a2-4e10-8ffa-92eea4a5700c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3, 2, 3072])"]},"metadata":{},"execution_count":71}]},{"cell_type":"code","source":["# use a fwd pass to compute ALL feature actvs for ALL this steering vec\n","output_tuple = autoencoder.forward(post_reshaped)\n","acts = output_tuple[3]\n","acts.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PXnogf1PXu0E","executionInfo":{"status":"ok","timestamp":1714523147660,"user_tz":240,"elapsed":41,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b92fd061-3c52-426b-99b5-cccde25b4489"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3, 2, 6144])"]},"metadata":{},"execution_count":72}]},{"cell_type":"code","source":["# Get the top k largest activations for feature neurons, not batch seq. use , dim=-1\n","feat_k = 5\n","top_acts_values, top_acts_indices = acts.topk(feat_k, dim=-1)"],"metadata":{"id":"CqaQZ6q_ftd_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["top_acts_indices"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D__HQHXtfFKO","executionInfo":{"status":"ok","timestamp":1714523147660,"user_tz":240,"elapsed":39,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c8a8c059-4458-4eac-ec5d-3ff834da7c25"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[  21, 3622, 3274, 4597, 1279],\n","         [ 144, 3016, 1272, 1681,  917]],\n","\n","        [[ 939, 4847,  594, 5196, 1176],\n","         [ 623, 3874, 4619,  663, 1692]],\n","\n","        [[   1,    0,    2,    4,    3],\n","         [   1,    0,    2,    4,    3]]], device='cuda:0')"]},"metadata":{},"execution_count":74}]},{"cell_type":"code","source":["all_tokens = model.to_tokens(batch_input, prepend_bos=True)\n","all_tokens = all_tokens.to(device)\n","all_tokens.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rgnxAj8Eii4c","executionInfo":{"status":"ok","timestamp":1714523539562,"user_tz":240,"elapsed":240,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c50b61da-d55f-4a1d-ab36-a78cb8168b6a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([100, 34])"]},"metadata":{},"execution_count":95}]},{"cell_type":"code","source":["# get top samp_m tokens for all top feat_k feature neurons\n","samp_m = 5\n","for feature_idx in top_acts_indices[0][0]:\n","    feature_idx = feature_idx.item()\n","    ds_top_acts_indices, ds_top_acts_values = highest_activating_tokens(all_tokens, model, autoencoder, feature_idx,\n","                                                            autoencoder_B=False, k=samp_m, layer_name=layer_name)\n","    display_top_sequences(ds_top_acts_indices, ds_top_acts_values, all_tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":817},"id":"IKGqt_lEiXWC","executionInfo":{"status":"ok","timestamp":1714523543055,"user_tz":240,"elapsed":249,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3146ca80-b474-471a-cb6e-4a51cb30586f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[3m           Tokens which most activate feature 21            \u001b[0m\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mSequence                                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mActivation\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n","│ at the time of this\u001b[1;4;38;5;208m writing\u001b[0m in early June)  │ -0.01      │\n","│  a dozen — \"Americans\u001b[1;4;38;5;208m for\u001b[0m Real Good Coffee\" │ -0.04      │\n","│ \u001b[1;4;38;5;208m<|endoftext|>\u001b[0mAnarchists in                  │ -0.11      │\n","│ \u001b[1;4;38;5;208m<|endoftext|>\u001b[0mFor today��                    │ -0.11      │\n","│ \u001b[1;4;38;5;208m<|endoftext|>\u001b[0mA magazine supplement with     │ -0.11      │\n","└─────────────────────────────────────────────┴────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">           Tokens which most activate feature 21            </span>\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Sequence                                    </span>┃<span style=\"font-weight: bold\"> Activation </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n","│ at the time of this<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> writing</span> in early June)  │ -0.01      │\n","│  a dozen — \"Americans<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> for</span> Real Good Coffee\" │ -0.04      │\n","│ <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">&lt;|endoftext|&gt;</span>Anarchists in                  │ -0.11      │\n","│ <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">&lt;|endoftext|&gt;</span>For today��                    │ -0.11      │\n","│ <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">&lt;|endoftext|&gt;</span>A magazine supplement with     │ -0.11      │\n","└─────────────────────────────────────────────┴────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[3m          Tokens which most activate feature 3622           \u001b[0m\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mSequence                                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mActivation\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n","│ at the time of this\u001b[1;4;38;5;208m writing\u001b[0m in early June)  │ -0.04      │\n","│  a dozen — \"Americans\u001b[1;4;38;5;208m for\u001b[0m Real Good Coffee\" │ -0.07      │\n","│ \u001b[1;4;38;5;208m<|endoftext|>\u001b[0mAnarchists in                  │ -0.12      │\n","│ \u001b[1;4;38;5;208m<|endoftext|>\u001b[0mFor today��                    │ -0.12      │\n","│ \u001b[1;4;38;5;208m<|endoftext|>\u001b[0mA magazine supplement with     │ -0.12      │\n","└─────────────────────────────────────────────┴────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">          Tokens which most activate feature 3622           </span>\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Sequence                                    </span>┃<span style=\"font-weight: bold\"> Activation </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n","│ at the time of this<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> writing</span> in early June)  │ -0.04      │\n","│  a dozen — \"Americans<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> for</span> Real Good Coffee\" │ -0.07      │\n","│ <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">&lt;|endoftext|&gt;</span>Anarchists in                  │ -0.12      │\n","│ <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">&lt;|endoftext|&gt;</span>For today��                    │ -0.12      │\n","│ <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">&lt;|endoftext|&gt;</span>A magazine supplement with     │ -0.12      │\n","└─────────────────────────────────────────────┴────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[3m                           Tokens which most activate feature 3274                            \u001b[0m\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mSequence                                                                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mActivation\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n","│  a dozen — \"Americans\u001b[1;4;38;5;208m for\u001b[0m Real Good Coffee\"                                   │ -0.03      │\n","│ at the time of this\u001b[1;4;38;5;208m writing\u001b[0m in early June)                                    │ -0.04      │\n","│  the sauce in their carry\u001b[1;4;38;5;208m-\u001b[0mon luggage, e                                       │ -0.09      │\n","│  of the Johns Hopkins Bl\u001b[1;4;38;5;208mo\u001b[0m<|endoftext|><|endoftext|><|endoftext|><|endoftext|> │ -0.09      │\n","│  the former J.L\u001b[1;4;38;5;208m.\u001b[0m Hudson��s                                                    │ -0.09      │\n","└───────────────────────────────────────────────────────────────────────────────┴────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                           Tokens which most activate feature 3274                            </span>\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Sequence                                                                      </span>┃<span style=\"font-weight: bold\"> Activation </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n","│  a dozen — \"Americans<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> for</span> Real Good Coffee\"                                   │ -0.03      │\n","│ at the time of this<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> writing</span> in early June)                                    │ -0.04      │\n","│  the sauce in their carry<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">-</span>on luggage, e                                       │ -0.09      │\n","│  of the Johns Hopkins Bl<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">o</span>&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt; │ -0.09      │\n","│  the former J.L<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">.</span> Hudson��s                                                    │ -0.09      │\n","└───────────────────────────────────────────────────────────────────────────────┴────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[3m            Tokens which most activate feature 4597            \u001b[0m\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mSequence                                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mActivation\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n","│ at the time of this\u001b[1;4;38;5;208m writing\u001b[0m in early June)     │ -0.05      │\n","│  a dozen — \"Americans\u001b[1;4;38;5;208m for\u001b[0m Real Good Coffee\"    │ -0.06      │\n","│  the sauce in their carry\u001b[1;4;38;5;208m-\u001b[0mon luggage, e        │ -0.14      │\n","│ It's not clear how\u001b[1;4;38;5;208m or\u001b[0m why two men attacked     │ -0.15      │\n","│  The world's best make\u001b[1;4;38;5;208m-\u001b[0mup artists reveal their │ -0.18      │\n","└────────────────────────────────────────────────┴────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">            Tokens which most activate feature 4597            </span>\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Sequence                                       </span>┃<span style=\"font-weight: bold\"> Activation </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n","│ at the time of this<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> writing</span> in early June)     │ -0.05      │\n","│  a dozen — \"Americans<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> for</span> Real Good Coffee\"    │ -0.06      │\n","│  the sauce in their carry<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">-</span>on luggage, e        │ -0.14      │\n","│ It's not clear how<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> or</span> why two men attacked     │ -0.15      │\n","│  The world's best make<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">-</span>up artists reveal their │ -0.18      │\n","└────────────────────────────────────────────────┴────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[3m          Tokens which most activate feature 1279           \u001b[0m\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mSequence                                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mActivation\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n","│ at the time of this\u001b[1;4;38;5;208m writing\u001b[0m in early June)  │ -0.00      │\n","│  a dozen — \"Americans\u001b[1;4;38;5;208m for\u001b[0m Real Good Coffee\" │ -0.05      │\n","│ It's not clear how\u001b[1;4;38;5;208m or\u001b[0m why two men attacked  │ -0.10      │\n","│ \u001b[1;4;38;5;208m<|endoftext|>\u001b[0mFor today��                    │ -0.12      │\n","│ \u001b[1;4;38;5;208m<|endoftext|>\u001b[0mA magazine supplement with     │ -0.12      │\n","└─────────────────────────────────────────────┴────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">          Tokens which most activate feature 1279           </span>\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Sequence                                    </span>┃<span style=\"font-weight: bold\"> Activation </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n","│ at the time of this<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> writing</span> in early June)  │ -0.00      │\n","│  a dozen — \"Americans<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> for</span> Real Good Coffee\" │ -0.05      │\n","│ It's not clear how<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\"> or</span> why two men attacked  │ -0.10      │\n","│ <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">&lt;|endoftext|&gt;</span>For today��                    │ -0.12      │\n","│ <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">&lt;|endoftext|&gt;</span>A magazine supplement with     │ -0.12      │\n","└─────────────────────────────────────────────┴────────────┘\n","</pre>\n"]},"metadata":{}}]}]}